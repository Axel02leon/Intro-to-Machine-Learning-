{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNTp86OrW0T+XlhAK9OUShq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Axel02leon/Intro-to-Machine-Learning-/blob/main/HW7.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Problem 1A"
      ],
      "metadata": {
        "id": "ycM4WnGzvvWa"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X2qvgdclM8iR"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import time\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "saqLJ_JguDVV",
        "outputId": "ee0450db-9dff-493f-fc4d-ef8c0e748493"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32,padding =4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "B_awJo48tXP0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transforms.ToTensor(), download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transforms.ToTensor(), download=True)"
      ],
      "metadata": {
        "id": "GyyOGRmtmE3r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40dd3733-6f3d-467a-c716-6245b4bcd58b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:18<00:00, 9.00MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "train_Loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_Loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "metadata": {
        "id": "PYckAdewskpV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Definding the CNN Model\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(64 * 8 * 8, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = x.view(-1, 64 * 8 * 8)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "FjvrWON4tvXq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, n_epochs = 200, patience=300):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    best_val_loss = float('inf')\n",
        "    epochs_no_improve = 0\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass and optimization\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average training loss\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation step\n",
        "        val_loss, val_accuracy = evaluate_model(model, val_loader, return_loss=True)\n",
        "\n",
        "        # Early stopping\n",
        "        if val_loss < best_val_loss:\n",
        "            best_val_loss = val_loss\n",
        "            epochs_no_improve = 0\n",
        "        else:\n",
        "            epochs_no_improve += 1\n",
        "            if epochs_no_improve >= patience:\n",
        "                print(f\"Early stopping triggered at epoch {epoch}\")\n",
        "                break\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, Val Loss: {val_loss:.4f}, Val Acc: {val_accuracy:.2f}%\")\n",
        "\n",
        "    return train_losses, val_losses\n"
      ],
      "metadata": {
        "id": "YsD9TFwAjEGW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function\n",
        "def evaluate_model(model, loader, return_loss=False):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    true_labels = []\n",
        "    predicted_labels = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            if return_loss:\n",
        "                total_loss += criterion(outputs, targets).item()\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            correct += (predicted == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "            true_labels.extend(targets.cpu().numpy())\n",
        "            predicted_labels.extend(predicted.cpu().numpy())\n",
        "\n",
        "    accuracy = 100 * correct / total\n",
        "    if return_loss:\n",
        "        average_loss = total_loss / len(loader)\n",
        "        return average_loss, accuracy\n",
        "    else:\n",
        "        return accuracy\n"
      ],
      "metadata": {
        "id": "GctyYpavLjT2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Instantiate Model, Loss Function, and Optimizer\n",
        "model = CNN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train the Model\n",
        "n_epochs = 200\n",
        "train_losses, val_losses = train_model(model, criterion, optimizer, train_Loader, test_Loader, n_epochs)\n",
        "\n",
        "# Test the Model\n",
        "test_accuracy = evaluate_model(model, test_Loader)\n",
        "print(f\"Test Accuracy: {test_accuracy:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ha5RPa2Mbwy",
        "outputId": "7f4db6da-0028-4dd1-845d-eabb82b0fc9c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200 - Train Loss: 1.5454, Val Loss: 1.2110, Val Acc: 56.16%\n",
            "Epoch 2/200 - Train Loss: 1.1847, Val Loss: 1.0677, Val Acc: 62.18%\n",
            "Epoch 3/200 - Train Loss: 1.0400, Val Loss: 0.9934, Val Acc: 65.15%\n",
            "Epoch 4/200 - Train Loss: 0.9369, Val Loss: 0.8952, Val Acc: 68.78%\n",
            "Epoch 5/200 - Train Loss: 0.8581, Val Loss: 0.8776, Val Acc: 69.61%\n",
            "Epoch 6/200 - Train Loss: 0.7935, Val Loss: 0.8439, Val Acc: 70.52%\n",
            "Epoch 7/200 - Train Loss: 0.7292, Val Loss: 0.8127, Val Acc: 71.85%\n",
            "Epoch 8/200 - Train Loss: 0.6780, Val Loss: 0.8348, Val Acc: 71.58%\n",
            "Epoch 9/200 - Train Loss: 0.6338, Val Loss: 0.8245, Val Acc: 72.06%\n",
            "Epoch 10/200 - Train Loss: 0.5827, Val Loss: 0.8102, Val Acc: 73.11%\n",
            "Epoch 11/200 - Train Loss: 0.5429, Val Loss: 0.8409, Val Acc: 72.63%\n",
            "Epoch 12/200 - Train Loss: 0.4996, Val Loss: 0.8594, Val Acc: 73.11%\n",
            "Epoch 13/200 - Train Loss: 0.4637, Val Loss: 0.8430, Val Acc: 73.52%\n",
            "Epoch 14/200 - Train Loss: 0.4306, Val Loss: 0.8824, Val Acc: 73.23%\n",
            "Epoch 15/200 - Train Loss: 0.4013, Val Loss: 0.9005, Val Acc: 73.39%\n",
            "Epoch 16/200 - Train Loss: 0.3728, Val Loss: 0.9061, Val Acc: 73.21%\n",
            "Epoch 17/200 - Train Loss: 0.3497, Val Loss: 0.9559, Val Acc: 72.96%\n",
            "Epoch 18/200 - Train Loss: 0.3261, Val Loss: 0.9795, Val Acc: 72.50%\n",
            "Epoch 19/200 - Train Loss: 0.3102, Val Loss: 1.0009, Val Acc: 73.36%\n",
            "Epoch 20/200 - Train Loss: 0.2873, Val Loss: 1.0374, Val Acc: 73.89%\n",
            "Epoch 21/200 - Train Loss: 0.2730, Val Loss: 1.0600, Val Acc: 72.64%\n",
            "Epoch 22/200 - Train Loss: 0.2594, Val Loss: 1.0953, Val Acc: 72.40%\n",
            "Epoch 23/200 - Train Loss: 0.2496, Val Loss: 1.1202, Val Acc: 73.09%\n",
            "Epoch 24/200 - Train Loss: 0.2309, Val Loss: 1.1818, Val Acc: 73.02%\n",
            "Epoch 25/200 - Train Loss: 0.2220, Val Loss: 1.1473, Val Acc: 73.26%\n",
            "Epoch 26/200 - Train Loss: 0.2228, Val Loss: 1.2033, Val Acc: 73.05%\n",
            "Epoch 27/200 - Train Loss: 0.2127, Val Loss: 1.1810, Val Acc: 73.51%\n",
            "Epoch 28/200 - Train Loss: 0.2052, Val Loss: 1.2174, Val Acc: 72.80%\n",
            "Epoch 29/200 - Train Loss: 0.2031, Val Loss: 1.2469, Val Acc: 72.85%\n",
            "Epoch 30/200 - Train Loss: 0.1929, Val Loss: 1.2936, Val Acc: 73.35%\n",
            "Epoch 31/200 - Train Loss: 0.1881, Val Loss: 1.3280, Val Acc: 72.71%\n",
            "Epoch 32/200 - Train Loss: 0.1866, Val Loss: 1.3245, Val Acc: 72.73%\n",
            "Epoch 33/200 - Train Loss: 0.1733, Val Loss: 1.3299, Val Acc: 72.62%\n",
            "Epoch 34/200 - Train Loss: 0.1738, Val Loss: 1.4220, Val Acc: 73.06%\n",
            "Epoch 35/200 - Train Loss: 0.1713, Val Loss: 1.3635, Val Acc: 72.99%\n",
            "Epoch 36/200 - Train Loss: 0.1694, Val Loss: 1.3828, Val Acc: 73.36%\n",
            "Epoch 37/200 - Train Loss: 0.1606, Val Loss: 1.4736, Val Acc: 72.38%\n",
            "Epoch 38/200 - Train Loss: 0.1566, Val Loss: 1.4558, Val Acc: 72.88%\n",
            "Epoch 39/200 - Train Loss: 0.1521, Val Loss: 1.4889, Val Acc: 72.30%\n",
            "Epoch 40/200 - Train Loss: 0.1545, Val Loss: 1.4717, Val Acc: 73.20%\n",
            "Epoch 41/200 - Train Loss: 0.1500, Val Loss: 1.4503, Val Acc: 72.50%\n",
            "Epoch 42/200 - Train Loss: 0.1463, Val Loss: 1.4949, Val Acc: 72.98%\n",
            "Epoch 43/200 - Train Loss: 0.1522, Val Loss: 1.5545, Val Acc: 73.08%\n",
            "Epoch 44/200 - Train Loss: 0.1432, Val Loss: 1.5906, Val Acc: 72.28%\n",
            "Epoch 45/200 - Train Loss: 0.1419, Val Loss: 1.5371, Val Acc: 72.85%\n",
            "Epoch 46/200 - Train Loss: 0.1368, Val Loss: 1.5121, Val Acc: 72.86%\n",
            "Epoch 47/200 - Train Loss: 0.1326, Val Loss: 1.6096, Val Acc: 72.82%\n",
            "Epoch 48/200 - Train Loss: 0.1380, Val Loss: 1.6209, Val Acc: 72.24%\n",
            "Epoch 49/200 - Train Loss: 0.1353, Val Loss: 1.5950, Val Acc: 73.17%\n",
            "Epoch 50/200 - Train Loss: 0.1295, Val Loss: 1.6635, Val Acc: 72.57%\n",
            "Epoch 51/200 - Train Loss: 0.1366, Val Loss: 1.6134, Val Acc: 73.13%\n",
            "Epoch 52/200 - Train Loss: 0.1256, Val Loss: 1.7103, Val Acc: 71.80%\n",
            "Epoch 53/200 - Train Loss: 0.1229, Val Loss: 1.6331, Val Acc: 72.73%\n",
            "Epoch 54/200 - Train Loss: 0.1318, Val Loss: 1.6748, Val Acc: 72.83%\n",
            "Epoch 55/200 - Train Loss: 0.1232, Val Loss: 1.6986, Val Acc: 72.75%\n",
            "Epoch 56/200 - Train Loss: 0.1216, Val Loss: 1.7445, Val Acc: 72.92%\n",
            "Epoch 57/200 - Train Loss: 0.1193, Val Loss: 1.8862, Val Acc: 72.93%\n",
            "Epoch 58/200 - Train Loss: 0.1174, Val Loss: 1.7641, Val Acc: 72.87%\n",
            "Epoch 59/200 - Train Loss: 0.1167, Val Loss: 1.7259, Val Acc: 72.70%\n",
            "Epoch 60/200 - Train Loss: 0.1187, Val Loss: 1.7055, Val Acc: 72.84%\n",
            "Epoch 61/200 - Train Loss: 0.1166, Val Loss: 1.8007, Val Acc: 72.55%\n",
            "Epoch 62/200 - Train Loss: 0.1217, Val Loss: 1.8699, Val Acc: 72.48%\n",
            "Epoch 63/200 - Train Loss: 0.1149, Val Loss: 1.8175, Val Acc: 72.35%\n",
            "Epoch 64/200 - Train Loss: 0.1141, Val Loss: 1.8607, Val Acc: 72.75%\n",
            "Epoch 65/200 - Train Loss: 0.1140, Val Loss: 1.8415, Val Acc: 72.76%\n",
            "Epoch 66/200 - Train Loss: 0.1101, Val Loss: 1.8483, Val Acc: 72.49%\n",
            "Epoch 67/200 - Train Loss: 0.1140, Val Loss: 1.8442, Val Acc: 72.43%\n",
            "Epoch 68/200 - Train Loss: 0.1132, Val Loss: 1.9055, Val Acc: 72.57%\n",
            "Epoch 69/200 - Train Loss: 0.1089, Val Loss: 1.8561, Val Acc: 73.13%\n",
            "Epoch 70/200 - Train Loss: 0.1127, Val Loss: 1.9271, Val Acc: 72.72%\n",
            "Epoch 71/200 - Train Loss: 0.1066, Val Loss: 1.8955, Val Acc: 72.63%\n",
            "Epoch 72/200 - Train Loss: 0.1060, Val Loss: 2.0191, Val Acc: 72.92%\n",
            "Epoch 73/200 - Train Loss: 0.1033, Val Loss: 2.0129, Val Acc: 71.87%\n",
            "Epoch 74/200 - Train Loss: 0.1067, Val Loss: 1.9213, Val Acc: 72.00%\n",
            "Epoch 75/200 - Train Loss: 0.1020, Val Loss: 1.9881, Val Acc: 72.63%\n",
            "Epoch 76/200 - Train Loss: 0.1039, Val Loss: 1.9059, Val Acc: 72.94%\n",
            "Epoch 77/200 - Train Loss: 0.1083, Val Loss: 1.8934, Val Acc: 72.77%\n",
            "Epoch 78/200 - Train Loss: 0.0980, Val Loss: 1.9648, Val Acc: 72.39%\n",
            "Epoch 79/200 - Train Loss: 0.1062, Val Loss: 1.9764, Val Acc: 72.82%\n",
            "Epoch 80/200 - Train Loss: 0.0966, Val Loss: 1.9942, Val Acc: 73.00%\n",
            "Epoch 81/200 - Train Loss: 0.0997, Val Loss: 1.9020, Val Acc: 73.09%\n",
            "Epoch 82/200 - Train Loss: 0.1031, Val Loss: 2.0172, Val Acc: 72.76%\n",
            "Epoch 83/200 - Train Loss: 0.1043, Val Loss: 2.1037, Val Acc: 72.29%\n",
            "Epoch 84/200 - Train Loss: 0.0961, Val Loss: 2.0719, Val Acc: 73.05%\n",
            "Epoch 85/200 - Train Loss: 0.0942, Val Loss: 2.0963, Val Acc: 72.47%\n",
            "Epoch 86/200 - Train Loss: 0.0960, Val Loss: 2.0446, Val Acc: 72.48%\n",
            "Epoch 87/200 - Train Loss: 0.1005, Val Loss: 2.1089, Val Acc: 72.69%\n",
            "Epoch 88/200 - Train Loss: 0.0965, Val Loss: 2.0860, Val Acc: 72.61%\n",
            "Epoch 89/200 - Train Loss: 0.0951, Val Loss: 2.1037, Val Acc: 72.13%\n",
            "Epoch 90/200 - Train Loss: 0.0942, Val Loss: 2.1343, Val Acc: 72.48%\n",
            "Epoch 91/200 - Train Loss: 0.0902, Val Loss: 2.0625, Val Acc: 72.80%\n",
            "Epoch 92/200 - Train Loss: 0.0951, Val Loss: 2.1182, Val Acc: 72.16%\n",
            "Epoch 93/200 - Train Loss: 0.0955, Val Loss: 2.0213, Val Acc: 72.74%\n",
            "Epoch 94/200 - Train Loss: 0.0900, Val Loss: 2.2251, Val Acc: 72.18%\n",
            "Epoch 95/200 - Train Loss: 0.0928, Val Loss: 2.2104, Val Acc: 72.40%\n",
            "Epoch 96/200 - Train Loss: 0.0899, Val Loss: 2.1044, Val Acc: 72.32%\n",
            "Epoch 97/200 - Train Loss: 0.0871, Val Loss: 2.1127, Val Acc: 71.89%\n",
            "Epoch 98/200 - Train Loss: 0.0926, Val Loss: 2.1998, Val Acc: 72.51%\n",
            "Epoch 99/200 - Train Loss: 0.0985, Val Loss: 2.1486, Val Acc: 72.82%\n",
            "Epoch 100/200 - Train Loss: 0.0886, Val Loss: 2.1772, Val Acc: 72.47%\n",
            "Epoch 101/200 - Train Loss: 0.0890, Val Loss: 2.2070, Val Acc: 72.85%\n",
            "Epoch 102/200 - Train Loss: 0.0895, Val Loss: 2.1572, Val Acc: 72.73%\n",
            "Epoch 103/200 - Train Loss: 0.0875, Val Loss: 2.1253, Val Acc: 73.03%\n",
            "Epoch 104/200 - Train Loss: 0.0898, Val Loss: 2.2324, Val Acc: 72.62%\n",
            "Epoch 105/200 - Train Loss: 0.0854, Val Loss: 2.0869, Val Acc: 73.20%\n",
            "Epoch 106/200 - Train Loss: 0.0875, Val Loss: 2.1426, Val Acc: 72.17%\n",
            "Epoch 107/200 - Train Loss: 0.0831, Val Loss: 2.1972, Val Acc: 72.68%\n",
            "Epoch 108/200 - Train Loss: 0.0861, Val Loss: 2.2951, Val Acc: 72.88%\n",
            "Epoch 109/200 - Train Loss: 0.0870, Val Loss: 2.3833, Val Acc: 72.44%\n",
            "Epoch 110/200 - Train Loss: 0.0885, Val Loss: 2.2640, Val Acc: 72.86%\n",
            "Epoch 111/200 - Train Loss: 0.0857, Val Loss: 2.3985, Val Acc: 72.38%\n",
            "Epoch 112/200 - Train Loss: 0.0829, Val Loss: 2.2444, Val Acc: 72.40%\n",
            "Epoch 113/200 - Train Loss: 0.0794, Val Loss: 2.2991, Val Acc: 72.56%\n",
            "Epoch 114/200 - Train Loss: 0.0847, Val Loss: 2.3036, Val Acc: 73.31%\n",
            "Epoch 115/200 - Train Loss: 0.0802, Val Loss: 2.1743, Val Acc: 72.72%\n",
            "Epoch 116/200 - Train Loss: 0.0827, Val Loss: 2.2973, Val Acc: 72.53%\n",
            "Epoch 117/200 - Train Loss: 0.0860, Val Loss: 2.2054, Val Acc: 72.81%\n",
            "Epoch 118/200 - Train Loss: 0.0842, Val Loss: 2.3355, Val Acc: 72.46%\n",
            "Epoch 119/200 - Train Loss: 0.0832, Val Loss: 2.1982, Val Acc: 72.70%\n",
            "Epoch 120/200 - Train Loss: 0.0796, Val Loss: 2.3146, Val Acc: 72.67%\n",
            "Epoch 121/200 - Train Loss: 0.0791, Val Loss: 2.3553, Val Acc: 72.21%\n",
            "Epoch 122/200 - Train Loss: 0.0832, Val Loss: 2.3333, Val Acc: 72.65%\n",
            "Epoch 123/200 - Train Loss: 0.0855, Val Loss: 2.4446, Val Acc: 72.20%\n",
            "Epoch 124/200 - Train Loss: 0.0847, Val Loss: 2.3603, Val Acc: 72.62%\n",
            "Epoch 125/200 - Train Loss: 0.0760, Val Loss: 2.2476, Val Acc: 72.73%\n",
            "Epoch 126/200 - Train Loss: 0.0791, Val Loss: 2.2714, Val Acc: 72.55%\n",
            "Epoch 127/200 - Train Loss: 0.0789, Val Loss: 2.3453, Val Acc: 72.53%\n",
            "Epoch 128/200 - Train Loss: 0.0799, Val Loss: 2.3684, Val Acc: 71.98%\n",
            "Epoch 129/200 - Train Loss: 0.0856, Val Loss: 2.3924, Val Acc: 72.91%\n",
            "Epoch 130/200 - Train Loss: 0.0797, Val Loss: 2.3158, Val Acc: 72.44%\n",
            "Epoch 131/200 - Train Loss: 0.0725, Val Loss: 2.5496, Val Acc: 72.89%\n",
            "Epoch 132/200 - Train Loss: 0.0808, Val Loss: 2.5162, Val Acc: 72.82%\n",
            "Epoch 133/200 - Train Loss: 0.0793, Val Loss: 2.5833, Val Acc: 72.37%\n",
            "Epoch 134/200 - Train Loss: 0.0850, Val Loss: 2.3026, Val Acc: 73.17%\n",
            "Epoch 135/200 - Train Loss: 0.0728, Val Loss: 2.4481, Val Acc: 72.49%\n",
            "Epoch 136/200 - Train Loss: 0.0738, Val Loss: 2.5059, Val Acc: 72.17%\n",
            "Epoch 137/200 - Train Loss: 0.0763, Val Loss: 2.4293, Val Acc: 72.50%\n",
            "Epoch 138/200 - Train Loss: 0.0777, Val Loss: 2.5544, Val Acc: 72.11%\n",
            "Epoch 139/200 - Train Loss: 0.0744, Val Loss: 2.4592, Val Acc: 72.19%\n",
            "Epoch 140/200 - Train Loss: 0.0765, Val Loss: 2.4442, Val Acc: 72.31%\n",
            "Epoch 141/200 - Train Loss: 0.0784, Val Loss: 2.5308, Val Acc: 72.84%\n",
            "Epoch 142/200 - Train Loss: 0.0752, Val Loss: 2.4779, Val Acc: 72.84%\n",
            "Epoch 143/200 - Train Loss: 0.0787, Val Loss: 2.5141, Val Acc: 72.51%\n",
            "Epoch 144/200 - Train Loss: 0.0746, Val Loss: 2.3805, Val Acc: 72.73%\n",
            "Epoch 145/200 - Train Loss: 0.0716, Val Loss: 2.3670, Val Acc: 72.12%\n",
            "Epoch 146/200 - Train Loss: 0.0739, Val Loss: 2.5035, Val Acc: 72.18%\n",
            "Epoch 147/200 - Train Loss: 0.0704, Val Loss: 2.4434, Val Acc: 72.90%\n",
            "Epoch 148/200 - Train Loss: 0.0734, Val Loss: 2.4975, Val Acc: 72.23%\n",
            "Epoch 149/200 - Train Loss: 0.0764, Val Loss: 2.5065, Val Acc: 72.43%\n",
            "Epoch 150/200 - Train Loss: 0.0724, Val Loss: 2.5607, Val Acc: 71.74%\n",
            "Epoch 151/200 - Train Loss: 0.0772, Val Loss: 2.3458, Val Acc: 72.55%\n",
            "Epoch 152/200 - Train Loss: 0.0721, Val Loss: 2.5401, Val Acc: 72.72%\n",
            "Epoch 153/200 - Train Loss: 0.0732, Val Loss: 2.6483, Val Acc: 72.19%\n",
            "Epoch 154/200 - Train Loss: 0.0689, Val Loss: 2.6641, Val Acc: 72.37%\n",
            "Epoch 155/200 - Train Loss: 0.0755, Val Loss: 2.5387, Val Acc: 72.52%\n",
            "Epoch 156/200 - Train Loss: 0.0693, Val Loss: 2.6607, Val Acc: 72.60%\n",
            "Epoch 157/200 - Train Loss: 0.0704, Val Loss: 2.5048, Val Acc: 72.21%\n",
            "Epoch 158/200 - Train Loss: 0.0790, Val Loss: 2.5260, Val Acc: 72.50%\n",
            "Epoch 159/200 - Train Loss: 0.0718, Val Loss: 2.6823, Val Acc: 72.66%\n",
            "Epoch 160/200 - Train Loss: 0.0713, Val Loss: 2.5812, Val Acc: 72.39%\n",
            "Epoch 161/200 - Train Loss: 0.0725, Val Loss: 2.5692, Val Acc: 73.05%\n",
            "Epoch 162/200 - Train Loss: 0.0696, Val Loss: 2.5444, Val Acc: 72.34%\n",
            "Epoch 163/200 - Train Loss: 0.0735, Val Loss: 2.5153, Val Acc: 72.44%\n",
            "Epoch 164/200 - Train Loss: 0.0744, Val Loss: 2.6025, Val Acc: 72.75%\n",
            "Epoch 165/200 - Train Loss: 0.0694, Val Loss: 2.5733, Val Acc: 72.14%\n",
            "Epoch 166/200 - Train Loss: 0.0702, Val Loss: 2.5296, Val Acc: 72.53%\n",
            "Epoch 167/200 - Train Loss: 0.0676, Val Loss: 2.5863, Val Acc: 72.47%\n",
            "Epoch 168/200 - Train Loss: 0.0632, Val Loss: 2.6839, Val Acc: 72.32%\n",
            "Epoch 169/200 - Train Loss: 0.0724, Val Loss: 2.6209, Val Acc: 71.96%\n",
            "Epoch 170/200 - Train Loss: 0.0692, Val Loss: 2.4580, Val Acc: 72.33%\n",
            "Epoch 171/200 - Train Loss: 0.0680, Val Loss: 2.6339, Val Acc: 72.73%\n",
            "Epoch 172/200 - Train Loss: 0.0678, Val Loss: 2.6965, Val Acc: 72.65%\n",
            "Epoch 173/200 - Train Loss: 0.0689, Val Loss: 2.5181, Val Acc: 71.86%\n",
            "Epoch 174/200 - Train Loss: 0.0657, Val Loss: 2.6463, Val Acc: 72.23%\n",
            "Epoch 175/200 - Train Loss: 0.0699, Val Loss: 2.7376, Val Acc: 72.93%\n",
            "Epoch 176/200 - Train Loss: 0.0716, Val Loss: 2.5500, Val Acc: 72.24%\n",
            "Epoch 177/200 - Train Loss: 0.0690, Val Loss: 2.7545, Val Acc: 72.40%\n",
            "Epoch 178/200 - Train Loss: 0.0692, Val Loss: 2.7241, Val Acc: 72.27%\n",
            "Epoch 179/200 - Train Loss: 0.0660, Val Loss: 2.6946, Val Acc: 72.40%\n",
            "Epoch 180/200 - Train Loss: 0.0723, Val Loss: 2.6930, Val Acc: 72.46%\n",
            "Epoch 181/200 - Train Loss: 0.0629, Val Loss: 2.7186, Val Acc: 72.36%\n",
            "Epoch 182/200 - Train Loss: 0.0705, Val Loss: 2.5009, Val Acc: 72.14%\n",
            "Epoch 183/200 - Train Loss: 0.0666, Val Loss: 2.6248, Val Acc: 72.42%\n",
            "Epoch 184/200 - Train Loss: 0.0659, Val Loss: 2.6907, Val Acc: 72.16%\n",
            "Epoch 185/200 - Train Loss: 0.0670, Val Loss: 2.7109, Val Acc: 72.25%\n",
            "Epoch 186/200 - Train Loss: 0.0717, Val Loss: 2.6628, Val Acc: 72.34%\n",
            "Epoch 187/200 - Train Loss: 0.0709, Val Loss: 2.8531, Val Acc: 72.12%\n",
            "Epoch 188/200 - Train Loss: 0.0626, Val Loss: 2.7541, Val Acc: 72.80%\n",
            "Epoch 189/200 - Train Loss: 0.0644, Val Loss: 2.7621, Val Acc: 72.14%\n",
            "Epoch 190/200 - Train Loss: 0.0631, Val Loss: 2.6363, Val Acc: 71.80%\n",
            "Epoch 191/200 - Train Loss: 0.0656, Val Loss: 2.7074, Val Acc: 71.81%\n",
            "Epoch 192/200 - Train Loss: 0.0645, Val Loss: 2.8267, Val Acc: 72.47%\n",
            "Epoch 193/200 - Train Loss: 0.0680, Val Loss: 2.7932, Val Acc: 72.50%\n",
            "Epoch 194/200 - Train Loss: 0.0647, Val Loss: 2.7233, Val Acc: 72.50%\n",
            "Epoch 195/200 - Train Loss: 0.0690, Val Loss: 2.9049, Val Acc: 72.25%\n",
            "Epoch 196/200 - Train Loss: 0.0649, Val Loss: 2.7417, Val Acc: 72.37%\n",
            "Epoch 197/200 - Train Loss: 0.0629, Val Loss: 2.7360, Val Acc: 72.06%\n",
            "Epoch 198/200 - Train Loss: 0.0606, Val Loss: 2.7512, Val Acc: 72.15%\n",
            "Epoch 199/200 - Train Loss: 0.0704, Val Loss: 2.6557, Val Acc: 72.06%\n",
            "Epoch 200/200 - Train Loss: 0.0632, Val Loss: 2.5333, Val Acc: 71.66%\n",
            "Test Accuracy: 71.66%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Problem B1\n",
        "# New Section"
      ],
      "metadata": {
        "id": "wsDO7TckrTAM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import f1_score, confusion_matrix\n",
        "import time\n"
      ],
      "metadata": {
        "id": "ZukbrzP3rZUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for GPU availability\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x3dvwydOBnep",
        "outputId": "b9492402-0663-4f81-89e7-f5ec8e5de339"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "3MDhRK3QsJSv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Preprocessing\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
        "])"
      ],
      "metadata": {
        "id": "2ZtsBxnVBsmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CIFAR-10 Dataset\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True, transform=transform, download=True)\n",
        "test_dataset = datasets.CIFAR10(root='./data', train=False, transform=transform, download=True)\n",
        "\n",
        "# Create DataLoaders\n",
        "batch_size = 64\n",
        "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FTsd7xPBuUm",
        "outputId": "43983c7f-d5d4-4f47-a722-e039d8030679"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170M/170M [00:13<00:00, 13.1MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for inputs, targets in train_loader:\n",
        "    print(f\"Sample Input Shape: {inputs.shape}\")  # Expected: [batch_size, 3, 32, 32]\n",
        "    print(f\"Sample Target Shape: {targets.shape}\")  # Expected: [batch_size]\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JPxNuFTKHR0S",
        "outputId": "52574480-6803-4034-d3f3-4e0767b2101f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample Input Shape: torch.Size([64, 3, 32, 32])\n",
            "Sample Target Shape: torch.Size([64])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Extended CNN Model\n",
        "class CNNEXTEN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNNEXTEN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        self.fc1 = nn.Linear(128 * 4 * 4, 512)\n",
        "        self.fc2 = nn.Linear(512, 10)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 4 * 4)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "-NDYXQXXBzgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training Function\n",
        "def train_model(model, criterion, optimizer, train_loader, val_loader, n_epochs=200):\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "\n",
        "    for epoch in range(1, n_epochs + 1):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for inputs, targets in train_loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward pass\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        # Calculate average training loss\n",
        "        avg_train_loss = running_loss / len(train_loader)\n",
        "        train_losses.append(avg_train_loss)\n",
        "\n",
        "        # Validation step\n",
        "        val_loss, val_accuracy, _, _ = evaluate_model(model, val_loader)  # Unpack only needed values\n",
        "        val_losses.append(val_loss)\n",
        "\n",
        "        # Print training and validation results every epoch\n",
        "        print(f\"Epoch {epoch}/{n_epochs} - Train Loss: {avg_train_loss:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%\")\n",
        "\n",
        "    return train_losses, val_losses\n"
      ],
      "metadata": {
        "id": "M1HmHiegB6Sd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Evaluation Function with F1-Score, Confusion Matrix, and Accuracy\n",
        "def evaluate_model(model, loader):\n",
        "    model.eval()\n",
        "    all_targets = []\n",
        "    all_predictions = []\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    total_loss = 0.0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in loader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            _, predictions = torch.max(outputs, 1)\n",
        "            correct += (predictions == targets).sum().item()\n",
        "            total += targets.size(0)\n",
        "\n",
        "            all_targets.extend(targets.cpu().numpy())\n",
        "            all_predictions.extend(predictions.cpu().numpy())\n",
        "\n",
        "    # Calculate metrics\n",
        "    accuracy = correct / total * 100\n",
        "    f1 = f1_score(all_targets, all_predictions, average='weighted')\n",
        "    cm = confusion_matrix(all_targets, all_predictions)\n",
        "    avg_loss = total_loss / len(loader)\n",
        "\n",
        "    # Print metrics\n",
        "    print(f\"Evaluation Results:\")\n",
        "    print(f\"Average Loss: {avg_loss:.4f}\")\n",
        "    print(f\"Accuracy: {accuracy:.2f}%\")\n",
        "    print(f\"F1 Score: {f1:.4f}\")\n",
        "    print(f\"Confusion Matrix:\\n{cm}\")\n",
        "\n",
        "    return avg_loss, accuracy, f1, cm\n",
        "\n"
      ],
      "metadata": {
        "id": "ZReInnp4CSlD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train and Test Extended CNN\n",
        "extended_model = CNNEXTEN().to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(extended_model.parameters(), lr=0.001)\n",
        "\n",
        "print(\"\\nTraining Extended CNN...\")\n",
        "train_losses, val_losses = train_model(extended_model, criterion, optimizer, train_loader, test_loader, n_epochs=200)\n",
        "\n",
        "extended_test_accuracy = evaluate_model(extended_model, test_loader)\n",
        "print(f\"Extended CNN Test Accuracy: {extended_test_accuracy:.2f}%\")\n",
        "print(\"\\nEvaluating Extended CNN...\")\n",
        "_, test_accuracy, f1, cm = evaluate_model(extended_model, test_loader)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RfZi1rxKCYM1",
        "outputId": "b7f0ac92-a35d-43f6-b5ba-eaf8c5e66041"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training Extended CNN...\n",
            "Evaluation Results:\n",
            "Average Loss: 1.3022\n",
            "Accuracy: 52.82%\n",
            "F1 Score: 0.5172\n",
            "Confusion Matrix:\n",
            "[[696  52  57  11  15  21  16   8  73  51]\n",
            " [ 31 713   6   8   7  14  14   6  28 173]\n",
            " [118  15 267  49 204 147 123  29  21  27]\n",
            " [ 30  26  81 206  85 348 125  41  14  44]\n",
            " [ 53  16  89  39 434  83 168  90  11  17]\n",
            " [ 13   8  82  89  74 606  47  47  10  24]\n",
            " [ 12  10  31  52  94  38 710  15  10  28]\n",
            " [ 29  14  36  31  89 178  27 520   7  69]\n",
            " [277  90  21  12   4  17  18   4 502  55]\n",
            " [ 37 198  12  10   7  26  23  14  45 628]]\n",
            "Epoch 1/200 - Train Loss: 1.6091, Val Loss: 1.3022, Val Accuracy: 52.82%\n",
            "Evaluation Results:\n",
            "Average Loss: 1.0624\n",
            "Accuracy: 61.61%\n",
            "F1 Score: 0.6148\n",
            "Confusion Matrix:\n",
            "[[757  34  54  11  18   6   6  21  47  46]\n",
            " [ 31 779   2   9   4   4  11  12  10 138]\n",
            " [101  11 406  77 166 111  69  37   9  13]\n",
            " [ 34  12  65 405  91 241  79  42  14  17]\n",
            " [ 41   6  87  75 576  49  71  88   5   2]\n",
            " [ 15   7  63 170  60 569  23  73   7  13]\n",
            " [ 12  10  43 112  99  17 684  10   1  12]\n",
            " [ 19   6  27  45 103 104  10 664   1  21]\n",
            " [178  73  22  20  12  10  10   7 609  59]\n",
            " [ 36 148   8  20  10   9  12  30  15 712]]\n",
            "Epoch 2/200 - Train Loss: 1.2413, Val Loss: 1.0624, Val Accuracy: 61.61%\n",
            "Evaluation Results:\n",
            "Average Loss: 1.0212\n",
            "Accuracy: 63.74%\n",
            "F1 Score: 0.6297\n",
            "Confusion Matrix:\n",
            "[[843  24  37   3   5   5   1  24  35  23]\n",
            " [ 47 847   3   1   2   2   0   6  19  73]\n",
            " [133  13 616  20  52  66  15  71   9   5]\n",
            " [ 59  22 144 253  68 236  40 138  23  17]\n",
            " [ 60   4 192  23 459  41  18 191  10   2]\n",
            " [ 32  11 104  80  33 566   9 151   8   6]\n",
            " [ 35  13 163  44 100  27 565  25  12  16]\n",
            " [ 44   1  41   8  21  43   1 827   1  13]\n",
            " [196  46  14   3   3   4   2  13 705  14]\n",
            " [ 81 146   7   4   4   2   3  35  25 693]]\n",
            "Epoch 3/200 - Train Loss: 1.0648, Val Loss: 1.0212, Val Accuracy: 63.74%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.9531\n",
            "Accuracy: 67.23%\n",
            "F1 Score: 0.6630\n",
            "Confusion Matrix:\n",
            "[[768  39  31   3   9   2   8   5  92  43]\n",
            " [ 13 907   3   0   0   1   6   1  24  45]\n",
            " [133  22 529  37  75  36 105  26  21  16]\n",
            " [ 49  40  95 376  72  96 142  48  31  51]\n",
            " [ 59  12  93  24 562   9  99 109  16  17]\n",
            " [ 29  20  82 178  49 480  42  70  14  36]\n",
            " [ 13  26  50  29  30   5 809   3  15  20]\n",
            " [ 49  20  39  33  52  29   9 717   9  43]\n",
            " [ 68  48   2   6   2   1   5   6 838  24]\n",
            " [ 31 178   5   2   5   1   4   4  33 737]]\n",
            "Epoch 4/200 - Train Loss: 0.9582, Val Loss: 0.9531, Val Accuracy: 67.23%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.8841\n",
            "Accuracy: 69.66%\n",
            "F1 Score: 0.6917\n",
            "Confusion Matrix:\n",
            "[[820   9  36   3   8   0   3   7  85  29]\n",
            " [ 38 838   0   1   2   1   1   1  42  76]\n",
            " [137   4 550  27 107  49  47  33  30  16]\n",
            " [ 64   5  99 412  90 128  69  49  41  43]\n",
            " [ 67   4  71  27 660  16  36  95  19   5]\n",
            " [ 32   6  70 148  52 536  20  94  25  17]\n",
            " [ 18   5  64  44  62   8 755   7  22  15]\n",
            " [ 56   8  36  18  52  35   1 768   8  18]\n",
            " [ 94  18   3   4   5   4   1   0 855  16]\n",
            " [ 64  81   4   4   6   1   3   5  60 772]]\n",
            "Epoch 5/200 - Train Loss: 0.8917, Val Loss: 0.8841, Val Accuracy: 69.66%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.7965\n",
            "Accuracy: 71.61%\n",
            "F1 Score: 0.7186\n",
            "Confusion Matrix:\n",
            "[[745  11  70  15  18   4   3  10  92  32]\n",
            " [ 24 815   6   8   1  10   2   1  45  88]\n",
            " [ 63   4 712  38  77  48  20  10  20   8]\n",
            " [ 17   2 147 504  48 196  32  20  24  10]\n",
            " [ 16   1 123  58 665  51  24  45  14   3]\n",
            " [  7   2  97 141  49 655   4  29  10   6]\n",
            " [  5   2 125  75  72  32 672   3   7   7]\n",
            " [ 11   1  68  38  94  83   5 673   7  20]\n",
            " [ 45   7  14  10   6   2   2   2 895  17]\n",
            " [ 21  50  15  15   5   4   1   8  56 825]]\n",
            "Epoch 6/200 - Train Loss: 0.8375, Val Loss: 0.7965, Val Accuracy: 71.61%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.7641\n",
            "Accuracy: 73.54%\n",
            "F1 Score: 0.7324\n",
            "Confusion Matrix:\n",
            "[[810  21  44  13   6   4   9  20  44  29]\n",
            " [ 19 901   0   2   2   2   5   2  18  49]\n",
            " [ 77   4 621  31  93  49  79  32   7   7]\n",
            " [ 24   9  83 463  72 175 101  48   8  17]\n",
            " [ 27   4  73  35 671  30  40 114   2   4]\n",
            " [ 14   3  58 135  48 656  19  56   3   8]\n",
            " [  7   3  57  28  72  10 808   6   4   5]\n",
            " [ 10   3  37  25  40  48  11 821   1   4]\n",
            " [106  23   7  14   5   2   6   8 804  25]\n",
            " [ 34 101   4   8   4   5   6  18  21 799]]\n",
            "Epoch 7/200 - Train Loss: 0.7982, Val Loss: 0.7641, Val Accuracy: 73.54%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.7294\n",
            "Accuracy: 74.42%\n",
            "F1 Score: 0.7433\n",
            "Confusion Matrix:\n",
            "[[851  26  37   8   7   4   5  12  27  23]\n",
            " [ 14 924   1   6   1   3   4   1  12  34]\n",
            " [ 79   3 648  56  43  54  60  33   7  17]\n",
            " [ 37  10  79 533  58 177  56  29  11  10]\n",
            " [ 31   3 104  60 654  29  45  64   4   6]\n",
            " [ 11   5  51 158  31 648  15  70   3   8]\n",
            " [ 14   5  60  65  26  23 792   8   3   4]\n",
            " [ 18   4  31  42  35  43   3 806   1  17]\n",
            " [134  36   7  16   4   3   5   6 766  23]\n",
            " [ 42  89   4   7   4   3   5  14  12 820]]\n",
            "Epoch 8/200 - Train Loss: 0.7620, Val Loss: 0.7294, Val Accuracy: 74.42%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.7275\n",
            "Accuracy: 74.82%\n",
            "F1 Score: 0.7488\n",
            "Confusion Matrix:\n",
            "[[774  12  32  24  11   3   2   8  84  50]\n",
            " [ 13 845   0   6   2   0   3   1  22 108]\n",
            " [ 75   8 571  94  78  61  61  12  18  22]\n",
            " [ 16   6  36 664  49 123  45  13  19  29]\n",
            " [ 18   3  37  86 734  20  49  38   8   7]\n",
            " [ 10   2  25 245  49 605   9  33   5  17]\n",
            " [  5   2  26  79  32  17 814   7   7  11]\n",
            " [ 19   6  16  78  69  52   4 714   7  35]\n",
            " [ 55  19   1  18   3   1   2   4 859  38]\n",
            " [ 12  35   3  13   2   0   3   5  25 902]]\n",
            "Epoch 9/200 - Train Loss: 0.7436, Val Loss: 0.7275, Val Accuracy: 74.82%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.7053\n",
            "Accuracy: 75.48%\n",
            "F1 Score: 0.7525\n",
            "Confusion Matrix:\n",
            "[[764  13  37  16  12   4   8  10 110  26]\n",
            " [ 17 879   3   4   3   0   4   3  30  57]\n",
            " [ 62   4 680  38  77  41  44  34  16   4]\n",
            " [ 16   5  79 510  78 148  68  64  17  15]\n",
            " [ 16   2  64  39 734  24  31  73  14   3]\n",
            " [  8   4  62 141  47 628  13  87   4   6]\n",
            " [  6   3  66  62  45  14 784  14   5   1]\n",
            " [ 10   2  35  20  57  23   5 834   5   9]\n",
            " [ 30  10   7  10   3   2   4   3 913  18]\n",
            " [ 31  69   7  11   6   1   4  13  36 822]]\n",
            "Epoch 10/200 - Train Loss: 0.7163, Val Loss: 0.7053, Val Accuracy: 75.48%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.7043\n",
            "Accuracy: 75.40%\n",
            "F1 Score: 0.7538\n",
            "Confusion Matrix:\n",
            "[[714  24  36  30  17   8   8  15 111  37]\n",
            " [  5 906   3   7   2   5   1   3  26  42]\n",
            " [ 63   7 573  81  71  89  64  32  12   8]\n",
            " [  8   3  42 601  37 218  40  28  12  11]\n",
            " [  8   4  38  78 700  42  47  70  10   3]\n",
            " [  6   3  27 156  36 724   5  32   5   6]\n",
            " [  6   5  21  74  28  24 820  12   6   4]\n",
            " [  7   2  13  37  48  78   3 799   4   9]\n",
            " [ 31  28   3  17   4   4   2   5 889  17]\n",
            " [ 13  95   2  13   6   6   7  15  29 814]]\n",
            "Epoch 11/200 - Train Loss: 0.6948, Val Loss: 0.7043, Val Accuracy: 75.40%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6702\n",
            "Accuracy: 76.59%\n",
            "F1 Score: 0.7647\n",
            "Confusion Matrix:\n",
            "[[847  10  16  13  14   2   4  11  58  25]\n",
            " [ 25 857   4   5   2   2   5   3  18  79]\n",
            " [ 74   2 624  43  96  56  56  28  11  10]\n",
            " [ 22   4  49 562  62 177  39  49  16  20]\n",
            " [ 21   1  42  46 762  35  30  54   5   4]\n",
            " [ 11   1  43 157  43 673  10  47   4  11]\n",
            " [  8   3  37  65  51  29 783   6   9   9]\n",
            " [ 20   4  24  29  47  47   5 815   0   9]\n",
            " [ 60  13   5   8   7   3   2   5 874  23]\n",
            " [ 25  59   5   7   2   2   3  10  25 862]]\n",
            "Epoch 12/200 - Train Loss: 0.6811, Val Loss: 0.6702, Val Accuracy: 76.59%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6798\n",
            "Accuracy: 77.15%\n",
            "F1 Score: 0.7680\n",
            "Confusion Matrix:\n",
            "[[860   7  32   9   6   2  10   7  54  13]\n",
            " [ 18 906   3   5   1   2   6   0  28  31]\n",
            " [ 69   3 701  24  54  42  69  23  11   4]\n",
            " [ 25   7  95 493  68 128 104  38  25  17]\n",
            " [ 30   0  71  22 722  22  75  48   7   3]\n",
            " [ 14   4  68 114  43 661  33  52   6   5]\n",
            " [  6   2  44  26  21  12 877   4   5   3]\n",
            " [ 18   3  37  27  46  36  10 815   0   8]\n",
            " [ 56  12   7   3   3   1   6   4 897  11]\n",
            " [ 47  95   6   4   4   1  11  13  36 783]]\n",
            "Epoch 13/200 - Train Loss: 0.6656, Val Loss: 0.6798, Val Accuracy: 77.15%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6444\n",
            "Accuracy: 77.56%\n",
            "F1 Score: 0.7746\n",
            "Confusion Matrix:\n",
            "[[825  13  34   9  19   6   9  10  37  38]\n",
            " [ 11 916   3   9   0   3   6   0  10  42]\n",
            " [ 62   3 621  55  83  65  63  33   8   7]\n",
            " [ 18   7  67 602  57 140  43  44  10  12]\n",
            " [  5   0  42  58 720  27  32 104   7   5]\n",
            " [  6   2  37 149  27 695  13  59   4   8]\n",
            " [  8   1  33  63  31  15 836   9   4   0]\n",
            " [ 10   2  17  28  27  56   6 840   2  12]\n",
            " [ 72  18  10   9   4   4   5   7 844  27]\n",
            " [ 20  72   6   8   2   4   3   9  19 857]]\n",
            "Epoch 14/200 - Train Loss: 0.6518, Val Loss: 0.6444, Val Accuracy: 77.56%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6532\n",
            "Accuracy: 77.70%\n",
            "F1 Score: 0.7753\n",
            "Confusion Matrix:\n",
            "[[829  21  22  12  16   1   8   4  55  32]\n",
            " [ 13 899   3   2   0   2   6   1  15  59]\n",
            " [ 77   2 625  48  83  41  89  12  11  12]\n",
            " [ 20   7  55 635  57  75 105  14  11  21]\n",
            " [ 14   3  33  47 787  11  71  20  11   3]\n",
            " [  8   4  39 197  60 608  37  29   7  11]\n",
            " [  7   1  24  37  20   3 898   2   7   1]\n",
            " [ 18   6  28  55  82  37  12 746   2  14]\n",
            " [ 66  20   3   5   5   3   6   1 871  20]\n",
            " [ 20  65   4   8   3   2   4   2  20 872]]\n",
            "Epoch 15/200 - Train Loss: 0.6335, Val Loss: 0.6532, Val Accuracy: 77.70%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6488\n",
            "Accuracy: 77.23%\n",
            "F1 Score: 0.7729\n",
            "Confusion Matrix:\n",
            "[[823  15  57  10   8   0   7   9  44  27]\n",
            " [ 20 906   7   2   0   1   4   0  18  42]\n",
            " [ 57   2 775  38  40  19  42  11   6  10]\n",
            " [ 18   5 109 629  56  75  64  19  12  13]\n",
            " [ 21   1  96  63 717  13  49  34   5   1]\n",
            " [ 17   3 119 188  41 577  15  31   5   4]\n",
            " [  4   4  71  40  14   4 852   5   5   1]\n",
            " [ 16   3  66  52  42  30   9 761   3  18]\n",
            " [ 81  13  16   7   4   0   2   0 858  19]\n",
            " [ 33  86  12   9   2   1   5   7  20 825]]\n",
            "Epoch 16/200 - Train Loss: 0.6253, Val Loss: 0.6488, Val Accuracy: 77.23%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6531\n",
            "Accuracy: 77.88%\n",
            "F1 Score: 0.7784\n",
            "Confusion Matrix:\n",
            "[[833   9  38  13  20   8   4  11  34  30]\n",
            " [ 10 886   2   5   4   6   5   3  12  67]\n",
            " [ 52   2 663  38  93  79  42  22   3   6]\n",
            " [ 20   4  53 527  59 236  52  26   6  17]\n",
            " [ 12   0  38  27 809  34  29  46   3   2]\n",
            " [ 10   2  29  92  37 778  11  35   2   4]\n",
            " [  6   2  47  55  52  36 793   5   2   2]\n",
            " [ 11   3  25  33  45  64   2 814   0   3]\n",
            " [ 72  27  14  20   7   4   4   3 818  31]\n",
            " [ 35  42   3  13   3   7   7  12  11 867]]\n",
            "Epoch 17/200 - Train Loss: 0.6108, Val Loss: 0.6531, Val Accuracy: 77.88%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6262\n",
            "Accuracy: 79.01%\n",
            "F1 Score: 0.7897\n",
            "Confusion Matrix:\n",
            "[[842  12  41   9  10   0   6  13  43  24]\n",
            " [ 19 889   5   4   3   2   4   1  19  54]\n",
            " [ 64   0 778  31  46  20  33  14   5   9]\n",
            " [ 27   2 122 557  50 118  53  46  15  10]\n",
            " [ 23   1  80  32 772  12  33  42   5   0]\n",
            " [ 15   2  83 112  41 675  15  51   2   4]\n",
            " [  8   0  74  36  27   9 830   8   4   4]\n",
            " [ 21   1  53  21  53  21   4 819   3   4]\n",
            " [ 78   7  11   7   3   1   6   3 868  16]\n",
            " [ 31  43   9   4   5   4   7   6  20 871]]\n",
            "Epoch 18/200 - Train Loss: 0.5993, Val Loss: 0.6262, Val Accuracy: 79.01%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6383\n",
            "Accuracy: 78.58%\n",
            "F1 Score: 0.7841\n",
            "Confusion Matrix:\n",
            "[[870  19  31   6   6   1   4  10  29  24]\n",
            " [ 12 919   4   4   0   2   4   1   4  50]\n",
            " [ 64   4 739  20  39  45  46  29   2  12]\n",
            " [ 26   6  98 539  42 166  47  36  12  28]\n",
            " [ 23   2  79  28 744  27  33  54   4   6]\n",
            " [ 13   4  59  97  29 710  11  59   6  12]\n",
            " [ 11   9  56  48  25  21 816   6   3   5]\n",
            " [ 18   2  31  20  40  31   2 841   2  13]\n",
            " [ 95  28  14   5   5   1   3   3 810  36]\n",
            " [ 33  58   8   5   1   3   4   5  13 870]]\n",
            "Epoch 19/200 - Train Loss: 0.5938, Val Loss: 0.6383, Val Accuracy: 78.58%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6448\n",
            "Accuracy: 77.92%\n",
            "F1 Score: 0.7802\n",
            "Confusion Matrix:\n",
            "[[818  12  37  30   9   5   8  11  39  31]\n",
            " [  6 924   6   5   0   7  10   2   8  32]\n",
            " [ 52   1 637  64  51  81  77  22   7   8]\n",
            " [ 10   5  51 633  28 195  40  26   7   5]\n",
            " [ 21   1  37  73 713  49  70  31   4   1]\n",
            " [  4   3  26 118  25 789   8  23   0   4]\n",
            " [  3   2  25  61  13  32 855   7   1   1]\n",
            " [  9   1  14  61  46  62   9 789   2   7]\n",
            " [ 88  30   4  27   2   9   6   2 807  25]\n",
            " [ 24  77   7  16   1   8   7  14  19 827]]\n",
            "Epoch 20/200 - Train Loss: 0.5885, Val Loss: 0.6448, Val Accuracy: 77.92%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6059\n",
            "Accuracy: 79.47%\n",
            "F1 Score: 0.7942\n",
            "Confusion Matrix:\n",
            "[[868   6  26   9  16   2   7   8  37  21]\n",
            " [ 15 920   2   1   1   1   2   2  11  45]\n",
            " [ 68   1 689  42  67  60  42  21   5   5]\n",
            " [ 36   3  52 598  52 156  42  37  14  10]\n",
            " [ 18   1  39  42 796  25  30  37   8   4]\n",
            " [ 22   0  29 144  36 716  11  34   3   5]\n",
            " [ 13   1  48  47  26  19 839   3   2   2]\n",
            " [ 24   2  26  37  47  33   4 819   0   8]\n",
            " [ 75  13   9   8   2   2   2   6 852  31]\n",
            " [ 40  65   5   6   1   4   1  11  17 850]]\n",
            "Epoch 21/200 - Train Loss: 0.5818, Val Loss: 0.6059, Val Accuracy: 79.47%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6118\n",
            "Accuracy: 79.11%\n",
            "F1 Score: 0.7903\n",
            "Confusion Matrix:\n",
            "[[815   9  34  27  12   4  12  16  35  36]\n",
            " [ 12 862   5   6   1   2   3   2  11  96]\n",
            " [ 58   4 677  56  68  50  52  23   4   8]\n",
            " [  8   7  44 607  43 140  84  46   6  15]\n",
            " [ 15   1  40  48 759  30  37  65   4   1]\n",
            " [  8   1  30 135  34 711  24  47   0  10]\n",
            " [  4   2  37  36  23  12 868  10   5   3]\n",
            " [ 11   3  13  30  29  45   5 855   0   9]\n",
            " [ 68  13   8  10   8   5   9   6 849  24]\n",
            " [ 16  34   3   8   1   3   5   9  13 908]]\n",
            "Epoch 22/200 - Train Loss: 0.5715, Val Loss: 0.6118, Val Accuracy: 79.11%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6094\n",
            "Accuracy: 79.21%\n",
            "F1 Score: 0.7935\n",
            "Confusion Matrix:\n",
            "[[887   9  24  17   5   1   6  11  27  13]\n",
            " [ 15 910   4   8   1   1   3   2  19  37]\n",
            " [ 67   1 722  54  47  37  33  26   9   4]\n",
            " [ 28   3  42 689  42 106  47  30   5   8]\n",
            " [ 27   1  54  69 750  24  32  37   5   1]\n",
            " [ 12   1  45 204  29 661  11  33   1   3]\n",
            " [ 11   2  46  66  24  14 822   6   8   1]\n",
            " [ 13   0  36  43  42  34   2 825   0   5]\n",
            " [115  15   9  16   4   0   4   2 819  16]\n",
            " [ 34  63   9  19   1   0   4  17  17 836]]\n",
            "Epoch 23/200 - Train Loss: 0.5667, Val Loss: 0.6094, Val Accuracy: 79.21%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6463\n",
            "Accuracy: 78.17%\n",
            "F1 Score: 0.7800\n",
            "Confusion Matrix:\n",
            "[[790  11  21  16  13   0  11   7  93  38]\n",
            " [ 10 902   3   4   1   0   4   0  23  53]\n",
            " [ 61   1 659  49  66  30  92  19  13  10]\n",
            " [ 19   9  59 629  45 100  81  15  24  19]\n",
            " [ 20   1  60  38 747  12  79  29   9   5]\n",
            " [ 10   3  53 170  42 637  39  30   4  12]\n",
            " [  9   1  29  36  19   2 898   0   6   0]\n",
            " [ 25   3  35  52  40  29  16 780   3  17]\n",
            " [ 28  15   3   7   2   1   4   3 908  29]\n",
            " [ 25  63   6   8   3   0   6   3  19 867]]\n",
            "Epoch 24/200 - Train Loss: 0.5559, Val Loss: 0.6463, Val Accuracy: 78.17%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6057\n",
            "Accuracy: 79.44%\n",
            "F1 Score: 0.7951\n",
            "Confusion Matrix:\n",
            "[[845  13  23  25  12   4   7  10  36  25]\n",
            " [ 15 902   2   6   1   3   6   1   9  55]\n",
            " [ 55   1 679  60  47  64  64  19   5   6]\n",
            " [ 23   6  28 680  36 122  59  28   9   9]\n",
            " [ 10   0  40  66 713  41  77  42   9   2]\n",
            " [  8   4  24 170  19 725  15  29   1   5]\n",
            " [  8   0  20  55   8  23 878   5   2   1]\n",
            " [ 13   2  13  49  31  42  13 826   0  11]\n",
            " [ 77  18  12  13   2   4   8   3 842  21]\n",
            " [ 34  51   5  16   4   4   6   8  18 854]]\n",
            "Epoch 25/200 - Train Loss: 0.5474, Val Loss: 0.6057, Val Accuracy: 79.44%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5841\n",
            "Accuracy: 79.98%\n",
            "F1 Score: 0.7997\n",
            "Confusion Matrix:\n",
            "[[800  19  46  16   5   0   7  17  56  34]\n",
            " [  4 912   3   2   2   2   6   1  10  58]\n",
            " [ 33   3 728  50  60  38  62  16   4   6]\n",
            " [  9   6  58 688  46  77  61  30  11  14]\n",
            " [  9   0  47  58 757  19  48  55   7   0]\n",
            " [ 10   2  46 216  22 636  16  47   0   5]\n",
            " [  8   2  28  50  18   8 876   6   3   1]\n",
            " [  7   0  21  47  28  27   9 853   1   7]\n",
            " [ 42  22  13  18   0   2   8   3 871  21]\n",
            " [ 21  54   6   5   3   0   4   4  26 877]]\n",
            "Epoch 26/200 - Train Loss: 0.5417, Val Loss: 0.5841, Val Accuracy: 79.98%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5977\n",
            "Accuracy: 80.18%\n",
            "F1 Score: 0.8006\n",
            "Confusion Matrix:\n",
            "[[808  10  34  15   8   3  10   7  66  39]\n",
            " [ 13 877   2   5   1   3   2   0  26  71]\n",
            " [ 54   0 704  37  67  35  72  11   8  12]\n",
            " [ 12   7  45 648  55  94  64  35  20  20]\n",
            " [ 15   0  30  36 817  12  43  35   9   3]\n",
            " [  9   1  47 159  45 672  19  33   5  10]\n",
            " [  7   2  30  42  15   8 882   3   8   3]\n",
            " [ 13   3  30  29  47  31   9 821   4  13]\n",
            " [ 49  10   5   5   4   1   7   3 893  23]\n",
            " [ 15  38   3   4   3   1   5   7  28 896]]\n",
            "Epoch 27/200 - Train Loss: 0.5465, Val Loss: 0.5977, Val Accuracy: 80.18%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5992\n",
            "Accuracy: 79.85%\n",
            "F1 Score: 0.7988\n",
            "Confusion Matrix:\n",
            "[[821   9  26  21  11   2  10   8  47  45]\n",
            " [  8 866   1   8   1   2   4   0  22  88]\n",
            " [ 52   1 697  59  56  36  64  20   6   9]\n",
            " [ 21   2  39 706  44  84  67  19   7  11]\n",
            " [ 15   0  46  54 782  23  49  24   4   3]\n",
            " [ 15   4  30 191  33 655  28  32   3   9]\n",
            " [ 10   1  25  40  23   8 881   5   4   3]\n",
            " [ 12   4  18  64  45  32   7 803   0  15]\n",
            " [ 61  13   5  20   1   0   4   5 863  28]\n",
            " [ 10  31   2  13   4   0   5   9  15 911]]\n",
            "Epoch 28/200 - Train Loss: 0.5316, Val Loss: 0.5992, Val Accuracy: 79.85%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6008\n",
            "Accuracy: 79.50%\n",
            "F1 Score: 0.7938\n",
            "Confusion Matrix:\n",
            "[[887  11  35   9   5   0   4  12  20  17]\n",
            " [ 26 916   6   3   0   1   6   2   6  34]\n",
            " [ 64   1 788  24  40  17  33  28   2   3]\n",
            " [ 34   5 104 573  50  95  54  65  11   9]\n",
            " [ 17   0  68  29 768  17  23  73   4   1]\n",
            " [  9   1  96 125  32 632  18  84   2   1]\n",
            " [ 10   1  59  36  33  14 830  13   4   0]\n",
            " [ 14   1  30  23  12  19   4 892   1   4]\n",
            " [ 89  14   9   9   1   1   4   8 849  16]\n",
            " [ 34  72  13   6   5   2   6  26  21 815]]\n",
            "Epoch 29/200 - Train Loss: 0.5316, Val Loss: 0.6008, Val Accuracy: 79.50%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5835\n",
            "Accuracy: 80.84%\n",
            "F1 Score: 0.8081\n",
            "Confusion Matrix:\n",
            "[[879   5  25  14  13   3   7  13  33   8]\n",
            " [ 25 872   5   3   1   5   8   2  33  46]\n",
            " [ 53   0 713  40  63  40  66  13   9   3]\n",
            " [ 20   2  48 658  59  97  74  27  12   3]\n",
            " [ 11   0  30  50 804  11  57  32   5   0]\n",
            " [  8   0  32 139  46 718  31  21   5   0]\n",
            " [  8   0  24  25  21   7 908   5   2   0]\n",
            " [  8   0  23  33  52  35  11 830   4   4]\n",
            " [ 70   5   6   9   2   0   5   3 889  11]\n",
            " [ 44  51   7  13   5   6  12  20  29 813]]\n",
            "Epoch 30/200 - Train Loss: 0.5256, Val Loss: 0.5835, Val Accuracy: 80.84%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5931\n",
            "Accuracy: 79.79%\n",
            "F1 Score: 0.7963\n",
            "Confusion Matrix:\n",
            "[[853  13  27   9  13   2  11  10  34  28]\n",
            " [ 12 938   1   3   0   1   4   0   9  32]\n",
            " [ 66   4 690  36  60  33  86  15   6   4]\n",
            " [ 20   7  54 607  54 103 107  34   9   5]\n",
            " [ 14   2  33  30 804  16  76  23   2   0]\n",
            " [  4   5  51 155  42 666  42  29   3   3]\n",
            " [  8   0  32  19  16   4 915   4   2   0]\n",
            " [ 13   1  26  28  86  30  10 800   1   5]\n",
            " [ 51  23   5   9   5   0   7   3 875  22]\n",
            " [ 27  78   4   8   2   2  13  15  20 831]]\n",
            "Epoch 31/200 - Train Loss: 0.5234, Val Loss: 0.5931, Val Accuracy: 79.79%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5696\n",
            "Accuracy: 80.86%\n",
            "F1 Score: 0.8076\n",
            "Confusion Matrix:\n",
            "[[876   7  17  12  10   1   2  13  42  20]\n",
            " [ 15 878   2   2   2   2   2   3  35  59]\n",
            " [ 78   0 737  32  53  39  24  20  10   7]\n",
            " [ 25   2  55 627  58 119  36  39  23  16]\n",
            " [ 20   2  59  31 776  20  32  54   3   3]\n",
            " [ 14   0  32 126  41 712  11  54   5   5]\n",
            " [ 13   0  55  43  22  15 828   6  14   4]\n",
            " [ 15   1  15  17  34  32   2 875   3   6]\n",
            " [ 66   5   3   2   3   3   3   3 900  12]\n",
            " [ 32  41   2   5   3   0   4  10  26 877]]\n",
            "Epoch 32/200 - Train Loss: 0.5205, Val Loss: 0.5696, Val Accuracy: 80.86%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5836\n",
            "Accuracy: 80.63%\n",
            "F1 Score: 0.8063\n",
            "Confusion Matrix:\n",
            "[[862   5  16  15   2   0   4  13  59  24]\n",
            " [ 10 917   2   2   2   0   0   0  11  56]\n",
            " [ 79   3 724  62  37  30  26  18  12   9]\n",
            " [ 28   5  49 706  36  70  32  27  25  22]\n",
            " [ 38   0  42  61 742  28  25  55   6   3]\n",
            " [ 17   2  38 202  22 651  12  39  12   5]\n",
            " [ 14   4  45  61  18   9 829   5  12   3]\n",
            " [ 27   0  22  42  14  25   4 851   3  12]\n",
            " [ 44  15   2   5   1   0   2   1 909  21]\n",
            " [ 33  49   5  10   0   0   2   5  24 872]]\n",
            "Epoch 33/200 - Train Loss: 0.5117, Val Loss: 0.5836, Val Accuracy: 80.63%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5656\n",
            "Accuracy: 80.54%\n",
            "F1 Score: 0.8062\n",
            "Confusion Matrix:\n",
            "[[829   9  37  18  11   0   2   9  60  25]\n",
            " [ 12 873   2   5   1   2   5   1  22  77]\n",
            " [ 43   0 740  58  67  33  38   9   3   9]\n",
            " [ 17   5  44 706  54  83  44  22  16   9]\n",
            " [ 12   0  39  56 812  16  28  25   7   5]\n",
            " [  9   3  38 213  35 648  18  29   5   2]\n",
            " [  5   3  41  58  26   9 843   4   6   5]\n",
            " [ 15   1  22  49  40  36   3 820   2  12]\n",
            " [ 44  10   6  16   4   0   2   2 900  16]\n",
            " [ 17  30   3  11   4   0   6   5  41 883]]\n",
            "Epoch 34/200 - Train Loss: 0.5067, Val Loss: 0.5656, Val Accuracy: 80.54%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5624\n",
            "Accuracy: 80.81%\n",
            "F1 Score: 0.8085\n",
            "Confusion Matrix:\n",
            "[[815  18  22  17  11   1  10   8  66  32]\n",
            " [  8 921   3   3   1   2   2   1  14  45]\n",
            " [ 69   2 708  63  52  29  42  12  13  10]\n",
            " [ 12   6  49 730  36  79  41  17  16  14]\n",
            " [ 16   2  48  64 787  16  36  26   3   2]\n",
            " [ 12   6  39 204  32 658  18  24   1   6]\n",
            " [  7   0  34  66   9   4 874   1   5   0]\n",
            " [ 26   1  16  53  33  32   3 818   2  16]\n",
            " [ 38  14   4  13   3   1   3   3 901  20]\n",
            " [ 26  62   5   6   1   2   5   3  21 869]]\n",
            "Epoch 35/200 - Train Loss: 0.5089, Val Loss: 0.5624, Val Accuracy: 80.81%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5924\n",
            "Accuracy: 79.88%\n",
            "F1 Score: 0.7980\n",
            "Confusion Matrix:\n",
            "[[800   9  48  25  15   2   9  12  56  24]\n",
            " [ 11 895   5   6   0   0   5   1  17  60]\n",
            " [ 46   2 728  36  56  20  77  18   9   8]\n",
            " [ 16   4  55 660  54  72  89  21  15  14]\n",
            " [  9   0  42  43 802  11  57  29   5   2]\n",
            " [  8   2  59 193  54 617  31  28   3   5]\n",
            " [  3   0  29  30  18   2 909   4   4   1]\n",
            " [ 14   1  32  36  53  27  14 808   1  14]\n",
            " [ 50   8   5  13   3   1   4   2 891  23]\n",
            " [ 22  44   4  11   3   1   6   6  25 878]]\n",
            "Epoch 36/200 - Train Loss: 0.4985, Val Loss: 0.5924, Val Accuracy: 79.88%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5877\n",
            "Accuracy: 80.85%\n",
            "F1 Score: 0.8078\n",
            "Confusion Matrix:\n",
            "[[846  20  32  11  13   3   5  10  21  39]\n",
            " [  6 916   5   1   0   1   5   1   8  57]\n",
            " [ 64   1 727  38  53  34  53  16   4  10]\n",
            " [ 18   7  50 667  49  88  62  37   7  15]\n",
            " [ 16   2  54  51 773  17  45  31   4   7]\n",
            " [ 10   6  31 164  34 687  24  34   1   9]\n",
            " [  6   1  34  31  11  10 897   4   5   1]\n",
            " [  6   3  22  46  26  32   7 846   1  11]\n",
            " [ 77  23   4  10   5   2   8   3 827  41]\n",
            " [ 13  51   4   7   3   1   7   4  11 899]]\n",
            "Epoch 37/200 - Train Loss: 0.4980, Val Loss: 0.5877, Val Accuracy: 80.85%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5877\n",
            "Accuracy: 80.26%\n",
            "F1 Score: 0.8018\n",
            "Confusion Matrix:\n",
            "[[810   8  32  15  11   1   6  23  62  32]\n",
            " [ 12 881   6   4   1   0   3   2  17  74]\n",
            " [ 46   1 722  38  48  50  49  30  11   5]\n",
            " [ 15   1  49 601  34 178  60  36  13  13]\n",
            " [ 12   0  61  53 748  31  39  48   8   0]\n",
            " [  7   2  30 102  30 759  20  44   4   2]\n",
            " [  6   1  41  43  22  24 850  10   2   1]\n",
            " [  9   1  19  28  20  40   4 872   0   7]\n",
            " [ 40  11   7  11   2   3   8   2 892  24]\n",
            " [ 23  32   3  10   4   2   3  11  21 891]]\n",
            "Epoch 38/200 - Train Loss: 0.4964, Val Loss: 0.5877, Val Accuracy: 80.26%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5792\n",
            "Accuracy: 80.91%\n",
            "F1 Score: 0.8091\n",
            "Confusion Matrix:\n",
            "[[803  14  24  18  18   4   6   9  68  36]\n",
            " [  4 904   1   6   0   3   4   1  17  60]\n",
            " [ 42   2 688  60  65  56  57  15   6   9]\n",
            " [ 16   2  41 682  51 113  52  20  12  11]\n",
            " [  8   1  29  59 824  11  34  26   5   3]\n",
            " [  3   2  23 156  46 717  23  25   2   3]\n",
            " [  8   1  24  40  31   8 880   4   4   0]\n",
            " [ 12   2  14  41  55  44   8 813   4   7]\n",
            " [ 35  16   3   9   4   2   8   3 893  27]\n",
            " [ 18  47   3  13   2   2   3   9  16 887]]\n",
            "Epoch 39/200 - Train Loss: 0.4944, Val Loss: 0.5792, Val Accuracy: 80.91%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5544\n",
            "Accuracy: 81.67%\n",
            "F1 Score: 0.8158\n",
            "Confusion Matrix:\n",
            "[[837  12  30  10  19   0   9   7  58  18]\n",
            " [  9 920   1   3   0   3   5   0  20  39]\n",
            " [ 62   2 713  47  57  40  45  24   5   5]\n",
            " [ 17   3  55 639  53 136  42  36  10   9]\n",
            " [ 14   4  37  32 816  24  37  32   3   1]\n",
            " [  9   6  33 122  34 751  14  27   1   3]\n",
            " [  4   4  28  37  25  17 874   8   3   0]\n",
            " [ 14   1  17  26  33  45   6 850   2   6]\n",
            " [ 41  13   6   9   1   2   4   2 908  14]\n",
            " [ 22  54   4   8   4   6   8   7  28 859]]\n",
            "Epoch 40/200 - Train Loss: 0.4860, Val Loss: 0.5544, Val Accuracy: 81.67%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5687\n",
            "Accuracy: 81.52%\n",
            "F1 Score: 0.8147\n",
            "Confusion Matrix:\n",
            "[[850   6  23  16  10   2   4  14  49  26]\n",
            " [ 12 897   1   4   1   1   1   0  14  69]\n",
            " [ 49   2 729  43  70  43  30  16   6  12]\n",
            " [ 15   7  46 655  68 110  30  35  16  18]\n",
            " [ 18   2  26  34 821  21  15  52   7   4]\n",
            " [  8   5  29 141  33 719   9  42   3  11]\n",
            " [  9   4  34  50  58  16 815   7   3   4]\n",
            " [ 15   1  12  30  22  30   3 877   1   9]\n",
            " [ 54  16   2   8   3   3   2   2 883  27]\n",
            " [ 22  30   4   9   2   1   1   4  21 906]]\n",
            "Epoch 41/200 - Train Loss: 0.4824, Val Loss: 0.5687, Val Accuracy: 81.52%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5586\n",
            "Accuracy: 81.23%\n",
            "F1 Score: 0.8112\n",
            "Confusion Matrix:\n",
            "[[851   8  44   5   7   0  10  15  42  18]\n",
            " [ 10 927   4   2   0   3  10   1  14  29]\n",
            " [ 46   0 781  26  31  25  58  27   2   4]\n",
            " [ 19   2  70 625  54 109  52  53  12   4]\n",
            " [ 13   0  59  35 762  12  57  60   2   0]\n",
            " [  9   1  45 128  36 708  20  49   3   1]\n",
            " [  6   0  38  28  13   8 897   7   3   0]\n",
            " [ 11   2  26  23  29  25   6 871   4   3]\n",
            " [ 59  10   8   9   3   0   5   9 883  14]\n",
            " [ 36  67  10  12   1   1  10  15  30 818]]\n",
            "Epoch 42/200 - Train Loss: 0.4824, Val Loss: 0.5586, Val Accuracy: 81.23%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5486\n",
            "Accuracy: 81.83%\n",
            "F1 Score: 0.8174\n",
            "Confusion Matrix:\n",
            "[[859  10  22  17   6   2   7  10  49  18]\n",
            " [ 13 893   1   2   0   2   2   2  21  64]\n",
            " [ 52   1 746  31  45  38  52  16   7  12]\n",
            " [ 17   6  49 633  54 133  56  23  18  11]\n",
            " [ 21   1  38  38 791  14  49  37   7   4]\n",
            " [  8   2  37 126  30 739  17  28   4   9]\n",
            " [  9   3  26  40   9  12 892   4   3   2]\n",
            " [ 13   1  21  35  38  37   4 835   5  11]\n",
            " [ 43  12   7   8   2   3   5   2 903  15]\n",
            " [ 36  31   3   9   0   1   4   0  24 892]]\n",
            "Epoch 43/200 - Train Loss: 0.4768, Val Loss: 0.5486, Val Accuracy: 81.83%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5527\n",
            "Accuracy: 81.52%\n",
            "F1 Score: 0.8142\n",
            "Confusion Matrix:\n",
            "[[828   6  40  12  19   1   5  11  55  23]\n",
            " [ 15 895   1   4   2   1   3   2  28  49]\n",
            " [ 44   0 733  45  71  28  49  20   5   5]\n",
            " [ 11   1  59 636  68  98  57  33  21  16]\n",
            " [  8   3  25  31 847  18  24  35   5   4]\n",
            " [  3   2  41 132  54 702  19  36   3   8]\n",
            " [  7   1  19  45  43  11 863   7   2   2]\n",
            " [ 13   0  24  21  30  31   6 866   2   7]\n",
            " [ 51   9   6   8   2   1   4   3 904  12]\n",
            " [ 21  51   7   4   3   0   4   6  26 878]]\n",
            "Epoch 44/200 - Train Loss: 0.4758, Val Loss: 0.5527, Val Accuracy: 81.52%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5678\n",
            "Accuracy: 81.53%\n",
            "F1 Score: 0.8148\n",
            "Confusion Matrix:\n",
            "[[835  16  25  19   9   0   3   8  44  41]\n",
            " [  4 938   0   2   2   3   1   0   8  42]\n",
            " [ 55   5 705  66  59  23  36  24  12  15]\n",
            " [ 17  10  47 680  59  98  26  30  12  21]\n",
            " [ 11   4  32  50 816  14  18  45   5   5]\n",
            " [  8   7  48 133  34 707  10  43   2   8]\n",
            " [ 11   8  36  57  35  11 827   2   7   6]\n",
            " [ 12   3  13  46  25  30   0 849   4  18]\n",
            " [ 49  22   9   7   2   1   2   0 885  23]\n",
            " [  6  54   3   5   1   2   2   2  14 911]]\n",
            "Epoch 45/200 - Train Loss: 0.4719, Val Loss: 0.5678, Val Accuracy: 81.53%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5743\n",
            "Accuracy: 81.15%\n",
            "F1 Score: 0.8108\n",
            "Confusion Matrix:\n",
            "[[829  12  27  18  10   3   4   8  53  36]\n",
            " [  7 920   4   2   1   2   1   1   7  55]\n",
            " [ 56   3 717  50  44  54  34  25   6  11]\n",
            " [ 14   8  33 648  50 142  39  31  14  21]\n",
            " [ 11   2  36  49 763  26  25  79   7   2]\n",
            " [  3   2  19 122  26 763  12  37   5  11]\n",
            " [ 14   6  33  40  27  16 842  11   6   5]\n",
            " [ 11   0  13  31  11  37   4 878   1  14]\n",
            " [ 55  23   7   8   0   3   2   4 867  31]\n",
            " [ 15  49   3   8   3   2   4   5  23 888]]\n",
            "Epoch 46/200 - Train Loss: 0.4720, Val Loss: 0.5743, Val Accuracy: 81.15%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5634\n",
            "Accuracy: 81.43%\n",
            "F1 Score: 0.8126\n",
            "Confusion Matrix:\n",
            "[[839  11  28  13  11   2   4  14  53  25]\n",
            " [  4 931   4   1   1   2   9   3  16  29]\n",
            " [ 45   0 744  35  50  33  59  24   7   3]\n",
            " [ 12   4  53 622  45 120  87  38  11   8]\n",
            " [ 13   1  37  40 783  16  52  55   3   0]\n",
            " [  7   4  45 142  27 702  19  50   0   4]\n",
            " [  6   3  28  21  20   7 899   9   6   1]\n",
            " [ 13   1  18  24  28  20   5 885   1   5]\n",
            " [ 46  20   5   5   2   0   5   5 896  16]\n",
            " [ 18  77   5   9   1   2   6  10  30 842]]\n",
            "Epoch 47/200 - Train Loss: 0.4689, Val Loss: 0.5634, Val Accuracy: 81.43%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5609\n",
            "Accuracy: 81.74%\n",
            "F1 Score: 0.8164\n",
            "Confusion Matrix:\n",
            "[[857  11  28  11  13   4  11  18  26  21]\n",
            " [ 11 922   4   1   0   3   3   2   5  49]\n",
            " [ 55   0 716  29  46  47  76  22   2   7]\n",
            " [ 18   3  38 647  45 111  88  32   6  12]\n",
            " [  6   1  31  35 785  10  79  47   3   3]\n",
            " [  7   0  31 140  39 727  20  30   1   5]\n",
            " [  7   1  19  23  14  10 916   7   1   2]\n",
            " [  9   1  22  26  27  31  17 862   0   5]\n",
            " [ 72  27   7  11   1   1   3   3 850  25]\n",
            " [ 19  43   4   9   3   2   6   8  14 892]]\n",
            "Epoch 48/200 - Train Loss: 0.4697, Val Loss: 0.5609, Val Accuracy: 81.74%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5873\n",
            "Accuracy: 80.89%\n",
            "F1 Score: 0.8077\n",
            "Confusion Matrix:\n",
            "[[840  12  36  14   5   0   6   6  48  33]\n",
            " [ 14 928   5   2   0   0   4   0   9  38]\n",
            " [ 52   5 772  25  32  23  63  14   7   7]\n",
            " [ 20  12  94 621  33  91  77  18  22  12]\n",
            " [ 15   0  67  41 746  14  72  31   9   5]\n",
            " [  8   6  73 130  33 681  25  29   7   8]\n",
            " [ 11   4  37  27   5   8 904   1   2   1]\n",
            " [ 26   3  42  33  25  25  16 812   2  16]\n",
            " [ 44  18  10   4   0   1   7   2 903  11]\n",
            " [ 22  53   9   4   0   0   4   5  21 882]]\n",
            "Epoch 49/200 - Train Loss: 0.4624, Val Loss: 0.5873, Val Accuracy: 80.89%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5752\n",
            "Accuracy: 81.08%\n",
            "F1 Score: 0.8104\n",
            "Confusion Matrix:\n",
            "[[830  20  25  17   3   3  12   6  49  35]\n",
            " [  7 934   3   4   1   0   4   1  11  35]\n",
            " [ 49   5 716  58  32  44  62  13   7  14]\n",
            " [ 12   7  42 705  40 106  44  18  11  15]\n",
            " [ 27   6  48  47 775  17  50  23   5   2]\n",
            " [ 12   3  32 165  43 694  20  20   5   6]\n",
            " [  3   4  28  34  22  14 890   2   1   2]\n",
            " [ 19   1  22  53  34  45   9 790   2  25]\n",
            " [ 47  22   5   9   1   0   7   1 886  22]\n",
            " [ 15  65   3   5   0   2   2   1  19 888]]\n",
            "Epoch 50/200 - Train Loss: 0.4616, Val Loss: 0.5752, Val Accuracy: 81.08%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5591\n",
            "Accuracy: 82.27%\n",
            "F1 Score: 0.8228\n",
            "Confusion Matrix:\n",
            "[[834  13  35  29  10   2   5  14  28  30]\n",
            " [  7 926   5   7   1   2   3   2   3  44]\n",
            " [ 56   3 735  52  43  33  45  28   3   2]\n",
            " [  7   2  38 721  46  90  47  39   6   4]\n",
            " [  9   0  31  34 829  19  44  31   2   1]\n",
            " [  6   2  29 155  38 707  11  48   3   1]\n",
            " [  4   3  29  52  16  13 875   6   2   0]\n",
            " [  8   0  13  35  31  19   5 879   3   7]\n",
            " [ 46  28   8  15   4   1   6  10 853  29]\n",
            " [ 14  66   5  15   1   2   3   9  17 868]]\n",
            "Epoch 51/200 - Train Loss: 0.4617, Val Loss: 0.5591, Val Accuracy: 82.27%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5585\n",
            "Accuracy: 81.57%\n",
            "F1 Score: 0.8142\n",
            "Confusion Matrix:\n",
            "[[825  12  27  17   6   1   6  11  69  26]\n",
            " [ 12 907   1   1   0   2   4   1  17  55]\n",
            " [ 45   0 674  58  73  54  49  23  14  10]\n",
            " [ 15   6  31 616  66 145  47  31  29  14]\n",
            " [ 10   1  27  34 826  20  29  45   6   2]\n",
            " [ 10   2  21 108  37 771  11  29   8   3]\n",
            " [ 10   2  22  35  28  13 875   7   7   1]\n",
            " [ 15   0  12  30  31  50   3 849   1   9]\n",
            " [ 36  13   2   8   3   1   3   2 919  13]\n",
            " [ 20  36   3   6   2   0   0   8  30 895]]\n",
            "Epoch 52/200 - Train Loss: 0.4643, Val Loss: 0.5585, Val Accuracy: 81.57%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5698\n",
            "Accuracy: 81.16%\n",
            "F1 Score: 0.8122\n",
            "Confusion Matrix:\n",
            "[[915  13  14   8   7   1   0   3  21  18]\n",
            " [  7 933   2   3   0   0   0   0  10  45]\n",
            " [ 91   3 734  52  38  36  19  15   7   5]\n",
            " [ 32   7  57 685  32 114  36  20   9   8]\n",
            " [ 24   2  50  50 780  34  20  33   5   2]\n",
            " [ 10   8  38 163  19 719  11  24   3   5]\n",
            " [ 11   7  50  41  19  18 842   4   4   4]\n",
            " [ 22   3  23  53  27  54   1 804   1  12]\n",
            " [ 91  24   5   6   1   0   1   2 848  22]\n",
            " [ 37  78   4   6   1   1   2   2  13 856]]\n",
            "Epoch 53/200 - Train Loss: 0.4513, Val Loss: 0.5698, Val Accuracy: 81.16%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5608\n",
            "Accuracy: 81.37%\n",
            "F1 Score: 0.8129\n",
            "Confusion Matrix:\n",
            "[[790  14  38  20  13   3   8  17  57  40]\n",
            " [  6 906   1   2   1   3   6   1  15  59]\n",
            " [ 43   1 682  57  56  57  66  21  12   5]\n",
            " [ 17   3  26 611  52 203  44  22  10  12]\n",
            " [  5   1  29  40 832  33  34  22   3   1]\n",
            " [  4   2  16  85  41 809  13  24   1   5]\n",
            " [  2   1  17  44  20  19 886   5   3   3]\n",
            " [  9   0  16  22  48  67   4 822   2  10]\n",
            " [ 37  14   4   9   3   2   4   4 898  25]\n",
            " [ 12  41   3  10   2   2   6   4  19 901]]\n",
            "Epoch 54/200 - Train Loss: 0.4515, Val Loss: 0.5608, Val Accuracy: 81.37%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5679\n",
            "Accuracy: 81.29%\n",
            "F1 Score: 0.8130\n",
            "Confusion Matrix:\n",
            "[[849   6  16  20  14   0   8  12  41  34]\n",
            " [ 12 862   2   1   1   4   2   2  16  98]\n",
            " [ 65   0 709  63  52  27  52  16   6  10]\n",
            " [ 21   3  40 710  58  62  49  30  13  14]\n",
            " [ 12   0  28  47 811  15  47  34   2   4]\n",
            " [ 16   4  22 202  40 661  18  30   1   6]\n",
            " [  9   1  14  50  19  10 889   2   2   4]\n",
            " [ 13   1  16  49  36  21   7 838   2  17]\n",
            " [ 70  11   5   9   3   0   4   3 865  30]\n",
            " [ 18  18   5   6   0   1   4   1  12 935]]\n",
            "Epoch 55/200 - Train Loss: 0.4531, Val Loss: 0.5679, Val Accuracy: 81.29%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5580\n",
            "Accuracy: 81.67%\n",
            "F1 Score: 0.8163\n",
            "Confusion Matrix:\n",
            "[[815   9  28  22  13   0   3  12  69  29]\n",
            " [ 10 895   2   4   1   0   4   1  10  73]\n",
            " [ 49   0 725  53  50  30  53  18  12  10]\n",
            " [  8   3  45 710  44  88  42  38   7  15]\n",
            " [  9   2  26  50 770  19  48  65   8   3]\n",
            " [  2   2  29 182  35 680  14  47   3   6]\n",
            " [  8   2  25  48  14  12 883   1   4   3]\n",
            " [  7   5   8  34  16  38   7 876   1   8]\n",
            " [ 29  12   2  16   1   0   3   3 912  22]\n",
            " [ 11  39   5  10   1   0   1   8  24 901]]\n",
            "Epoch 56/200 - Train Loss: 0.4483, Val Loss: 0.5580, Val Accuracy: 81.67%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5397\n",
            "Accuracy: 81.80%\n",
            "F1 Score: 0.8177\n",
            "Confusion Matrix:\n",
            "[[849  10  21  15  13   1   4  16  40  31]\n",
            " [  9 879   0   5   0   3   4   1  10  89]\n",
            " [ 58   1 682  72  61  41  52  18   7   8]\n",
            " [ 11   4  29 677  52 127  45  33   7  15]\n",
            " [ 16   1  27  44 801  22  48  35   5   1]\n",
            " [  6   1  19 138  35 744  12  35   2   8]\n",
            " [  5   0  14  50  22  13 886   5   2   3]\n",
            " [ 12   1  10  28  39  34   6 855   2  13]\n",
            " [ 51   9   1  12   3   1   2   3 891  27]\n",
            " [ 12  28   1   9   1   0   6   7  20 916]]\n",
            "Epoch 57/200 - Train Loss: 0.4482, Val Loss: 0.5397, Val Accuracy: 81.80%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5774\n",
            "Accuracy: 81.55%\n",
            "F1 Score: 0.8138\n",
            "Confusion Matrix:\n",
            "[[860  15  48   6  10   2   5   9  22  23]\n",
            " [  6 941   2   1   0   0   4   0  10  36]\n",
            " [ 50   5 782  22  42  26  45  16   4   8]\n",
            " [ 16   9  74 602  50 114  82  33   6  14]\n",
            " [ 12   3  52  22 802  15  49  40   2   3]\n",
            " [  8   7  56 121  37 701  24  34   4   8]\n",
            " [  7   2  36  24  16   4 904   6   1   0]\n",
            " [ 21   1  29  20  33  26   7 857   0   6]\n",
            " [ 66  34   7  17   1   1   7   4 843  20]\n",
            " [ 23  74   6   5   1   1   9   7  11 863]]\n",
            "Epoch 58/200 - Train Loss: 0.4418, Val Loss: 0.5774, Val Accuracy: 81.55%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5478\n",
            "Accuracy: 82.30%\n",
            "F1 Score: 0.8215\n",
            "Confusion Matrix:\n",
            "[[841  16  18  14   7   4   7  17  55  21]\n",
            " [  5 929   0   3   2   2   1   2   9  47]\n",
            " [ 57   2 679  37  56  63  75  14  12   5]\n",
            " [  9   4  36 614  43 185  66  19  11  13]\n",
            " [ 15   2  24  33 810  41  41  26   5   3]\n",
            " [  6   4  24  83  34 806  17  21   1   4]\n",
            " [  3   3  14  27  17  11 912   3   6   4]\n",
            " [  9   1   8  29  41  52   4 850   2   4]\n",
            " [ 40  19   4  14   2   0   5   2 895  19]\n",
            " [ 12  43   3   9   2   2   5  10  20 894]]\n",
            "Epoch 59/200 - Train Loss: 0.4477, Val Loss: 0.5478, Val Accuracy: 82.30%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5540\n",
            "Accuracy: 81.91%\n",
            "F1 Score: 0.8185\n",
            "Confusion Matrix:\n",
            "[[847  13  23  10  13   5   9  10  44  26]\n",
            " [ 12 923   3   6   0   0   2   1   7  46]\n",
            " [ 53   1 656  62  81  47  68  20   4   8]\n",
            " [ 15   7  25 685  66 111  44  26  11  10]\n",
            " [  7   3  17  39 848  28  31  25   2   0]\n",
            " [  8   4  15 125  46 763  11  24   0   4]\n",
            " [  7   4  18  53  33  18 859   6   2   0]\n",
            " [  9   1  12  30  52  44   4 842   0   6]\n",
            " [ 43  22   2   9   4   0   2   5 901  12]\n",
            " [ 20  65   1   6   3   3   3   7  25 867]]\n",
            "Epoch 60/200 - Train Loss: 0.4363, Val Loss: 0.5540, Val Accuracy: 81.91%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5273\n",
            "Accuracy: 82.65%\n",
            "F1 Score: 0.8275\n",
            "Confusion Matrix:\n",
            "[[859   9  18  21   5   5   4  11  50  18]\n",
            " [ 17 909   2   3   0   3   3   1  15  47]\n",
            " [ 60   3 741  63  29  41  32  20   6   5]\n",
            " [ 17   2  32 729  32 122  30  23   9   4]\n",
            " [ 21   2  34  62 783  19  29  40  10   0]\n",
            " [  8   1  27 158  21 751   4  25   1   4]\n",
            " [  9   1  37  53  20  10 861   2   4   3]\n",
            " [ 12   0  18  45  25  40   6 847   0   7]\n",
            " [ 46  12   2   6   0   3   1   4 912  14]\n",
            " [ 35  45   5  12   1   2   3   2  22 873]]\n",
            "Epoch 61/200 - Train Loss: 0.4375, Val Loss: 0.5273, Val Accuracy: 82.65%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5622\n",
            "Accuracy: 82.09%\n",
            "F1 Score: 0.8218\n",
            "Confusion Matrix:\n",
            "[[854   8  36  19  24   5   2  10  30  12]\n",
            " [ 16 906   1   3   2   2   3   1  15  51]\n",
            " [ 48   2 723  57  75  48  26  11   3   7]\n",
            " [ 21   2  36 677  63 144  17  23  10   7]\n",
            " [ 13   1  27  30 864  28   9  24   4   0]\n",
            " [  8   4  23 113  39 769   9  27   2   6]\n",
            " [  4   0  41  71  44  18 815   2   5   0]\n",
            " [  9   2  14  32  39  57   1 838   0   8]\n",
            " [ 60  13   5  11   5   3   3   2 875  23]\n",
            " [ 28  40   5   6   4   3   4   6  16 888]]\n",
            "Epoch 62/200 - Train Loss: 0.4439, Val Loss: 0.5622, Val Accuracy: 82.09%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5664\n",
            "Accuracy: 81.45%\n",
            "F1 Score: 0.8127\n",
            "Confusion Matrix:\n",
            "[[895   9  22   9   5   1   2   8  33  16]\n",
            " [ 11 920   3   3   2   0   4   1  11  45]\n",
            " [ 62   4 744  37  60  19  43  23   4   4]\n",
            " [ 45   5  52 633  83  74  45  39  11  13]\n",
            " [ 30   2  38  19 839  10  21  37   3   1]\n",
            " [ 16   4  41 176  65 621  19  51   6   1]\n",
            " [ 14   3  34  31  36   5 853   9  11   4]\n",
            " [ 18   1  13  28  33  15   7 876   0   9]\n",
            " [ 62  17   4   8   0   1   1   2 890  15]\n",
            " [ 32  54   2   4   3   0   4   5  22 874]]\n",
            "Epoch 63/200 - Train Loss: 0.4430, Val Loss: 0.5664, Val Accuracy: 81.45%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5428\n",
            "Accuracy: 82.05%\n",
            "F1 Score: 0.8201\n",
            "Confusion Matrix:\n",
            "[[866  10  22  10   8   1   7  12  45  19]\n",
            " [ 12 913   4   3   1   2   3   0  15  47]\n",
            " [ 51   2 780  36  35  30  36  16   8   6]\n",
            " [ 28   2  44 668  37 109  62  30  13   7]\n",
            " [ 17   1  56  49 763  20  53  38   3   0]\n",
            " [ 10   2  42 141  31 724  14  31   2   3]\n",
            " [ 10   1  36  28  15  10 890   2   5   3]\n",
            " [ 16   3  16  47  26  41   3 842   1   5]\n",
            " [ 57  10   2   7   2   0   2   2 900  18]\n",
            " [ 33  55   8  10   1   1   5  11  17 859]]\n",
            "Epoch 64/200 - Train Loss: 0.4378, Val Loss: 0.5428, Val Accuracy: 82.05%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5579\n",
            "Accuracy: 82.15%\n",
            "F1 Score: 0.8210\n",
            "Confusion Matrix:\n",
            "[[843  13  34  17  14   5   4  12  25  33]\n",
            " [ 12 900   0   1   2   2   3   1  10  69]\n",
            " [ 42   0 759  40  39  44  48  19   3   6]\n",
            " [ 17   5  56 617  45 171  52  22   6   9]\n",
            " [ 10   1  48  31 787  33  50  37   1   2]\n",
            " [  8   2  24  86  26 812  15  26   1   0]\n",
            " [  7   0  44  27  12  15 890   5   0   0]\n",
            " [ 10   1  20  21  29  51   6 855   0   7]\n",
            " [ 64  10   9  13   6   4   5   4 863  22]\n",
            " [ 20  39   5   9   3   4   3   9  19 889]]\n",
            "Epoch 65/200 - Train Loss: 0.4365, Val Loss: 0.5579, Val Accuracy: 82.15%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5642\n",
            "Accuracy: 81.88%\n",
            "F1 Score: 0.8197\n",
            "Confusion Matrix:\n",
            "[[806   6  36  26   7   3   6  12  78  20]\n",
            " [ 11 877   5   8   0   2   4   3  40  50]\n",
            " [ 40   0 731  58  46  51  35  26  10   3]\n",
            " [  9   3  39 716  24 123  42  25  11   8]\n",
            " [  8   1  37  69 750  32  45  50   7   1]\n",
            " [  5   1  25 135  25 773  10  23   2   1]\n",
            " [  5   2  30  62  11  21 859   4   3   3]\n",
            " [  7   0  15  33  14  63   5 857   2   4]\n",
            " [ 28   3   6  11   0   2   3   4 932  11]\n",
            " [ 13  37   5  18   0   1   2   8  29 887]]\n",
            "Epoch 66/200 - Train Loss: 0.4387, Val Loss: 0.5642, Val Accuracy: 81.88%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5755\n",
            "Accuracy: 81.37%\n",
            "F1 Score: 0.8142\n",
            "Confusion Matrix:\n",
            "[[877  10  17  17   2   1   0   3  45  28]\n",
            " [ 13 896   2   4   0   1   4   1  11  68]\n",
            " [ 68   1 757  48  31  28  38   9   6  14]\n",
            " [ 23   3  46 737  26  82  46  14  15   8]\n",
            " [ 27   1  44  84 715  34  58  28   6   3]\n",
            " [ 12   2  42 168  18 711  17  19   5   6]\n",
            " [  9   3  44  37   7  13 871   6   7   3]\n",
            " [ 18   2  25  50  41  46   8 790   2  18]\n",
            " [ 63  10   5  12   3   1   1   0 880  25]\n",
            " [ 18  38   7   8   0   0   4   3  19 903]]\n",
            "Epoch 67/200 - Train Loss: 0.4382, Val Loss: 0.5755, Val Accuracy: 81.37%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5510\n",
            "Accuracy: 82.21%\n",
            "F1 Score: 0.8210\n",
            "Confusion Matrix:\n",
            "[[866  11  33  13  10   2   2   6  41  16]\n",
            " [ 16 914   5   1   0   1   2   0  16  45]\n",
            " [ 51   3 784  26  44  33  27  23   5   4]\n",
            " [ 24   6  66 611  53 139  50  31  13   7]\n",
            " [ 14   0  49  27 822  18  24  37   5   4]\n",
            " [  9   1  43  96  37 753  20  34   3   4]\n",
            " [  6   2  43  26  46   8 855   8   5   1]\n",
            " [ 18   1  24  23  35  37   6 849   0   7]\n",
            " [ 55  17   6   3   3   3   3   2 900   8]\n",
            " [ 29  53   6   4   2   1   6   9  23 867]]\n",
            "Epoch 68/200 - Train Loss: 0.4341, Val Loss: 0.5510, Val Accuracy: 82.21%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5674\n",
            "Accuracy: 81.70%\n",
            "F1 Score: 0.8167\n",
            "Confusion Matrix:\n",
            "[[804   7  77  13  16   0   5   8  46  24]\n",
            " [ 17 858   7   6   2   2   4   2  27  75]\n",
            " [ 29   1 818  14  49  29  38  11   6   5]\n",
            " [ 14   1  78 612  70 129  42  35  15   4]\n",
            " [ 12   0  39  30 837  16  34  25   6   1]\n",
            " [  6   0  52 100  41 754  14  27   3   3]\n",
            " [  7   0  46  30  27   7 871   5   4   3]\n",
            " [ 12   2  28  25  59  41   4 819   2   8]\n",
            " [ 39   2  14  10   7   0   7   3 902  16]\n",
            " [ 22  33   9   7   3   4   5   6  16 895]]\n",
            "Epoch 69/200 - Train Loss: 0.4230, Val Loss: 0.5674, Val Accuracy: 81.70%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5342\n",
            "Accuracy: 82.13%\n",
            "F1 Score: 0.8207\n",
            "Confusion Matrix:\n",
            "[[880   8  18  17   6   0   4   8  50   9]\n",
            " [ 18 920   3   3   2   1   7   1  18  27]\n",
            " [ 51   1 766  36  51  28  32  26   6   3]\n",
            " [ 25   7  51 670  56  83  62  27  13   6]\n",
            " [ 18   3  46  32 825  13  32  26   5   0]\n",
            " [ 13   0  39 145  37 710  25  28   2   1]\n",
            " [ 10   1  52  28  16  10 875   4   4   0]\n",
            " [ 22   2  15  32  38  32   9 845   2   3]\n",
            " [ 43  16   6   8   3   1   4   3 909   7]\n",
            " [ 43  77   5  11   2   1   3  13  32 813]]\n",
            "Epoch 70/200 - Train Loss: 0.4285, Val Loss: 0.5342, Val Accuracy: 82.13%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5545\n",
            "Accuracy: 81.83%\n",
            "F1 Score: 0.8179\n",
            "Confusion Matrix:\n",
            "[[818  16  32  23  14   2   7   8  51  29]\n",
            " [  8 929   2   0   0   1   6   0  15  39]\n",
            " [ 42   3 744  47  50  34  50  12   9   9]\n",
            " [ 18   5  47 678  45 106  58  22   9  12]\n",
            " [ 12   3  27  54 811  16  49  24   4   0]\n",
            " [  7   0  47 142  41 708  25  27   0   3]\n",
            " [  8   1  27  35  15   6 901   3   2   2]\n",
            " [ 18   2  26  45  59  38   9 790   1  12]\n",
            " [ 33  15   6  11   1   0   8   1 904  21]\n",
            " [ 15  48   5   6   2   1   4   5  14 900]]\n",
            "Epoch 71/200 - Train Loss: 0.4220, Val Loss: 0.5545, Val Accuracy: 81.83%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5429\n",
            "Accuracy: 82.19%\n",
            "F1 Score: 0.8216\n",
            "Confusion Matrix:\n",
            "[[903  13  20   7   3   1   4  12  24  13]\n",
            " [ 12 941   2   1   1   0   2   2  10  29]\n",
            " [ 66   3 767  40  24  25  38  24   5   8]\n",
            " [ 27  10  59 702  35  72  50  30   8   7]\n",
            " [ 25   0  58  52 747  15  42  56   3   2]\n",
            " [ 16   5  37 177  18 677  14  47   3   6]\n",
            " [ 14   3  35  50  13   3 873   4   3   2]\n",
            " [ 12   2  20  41  14  16   3 887   0   5]\n",
            " [ 76  17   6  10   1   1   3   6 859  21]\n",
            " [ 29  69   2   8   0   0   5   5  19 863]]\n",
            "Epoch 72/200 - Train Loss: 0.4240, Val Loss: 0.5429, Val Accuracy: 82.19%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5397\n",
            "Accuracy: 82.53%\n",
            "F1 Score: 0.8255\n",
            "Confusion Matrix:\n",
            "[[873  12  23  24  13   2   2  13  23  15]\n",
            " [  9 922   1   8   0   1   7   0   6  46]\n",
            " [ 52   1 714  59  58  34  47  22   7   6]\n",
            " [  9   5  31 734  33  97  49  22  17   3]\n",
            " [ 13   2  21  41 831  17  36  37   1   1]\n",
            " [  7   2  29 179  39 692  13  33   1   5]\n",
            " [  8   4  28  43  19  10 884   1   2   1]\n",
            " [ 20   3  15  42  29  30   5 851   1   4]\n",
            " [ 68  12   8   8   0   1   9   6 876  12]\n",
            " [ 24  51   2   8   2   4   6   6  21 876]]\n",
            "Epoch 73/200 - Train Loss: 0.4228, Val Loss: 0.5397, Val Accuracy: 82.53%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5424\n",
            "Accuracy: 82.29%\n",
            "F1 Score: 0.8236\n",
            "Confusion Matrix:\n",
            "[[838  16  40  21   9   1   2  12  46  15]\n",
            " [  9 927   2   7   0   2   3   0  23  27]\n",
            " [ 38   0 794  45  43  31  17  21   7   4]\n",
            " [ 19   1  52 710  51  86  31  30  17   3]\n",
            " [ 14   2  43  49 807  17  24  40   2   2]\n",
            " [  3   3  47 160  40 702   9  33   2   1]\n",
            " [  7   2  53  60  22  13 830   5   7   1]\n",
            " [ 13   0  24  38  35  24   5 856   0   5]\n",
            " [ 42  13   6  13   3   2   1   4 907   9]\n",
            " [ 22  64   6   8   2   4   1   7  28 858]]\n",
            "Epoch 74/200 - Train Loss: 0.4261, Val Loss: 0.5424, Val Accuracy: 82.29%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5447\n",
            "Accuracy: 82.20%\n",
            "F1 Score: 0.8220\n",
            "Confusion Matrix:\n",
            "[[834  11  37  16  17   4   6  11  36  28]\n",
            " [ 11 911   5   3   1   0   4   1   9  55]\n",
            " [ 44   1 761  47  56  27  39  13   2  10]\n",
            " [ 15   5  49 681  57  91  53  29   6  14]\n",
            " [  5   2  37  42 834  10  31  37   2   0]\n",
            " [  9   1  43 157  39 702   9  35   0   5]\n",
            " [  7   1  29  43  21   7 883   6   3   0]\n",
            " [  6   0  30  43  30  24   7 850   2   8]\n",
            " [ 60  18   8   8   5   0   4   6 870  21]\n",
            " [ 14  48   4  13   2   1   7   5  12 894]]\n",
            "Epoch 75/200 - Train Loss: 0.4209, Val Loss: 0.5447, Val Accuracy: 82.20%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5587\n",
            "Accuracy: 82.10%\n",
            "F1 Score: 0.8206\n",
            "Confusion Matrix:\n",
            "[[841  12  29  10   9   1   6  12  49  31]\n",
            " [  8 903   3   2   2   1   3   0  14  64]\n",
            " [ 47   1 758  42  58  18  33  14  17  12]\n",
            " [ 18   6  42 725  69  54  37  21  14  14]\n",
            " [ 16   2  34  34 841  12  19  36   4   2]\n",
            " [  7   5  40 206  49 640  13  31   4   5]\n",
            " [ 11   0  48  42  37   5 844   1  10   2]\n",
            " [  7   5  23  41  24  23   5 864   2   6]\n",
            " [ 42   9   5   8   3   0   1   6 900  26]\n",
            " [ 15  44   6   4   0   2   5   5  25 894]]\n",
            "Epoch 76/200 - Train Loss: 0.4223, Val Loss: 0.5587, Val Accuracy: 82.10%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5566\n",
            "Accuracy: 81.90%\n",
            "F1 Score: 0.8177\n",
            "Confusion Matrix:\n",
            "[[843  10  52   6   9   6   5  12  28  29]\n",
            " [ 11 923   4   7   1   0   4   1   5  44]\n",
            " [ 29   0 807  20  41  41  30  25   3   4]\n",
            " [ 16   3  73 570  52 171  47  50   8  10]\n",
            " [ 15   1  47  30 804  17  32  50   4   0]\n",
            " [ 12   1  47  94  30 760  14  40   0   2]\n",
            " [  7   1  55  22  22  17 861  10   3   2]\n",
            " [  4   1  22  10  31  41   7 877   1   6]\n",
            " [ 68  23  14   9   2   6   7   3 850  18]\n",
            " [ 13  46   8   7   2   3   1  12  13 895]]\n",
            "Epoch 77/200 - Train Loss: 0.4165, Val Loss: 0.5566, Val Accuracy: 81.90%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5401\n",
            "Accuracy: 82.85%\n",
            "F1 Score: 0.8277\n",
            "Confusion Matrix:\n",
            "[[887  11  23   6   5   3   3   9  29  24]\n",
            " [ 15 915   3   2   0   1   2   1  13  48]\n",
            " [ 46   0 784  29  44  31  29  20   6  11]\n",
            " [ 26   5  61 623  63 123  44  19  17  19]\n",
            " [ 17   0  41  33 837  21  27  19   3   2]\n",
            " [ 11   1  42 112  37 757   9  22   3   6]\n",
            " [  8   2  45  45  19  19 853   0   6   3]\n",
            " [ 19   2  18  32  34  33   4 849   1   8]\n",
            " [ 77  18   5   5   1   1   4   2 869  18]\n",
            " [ 23  43   3   4   0   1   0   3  12 911]]\n",
            "Epoch 78/200 - Train Loss: 0.4143, Val Loss: 0.5401, Val Accuracy: 82.85%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5623\n",
            "Accuracy: 82.15%\n",
            "F1 Score: 0.8226\n",
            "Confusion Matrix:\n",
            "[[866  10  23  17   6   4   2   7  53  12]\n",
            " [ 22 906   0   9   2   0   1   1  25  34]\n",
            " [ 48   2 744  66  41  33  37  17   8   4]\n",
            " [ 21   5  38 758  37  66  39  26   7   3]\n",
            " [ 17   3  29  61 795  16  38  34   6   1]\n",
            " [  8   3  34 222  25 665  13  28   0   2]\n",
            " [  8   1  29  54  15   5 880   5   3   0]\n",
            " [ 15   0  15  55  32  27   8 847   1   0]\n",
            " [ 56   6   4  12   3   0   2   4 905   8]\n",
            " [ 26  63   8  13   2   1   3   5  30 849]]\n",
            "Epoch 79/200 - Train Loss: 0.4157, Val Loss: 0.5623, Val Accuracy: 82.15%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5702\n",
            "Accuracy: 82.14%\n",
            "F1 Score: 0.8217\n",
            "Confusion Matrix:\n",
            "[[848  15  21  15   8   1   7  17  42  26]\n",
            " [ 11 934   2   5   2   2   2   0  13  29]\n",
            " [ 46   2 761  56  54  19  30  21   7   4]\n",
            " [ 18   4  42 709  49 103  33  25   8   9]\n",
            " [ 11   3  33  47 812  16  17  58   3   0]\n",
            " [  9   0  43 147  29 708  10  45   3   6]\n",
            " [ 10   4  37  56  22  10 846   9   5   1]\n",
            " [  9   0  32  44  19  25   2 861   1   7]\n",
            " [ 52  21  11  12   0   0   6   7 875  16]\n",
            " [ 15  70   8  10   2   4   2   8  21 860]]\n",
            "Epoch 80/200 - Train Loss: 0.4173, Val Loss: 0.5702, Val Accuracy: 82.14%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5413\n",
            "Accuracy: 82.63%\n",
            "F1 Score: 0.8261\n",
            "Confusion Matrix:\n",
            "[[869   6  26  17  10   1   6   5  37  23]\n",
            " [ 16 897   0   5   2   1   2   0  14  63]\n",
            " [ 58   0 754  34  49  28  38  22   6  11]\n",
            " [ 20   1  47 677  54 100  43  33   9  16]\n",
            " [ 17   0  26  37 804  27  35  48   5   1]\n",
            " [ 11   2  31 139  26 738   8  38   3   4]\n",
            " [ 11   1  26  51  25  11 869   2   3   1]\n",
            " [ 15   1  13  32  24  32   3 874   1   5]\n",
            " [ 74  13   3   9   1   1   4   2 872  21]\n",
            " [ 16  33   7   8   2   0   4   2  19 909]]\n",
            "Epoch 81/200 - Train Loss: 0.4190, Val Loss: 0.5413, Val Accuracy: 82.63%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5489\n",
            "Accuracy: 82.45%\n",
            "F1 Score: 0.8252\n",
            "Confusion Matrix:\n",
            "[[824  10  25  20  10   4   4  12  62  29]\n",
            " [ 14 894   4   8   1   3   6   2  13  55]\n",
            " [ 39   0 764  50  46  39  35  13  11   3]\n",
            " [ 15   0  52 689  30 134  46  18   9   7]\n",
            " [ 16   2  41  42 789  35  31  39   5   0]\n",
            " [  7   0  28 136  20 765  15  24   1   4]\n",
            " [  8   1  30  51  23  21 859   2   5   0]\n",
            " [ 11   0  16  39  23  48   7 849   2   5]\n",
            " [ 36   6   6  13   3   1   5   4 911  15]\n",
            " [ 11  31   4  13   1   3   7   4  25 901]]\n",
            "Epoch 82/200 - Train Loss: 0.4130, Val Loss: 0.5489, Val Accuracy: 82.45%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5490\n",
            "Accuracy: 82.06%\n",
            "F1 Score: 0.8200\n",
            "Confusion Matrix:\n",
            "[[887  15  15  11   7   2   4   8  31  20]\n",
            " [  7 923   3   2   0   2   3   2   8  50]\n",
            " [ 51   2 742  42  51  42  38  17   5  10]\n",
            " [ 27   4  59 645  41 120  35  33  17  19]\n",
            " [ 21   3  36  45 775  29  35  50   4   2]\n",
            " [  8   1  21 143  24 737  11  41   2  12]\n",
            " [  9   0  43  49  16  20 843   4   9   7]\n",
            " [ 15   2  16  33  23  43   2 850   0  16]\n",
            " [ 54  12   8   7   2   1   2   2 881  31]\n",
            " [ 16  36   1   9   0   1   0   2  12 923]]\n",
            "Epoch 83/200 - Train Loss: 0.4095, Val Loss: 0.5490, Val Accuracy: 82.06%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5607\n",
            "Accuracy: 82.23%\n",
            "F1 Score: 0.8245\n",
            "Confusion Matrix:\n",
            "[[846  17  25  14  16   0   3   9  42  28]\n",
            " [  8 928   0   9   0   1   4   0  12  38]\n",
            " [ 40   0 769  73  39  28  19  19   8   5]\n",
            " [ 15   2  37 759  44 102  15  14   8   4]\n",
            " [ 14   0  45  63 813  21  13  23   7   1]\n",
            " [  7   3  26 194  29 710   2  25   2   2]\n",
            " [ 14   2  41 101  30  11 792   4   5   0]\n",
            " [ 10   0  24  48  38  40   2 828   3   7]\n",
            " [ 39  20   6  15   1   4   2   2 903   8]\n",
            " [ 17  48   8  10   2   4   4   5  27 875]]\n",
            "Epoch 84/200 - Train Loss: 0.4156, Val Loss: 0.5607, Val Accuracy: 82.23%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5408\n",
            "Accuracy: 82.67%\n",
            "F1 Score: 0.8268\n",
            "Confusion Matrix:\n",
            "[[830   9  32  25  10   2   7   8  49  28]\n",
            " [  7 920   0   1   1   1   2   1  17  50]\n",
            " [ 43   0 737  48  53  43  46  16   6   8]\n",
            " [ 20   2  34 678  60 123  45  21   7  10]\n",
            " [ 12   2  23  53 835  20  29  22   3   1]\n",
            " [ 11   2  21 129  36 754  12  28   2   5]\n",
            " [  5   1  30  54  21  11 869   5   4   0]\n",
            " [ 10   0   8  35  28  35   9 866   3   6]\n",
            " [ 55  14   4  13   3   0   2   3 892  14]\n",
            " [ 15  50   2   9   1   1   6   8  22 886]]\n",
            "Epoch 85/200 - Train Loss: 0.4100, Val Loss: 0.5408, Val Accuracy: 82.67%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5506\n",
            "Accuracy: 82.69%\n",
            "F1 Score: 0.8270\n",
            "Confusion Matrix:\n",
            "[[816  13  32  29  12   5   8  10  48  27]\n",
            " [  9 925   2   6   0   3   1   0  10  44]\n",
            " [ 43   1 721  53  61  48  34  24   7   8]\n",
            " [  3   4  35 692  55 119  45  33   7   7]\n",
            " [  8   0  26  42 821  20  31  46   6   0]\n",
            " [  3   2  26 128  27 761  11  30   4   8]\n",
            " [  4   1  22  51  24  14 877   5   1   1]\n",
            " [  7   0  13  40  28  33   1 868   2   8]\n",
            " [ 37  12   4  19   4   1   5   6 894  18]\n",
            " [  7  54   1   9   2   5   4   8  16 894]]\n",
            "Epoch 86/200 - Train Loss: 0.4130, Val Loss: 0.5506, Val Accuracy: 82.69%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5442\n",
            "Accuracy: 82.43%\n",
            "F1 Score: 0.8237\n",
            "Confusion Matrix:\n",
            "[[841   6  25  15   7   4   5  11  52  34]\n",
            " [ 10 907   0   1   0   0   2   4  12  64]\n",
            " [ 49   2 710  47  50  55  56  17   8   6]\n",
            " [ 17   2  36 658  56 131  63  23  10   4]\n",
            " [ 12   1  28  39 833  25  26  31   3   2]\n",
            " [ 11   2  28 112  35 770  15  18   4   5]\n",
            " [  4   1  24  28  25  15 893   2   6   2]\n",
            " [ 22   0   7  40  37  50   6 831   2   5]\n",
            " [ 35  12   3   6   4   2   7   5 905  21]\n",
            " [ 14  33   3   9   4   2   3   6  31 895]]\n",
            "Epoch 87/200 - Train Loss: 0.4109, Val Loss: 0.5442, Val Accuracy: 82.43%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5415\n",
            "Accuracy: 82.54%\n",
            "F1 Score: 0.8253\n",
            "Confusion Matrix:\n",
            "[[830   9  43  15  16   5   4  11  41  26]\n",
            " [ 14 864   4   3   2   3   5   3  23  79]\n",
            " [ 34   0 776  38  50  40  42  11   4   5]\n",
            " [  9   2  47 643  51 162  44  22  12   8]\n",
            " [ 10   0  23  39 848  24  30  23   3   0]\n",
            " [  7   1  31 119  39 765  13  19   2   4]\n",
            " [  3   2  29  30  35  15 877   4   2   3]\n",
            " [ 14   1  23  34  38  30   4 847   1   8]\n",
            " [ 47   9   8   2   1   2   6   3 900  22]\n",
            " [ 20  27   4  13   0   4   2   5  21 904]]\n",
            "Epoch 88/200 - Train Loss: 0.4111, Val Loss: 0.5415, Val Accuracy: 82.54%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5482\n",
            "Accuracy: 82.19%\n",
            "F1 Score: 0.8217\n",
            "Confusion Matrix:\n",
            "[[865   7  36  11   7   2   3   5  54  10]\n",
            " [ 25 891   5   5   1   2   2   2  23  44]\n",
            " [ 51   0 787  30  48  29  27  15  11   2]\n",
            " [ 17   7  56 647  44 148  47  16  11   7]\n",
            " [ 16   4  47  29 806  36  24  33   5   0]\n",
            " [ 10   4  42 109  26 755  13  37   1   3]\n",
            " [  6   3  40  41  17  16 865   5   5   2]\n",
            " [ 21   2  18  35  23  34   2 857   2   6]\n",
            " [ 59  11   4   6   1   1   6   4 902   6]\n",
            " [ 36  62   6   9   3   1   1   9  29 844]]\n",
            "Epoch 89/200 - Train Loss: 0.4116, Val Loss: 0.5482, Val Accuracy: 82.19%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5553\n",
            "Accuracy: 82.56%\n",
            "F1 Score: 0.8251\n",
            "Confusion Matrix:\n",
            "[[850   7  22  15  18   2  10  16  36  24]\n",
            " [ 16 892   2   5   2   3   4   1  11  64]\n",
            " [ 46   1 742  41  77  35  26  23   4   5]\n",
            " [ 13   2  41 678  66  96  41  41  10  12]\n",
            " [ 11   1  22  25 874  12  24  28   3   0]\n",
            " [  7   2  33 143  49 704   8  49   2   3]\n",
            " [  6   2  40  47  33   9 842  12   5   4]\n",
            " [  4   0  15  26  32  16   5 895   1   6]\n",
            " [ 55  10  10  10   2   0   5   4 886  18]\n",
            " [ 18  36   4   6   3   1   3  18  18 893]]\n",
            "Epoch 90/200 - Train Loss: 0.4046, Val Loss: 0.5553, Val Accuracy: 82.56%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5383\n",
            "Accuracy: 82.61%\n",
            "F1 Score: 0.8256\n",
            "Confusion Matrix:\n",
            "[[858  10  34  10   7   2   5   7  36  31]\n",
            " [ 14 916   4   3   1   0   4   0   7  51]\n",
            " [ 53   2 759  40  41  30  44  13   6  12]\n",
            " [ 23   6  47 668  45 111  41  22  16  21]\n",
            " [ 14   3  31  43 804  20  38  36   6   5]\n",
            " [ 10   5  29 145  29 739  11  24   2   6]\n",
            " [ 11   0  14  40  16  11 897   2   6   3]\n",
            " [ 21   0  22  31  25  35  10 837   1  18]\n",
            " [ 69  19   3   4   2   1   2   2 873  25]\n",
            " [ 26  41   2   5   0   0   2   2  12 910]]\n",
            "Epoch 91/200 - Train Loss: 0.4077, Val Loss: 0.5383, Val Accuracy: 82.61%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5440\n",
            "Accuracy: 82.54%\n",
            "F1 Score: 0.8247\n",
            "Confusion Matrix:\n",
            "[[816  12  45  19  12   2  10  11  55  18]\n",
            " [ 13 909   3   5   1   1   8   1   8  51]\n",
            " [ 24   1 751  51  69  22  49  21   9   3]\n",
            " [  9   4  47 680  64  79  72  27   9   9]\n",
            " [  6   1  25  31 857  10  46  19   5   0]\n",
            " [  6   1  35 162  48 673  27  44   2   2]\n",
            " [  8   0  19  28  16   8 919   1   1   0]\n",
            " [ 10   1  20  29  45  18   4 867   4   2]\n",
            " [ 42  11   6   9   6   0   5   4 899  18]\n",
            " [ 21  39   5  10   4   1   6   9  22 883]]\n",
            "Epoch 92/200 - Train Loss: 0.4073, Val Loss: 0.5440, Val Accuracy: 82.54%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5712\n",
            "Accuracy: 81.88%\n",
            "F1 Score: 0.8179\n",
            "Confusion Matrix:\n",
            "[[825   8  46  24   7   3   7  13  43  24]\n",
            " [ 12 893   5   3   0   2   8   3  16  58]\n",
            " [ 40   1 742  34  42  61  56  15   2   7]\n",
            " [ 11   3  49 591  40 186  77  29   7   7]\n",
            " [ 14   2  44  31 805  20  55  26   1   2]\n",
            " [  3   0  23  79  27 804  32  24   4   4]\n",
            " [  5   1  26  26  15  17 903   2   4   1]\n",
            " [ 10   1  10  34  40  48  15 839   0   3]\n",
            " [ 45  12   8   9   1   4   6   6 889  20]\n",
            " [ 16  28   2   8   1   3  11   8  26 897]]\n",
            "Epoch 93/200 - Train Loss: 0.3985, Val Loss: 0.5712, Val Accuracy: 81.88%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5556\n",
            "Accuracy: 82.25%\n",
            "F1 Score: 0.8216\n",
            "Confusion Matrix:\n",
            "[[887   8  21  12  12   1   3  11  29  16]\n",
            " [ 20 908   3   7   0   0   3   1  17  41]\n",
            " [ 67   2 737  47  45  39  38  19   3   3]\n",
            " [ 27   7  41 613  57 148  52  40   9   6]\n",
            " [ 25   1  29  39 806  26  26  43   3   2]\n",
            " [ 10   3  26  90  31 771  14  52   3   0]\n",
            " [  9   4  29  34  26  13 874   7   4   0]\n",
            " [ 12   1  16  16  22  29   9 892   1   2]\n",
            " [ 83   8   2   7   2   3   4   8 874   9]\n",
            " [ 40  51   4   5   0   5   3  13  16 863]]\n",
            "Epoch 94/200 - Train Loss: 0.4000, Val Loss: 0.5556, Val Accuracy: 82.25%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5661\n",
            "Accuracy: 82.32%\n",
            "F1 Score: 0.8230\n",
            "Confusion Matrix:\n",
            "[[891  13  32   9   9   1   3   4  26  12]\n",
            " [ 15 933   3   2   1   4   3   1   9  29]\n",
            " [ 43   1 765  47  47  34  38  16   8   1]\n",
            " [ 21   1  47 673  54 119  50  21   9   5]\n",
            " [ 13   1  35  38 825  18  36  32   2   0]\n",
            " [ 14   3  23 120  42 743  18  32   1   4]\n",
            " [  9   2  34  38  22   9 877   5   4   0]\n",
            " [ 25   2  18  25  37  44   8 837   2   2]\n",
            " [ 84  24   8   5   7   1   3   3 854  11]\n",
            " [ 35  77   4   6   2   4   6   6  26 834]]\n",
            "Epoch 95/200 - Train Loss: 0.4023, Val Loss: 0.5661, Val Accuracy: 82.32%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5574\n",
            "Accuracy: 82.44%\n",
            "F1 Score: 0.8246\n",
            "Confusion Matrix:\n",
            "[[860   6  17  16  10   2   8   7  52  22]\n",
            " [  8 905   1   6   0   1   6   0  36  37]\n",
            " [ 60   0 713  58  49  48  42  13   8   9]\n",
            " [ 12   1  34 694  47 122  49  20  10  11]\n",
            " [ 15   1  32  52 814  24  33  20   8   1]\n",
            " [  7   4  12 142  26 761  13  26   4   5]\n",
            " [  5   1  24  45  23  12 883   1   5   1]\n",
            " [ 13   3  18  45  32  57   5 817   2   8]\n",
            " [ 41   5   4   8   3   0   1   4 925   9]\n",
            " [ 27  44   3   6   5   2   3   5  33 872]]\n",
            "Epoch 96/200 - Train Loss: 0.4040, Val Loss: 0.5574, Val Accuracy: 82.44%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5567\n",
            "Accuracy: 82.55%\n",
            "F1 Score: 0.8254\n",
            "Confusion Matrix:\n",
            "[[884  10  21  11   7   3   2   6  39  17]\n",
            " [ 18 883   4   1   2   2   1   0  25  64]\n",
            " [ 49   0 745  45  60  39  29  15  10   8]\n",
            " [ 27   2  26 686  63 110  35  31   9  11]\n",
            " [ 24   0  22  37 839  21  19  27   7   4]\n",
            " [ 10   1  32 120  52 732  15  25   5   8]\n",
            " [ 10   2  18  55  35  11 854   4   7   4]\n",
            " [ 28   0  21  30  34  32   3 847   2   3]\n",
            " [ 61  13   8   3   1   1   1   1 896  15]\n",
            " [ 27  43   3   8   0   2   3   6  19 889]]\n",
            "Epoch 97/200 - Train Loss: 0.4044, Val Loss: 0.5567, Val Accuracy: 82.55%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5259\n",
            "Accuracy: 83.19%\n",
            "F1 Score: 0.8319\n",
            "Confusion Matrix:\n",
            "[[854  11  25  21   3   1   7  10  43  25]\n",
            " [  9 933   2   4   2   1   4   0   9  36]\n",
            " [ 43   2 756  52  54  21  34  15  17   6]\n",
            " [ 15   3  50 750  44  53  47  17   9  12]\n",
            " [  9   1  33  57 819  15  32  30   4   0]\n",
            " [  9   3  32 204  26 671  10  32   7   6]\n",
            " [  9   1  28  32  14   6 903   0   5   2]\n",
            " [ 20   0  17  37  32  33   8 842   1  10]\n",
            " [ 42  14   5  12   1   0   3   3 902  18]\n",
            " [  9  53   6  10   1   0   5   6  21 889]]\n",
            "Epoch 98/200 - Train Loss: 0.4097, Val Loss: 0.5259, Val Accuracy: 83.19%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5281\n",
            "Accuracy: 83.31%\n",
            "F1 Score: 0.8331\n",
            "Confusion Matrix:\n",
            "[[853   8  27  19   3   0   5  11  54  20]\n",
            " [  9 929   1   2   2   2   2   1   8  44]\n",
            " [ 36   1 759  61  40  24  47  18   7   7]\n",
            " [ 18   3  43 694  25 114  62  28   7   6]\n",
            " [ 12   0  32  51 809  18  36  38   4   0]\n",
            " [  6   1  23 132  32 749  17  37   1   2]\n",
            " [  6   0  27  44  13   9 893   5   2   1]\n",
            " [ 11   0  18  35  29  44   7 850   2   4]\n",
            " [ 35  14   5   7   3   3   5   8 898  22]\n",
            " [ 20  40   5   6   0   1   3   9  19 897]]\n",
            "Epoch 99/200 - Train Loss: 0.3964, Val Loss: 0.5281, Val Accuracy: 83.31%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5443\n",
            "Accuracy: 82.36%\n",
            "F1 Score: 0.8228\n",
            "Confusion Matrix:\n",
            "[[808   9  13  18  20   4  13  20  64  31]\n",
            " [  6 925   3   1   0   1   4   4  15  41]\n",
            " [ 38   0 684  51  70  64  67  16   6   4]\n",
            " [ 14   4  23 635  56 168  52  29   8  11]\n",
            " [  2   0  16  38 852  29  37  24   1   1]\n",
            " [  2   1  16 104  30 799  13  30   1   4]\n",
            " [  5   3  11  39  21  19 891   5   3   3]\n",
            " [  7   0   8  22  29  50   8 871   0   5]\n",
            " [ 38  15   3  11   5   4   2   8 894  20]\n",
            " [ 12  53   4   8   0   5   4  12  25 877]]\n",
            "Epoch 100/200 - Train Loss: 0.4029, Val Loss: 0.5443, Val Accuracy: 82.36%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5378\n",
            "Accuracy: 82.84%\n",
            "F1 Score: 0.8293\n",
            "Confusion Matrix:\n",
            "[[874  10  28  11   6   1   1   4  44  21]\n",
            " [ 17 922   2   2   1   0   2   0  14  40]\n",
            " [ 36   5 796  43  39  25  29  12   7   8]\n",
            " [ 25   1  50 742  37  88  27  18   7   5]\n",
            " [ 28   0  43  52 802  18  34  20   3   0]\n",
            " [ 12   0  33 155  40 721   7  26   3   3]\n",
            " [ 15   2  45  56  20  10 845   3   4   0]\n",
            " [ 24   2  20  50  39  27   6 826   2   4]\n",
            " [ 55  12   6  15   1   0   2   2 894  13]\n",
            " [ 31  58   7   6   2   3   3   6  22 862]]\n",
            "Epoch 101/200 - Train Loss: 0.3952, Val Loss: 0.5378, Val Accuracy: 82.84%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5548\n",
            "Accuracy: 82.69%\n",
            "F1 Score: 0.8273\n",
            "Confusion Matrix:\n",
            "[[806  12  32  24  10   5   6  13  54  38]\n",
            " [ 12 889   2   7   2   1   1   3  10  73]\n",
            " [ 41   1 745  60  59  36  26  20   5   7]\n",
            " [ 14   6  34 718  50  99  24  36  10   9]\n",
            " [ 12   1  24  42 851  11  20  34   4   1]\n",
            " [  6   0  21 130  35 752   9  36   4   7]\n",
            " [  5   3  36  70  31  15 829   3   4   4]\n",
            " [  5   3  15  36  29  28   2 869   2  11]\n",
            " [ 34  15   8  10   2   1   6   5 887  32]\n",
            " [ 13  30   3   4   1   0   3   6  17 923]]\n",
            "Epoch 102/200 - Train Loss: 0.4049, Val Loss: 0.5548, Val Accuracy: 82.69%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5661\n",
            "Accuracy: 82.26%\n",
            "F1 Score: 0.8222\n",
            "Confusion Matrix:\n",
            "[[837  14  22  17  11   1   4   3  69  22]\n",
            " [  3 924   3   3   1   3   8   0  20  35]\n",
            " [ 37   1 756  45  41  26  67  10   7  10]\n",
            " [ 23   1  49 686  50  82  69  17  16   7]\n",
            " [ 10   0  34  44 819   8  65  14   6   0]\n",
            " [ 11   3  34 154  34 698  37  21   4   4]\n",
            " [  7   0  28  32  10   6 909   3   4   1]\n",
            " [ 16   3  23  46  59  33   8 803   2   7]\n",
            " [ 30  13   8   4   1   0   7   2 924  11]\n",
            " [ 18  52   6  12   3   1   4   2  32 870]]\n",
            "Epoch 103/200 - Train Loss: 0.3977, Val Loss: 0.5661, Val Accuracy: 82.26%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5409\n",
            "Accuracy: 82.80%\n",
            "F1 Score: 0.8271\n",
            "Confusion Matrix:\n",
            "[[830  16  30   9  13   1   3  13  48  37]\n",
            " [  8 927   2   2   2   0   1   0   9  49]\n",
            " [ 50   1 740  50  60  25  43  18   5   8]\n",
            " [ 14   5  27 681  93  93  35  34   6  12]\n",
            " [ 12   0  23  27 874   5  28  27   2   2]\n",
            " [  8   2  22 141  60 696  15  42   8   6]\n",
            " [  3   5  22  38  39  10 873   4   3   3]\n",
            " [  8   1  13  31  35  24   2 876   1   9]\n",
            " [ 44  20   4   7   3   0   5   6 891  20]\n",
            " [ 13  50   7   4   3   1   5   4  21 892]]\n",
            "Epoch 104/200 - Train Loss: 0.4013, Val Loss: 0.5409, Val Accuracy: 82.80%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5718\n",
            "Accuracy: 82.23%\n",
            "F1 Score: 0.8222\n",
            "Confusion Matrix:\n",
            "[[859   6  17  20  17   4   9   8  31  29]\n",
            " [ 14 862   3   1   2   2   9   2  19  86]\n",
            " [ 54   0 695  55  62  38  57  22   5  12]\n",
            " [ 10   1  36 711  62  77  47  26  11  19]\n",
            " [  9   0  20  43 832  11  44  33   6   2]\n",
            " [  6   3  15 151  42 727  17  28   3   8]\n",
            " [  7   1  11  43  19  14 893   2   7   3]\n",
            " [ 12   0  10  40  36  45   4 836   1  16]\n",
            " [ 59  13   3   9   1   0   7   3 879  26]\n",
            " [ 20  20   2   6   2   1   4   5  11 929]]\n",
            "Epoch 105/200 - Train Loss: 0.3904, Val Loss: 0.5718, Val Accuracy: 82.23%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5706\n",
            "Accuracy: 82.21%\n",
            "F1 Score: 0.8232\n",
            "Confusion Matrix:\n",
            "[[849   7  27  25   7   0   5   7  50  23]\n",
            " [ 17 861   2   5   1   1   1   1  17  94]\n",
            " [ 41   1 780  65  40  19  29  14   5   6]\n",
            " [ 17   1  49 728  45  86  41  13   9  11]\n",
            " [ 15   1  33  49 824  13  36  20   3   6]\n",
            " [ 12   1  32 182  38 696   9  18   3   9]\n",
            " [ 11   1  31  51  18  14 869   2   2   1]\n",
            " [ 19   0  28  52  45  29   8 795   5  19]\n",
            " [ 54   7   6  12   1   0   7   2 889  22]\n",
            " [ 15  17   6   7   2   1   2   1  19 930]]\n",
            "Epoch 106/200 - Train Loss: 0.4007, Val Loss: 0.5706, Val Accuracy: 82.21%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5316\n",
            "Accuracy: 82.95%\n",
            "F1 Score: 0.8293\n",
            "Confusion Matrix:\n",
            "[[829   8  32  13   7   2   7  10  62  30]\n",
            " [  8 922   2   5   1   0   4   4  12  42]\n",
            " [ 46   1 771  49  44  28  34  13  10   4]\n",
            " [ 11   3  53 660  36 146  42  24  16   9]\n",
            " [ 13   1  33  49 802  30  34  35   2   1]\n",
            " [  8   4  35 113  24 787   5  22   1   1]\n",
            " [  6   1  30  35  26  25 866   7   3   1]\n",
            " [ 12   1  18  29  29  41   5 858   3   4]\n",
            " [ 38   9   2  11   2   0   6   3 915  14]\n",
            " [ 13  47   7   5   3   5   5   4  26 885]]\n",
            "Epoch 107/200 - Train Loss: 0.4015, Val Loss: 0.5316, Val Accuracy: 82.95%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5613\n",
            "Accuracy: 82.52%\n",
            "F1 Score: 0.8244\n",
            "Confusion Matrix:\n",
            "[[880  12  24  14   6   3   5  10  30  16]\n",
            " [  8 930   3   2   0   3   3   1   8  42]\n",
            " [ 49   2 773  36  41  31  43   9   7   9]\n",
            " [ 16   6  58 644  51 121  63  22  12   7]\n",
            " [ 17   2  47  26 802  18  65  18   4   1]\n",
            " [  8   1  37 118  39 755  13  19   5   5]\n",
            " [  5   6  28  21  20  14 896   3   5   2]\n",
            " [ 14   2  21  41  47  42   8 811   5   9]\n",
            " [ 59  21   3   9   1   0   4   1 891  11]\n",
            " [ 28  55   5   3   3   3   6   4  23 870]]\n",
            "Epoch 108/200 - Train Loss: 0.3889, Val Loss: 0.5613, Val Accuracy: 82.52%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5430\n",
            "Accuracy: 82.79%\n",
            "F1 Score: 0.8283\n",
            "Confusion Matrix:\n",
            "[[846  10  41  14   6   1   8  10  41  23]\n",
            " [  9 920   0   7   2   0   3   0  12  47]\n",
            " [ 39   1 779  48  29  33  43  13   9   6]\n",
            " [ 24   4  50 719  31  85  55  17   6   9]\n",
            " [ 10   1  55  63 765  18  57  28   2   1]\n",
            " [  6   1  26 153  26 733  19  31   2   3]\n",
            " [  2   2  35  38  11   8 899   3   2   0]\n",
            " [ 11   2  29  39  26  29   4 854   1   5]\n",
            " [ 47  16   6  13   2   1   2   4 892  17]\n",
            " [ 18  50   6  13   3   0   7   7  24 872]]\n",
            "Epoch 109/200 - Train Loss: 0.3905, Val Loss: 0.5430, Val Accuracy: 82.79%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5591\n",
            "Accuracy: 82.61%\n",
            "F1 Score: 0.8271\n",
            "Confusion Matrix:\n",
            "[[868  12  15  17  14   4   5   9  22  34]\n",
            " [  9 933   0   5   0   1   1   0   8  43]\n",
            " [ 56   2 695  75  79  30  24  22   8   9]\n",
            " [ 14   3  20 751  56  87  26  19  10  14]\n",
            " [  9   2  19  55 849  16  14  34   2   0]\n",
            " [  8   1  18 158  47 731   7  28   1   1]\n",
            " [  3   6  24  75  48  13 820   3   3   5]\n",
            " [ 10   2  13  45  29  28   2 865   1   5]\n",
            " [ 76  23   3  12   3   1   0   5 855  22]\n",
            " [ 16  45   4  11   3   1   2   6  18 894]]\n",
            "Epoch 110/200 - Train Loss: 0.4002, Val Loss: 0.5591, Val Accuracy: 82.61%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5461\n",
            "Accuracy: 83.01%\n",
            "F1 Score: 0.8309\n",
            "Confusion Matrix:\n",
            "[[884   8  16  25   9   4   8  10  23  13]\n",
            " [ 11 917   3   5   1   1   3   1  18  40]\n",
            " [ 52   0 730  59  51  43  41  16   5   3]\n",
            " [ 17   3  28 692  30 147  45  27   6   5]\n",
            " [ 17   0  24  63 798  31  29  34   2   2]\n",
            " [  7   2  13 116  22 800  13  25   1   1]\n",
            " [  8   4  13  54  13  21 881   4   1   1]\n",
            " [  8   0   9  48  29  40   4 855   2   5]\n",
            " [ 61  13   4  14   2   0   1   6 887  12]\n",
            " [ 24  63   3  10   4   1   6   6  26 857]]\n",
            "Epoch 111/200 - Train Loss: 0.3922, Val Loss: 0.5461, Val Accuracy: 83.01%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5751\n",
            "Accuracy: 82.39%\n",
            "F1 Score: 0.8236\n",
            "Confusion Matrix:\n",
            "[[857  28  12  12  13   3   6   7  27  35]\n",
            " [  5 917   4   3   2   1   1   0   4  63]\n",
            " [ 51   1 702  56  66  40  55  16   5   8]\n",
            " [ 17   8  30 684  51 113  51  21   4  21]\n",
            " [ 14   1  19  31 856  24  27  22   3   3]\n",
            " [  7   3  18 132  43 773  11   8   2   3]\n",
            " [  4   2  14  48  29  10 886   4   2   1]\n",
            " [ 12   2  15  36  41  53  11 817   2  11]\n",
            " [ 59  30   5  11   3   3   7   4 836  42]\n",
            " [ 13  41   4   6   1   2   4   3  15 911]]\n",
            "Epoch 112/200 - Train Loss: 0.3894, Val Loss: 0.5751, Val Accuracy: 82.39%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5575\n",
            "Accuracy: 82.68%\n",
            "F1 Score: 0.8268\n",
            "Confusion Matrix:\n",
            "[[858  12  27  12  14   3   7  17  31  19]\n",
            " [ 13 914   7   6   2   3   6   2   7  40]\n",
            " [ 40   2 776  38  47  36  46  11   0   4]\n",
            " [ 15   1  42 668  50 123  57  36   4   4]\n",
            " [  8   0  32  31 831  28  36  30   3   1]\n",
            " [  6   1  27 124  44 737  18  37   2   4]\n",
            " [  8   1  30  44  13  14 886   2   2   0]\n",
            " [  7   1  21  31  45  32   6 850   0   7]\n",
            " [ 51  14   7  14   4   1  12   3 881  13]\n",
            " [ 21  47   6  11   6   3   8  13  18 867]]\n",
            "Epoch 113/200 - Train Loss: 0.3915, Val Loss: 0.5575, Val Accuracy: 82.68%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5508\n",
            "Accuracy: 82.83%\n",
            "F1 Score: 0.8290\n",
            "Confusion Matrix:\n",
            "[[857  11  38  20   7   1   7   4  36  19]\n",
            " [  9 915   2   5   0   1   7   1  15  45]\n",
            " [ 38   1 782  42  39  30  46   9   5   8]\n",
            " [ 14   2  52 727  35  82  57  12   9  10]\n",
            " [ 11   2  50  63 788  14  50  16   5   1]\n",
            " [  6   1  35 159  31 728  18  17   2   3]\n",
            " [  2   3  24  44  10  10 899   3   4   1]\n",
            " [ 12   1  26  44  40  37   6 822   4   8]\n",
            " [ 51  13   6   8   2   0   5   2 892  21]\n",
            " [ 20  58   3  11   2   1   7   4  21 873]]\n",
            "Epoch 114/200 - Train Loss: 0.3930, Val Loss: 0.5508, Val Accuracy: 82.83%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5483\n",
            "Accuracy: 82.90%\n",
            "F1 Score: 0.8290\n",
            "Confusion Matrix:\n",
            "[[850   9  31  14   9   1   8  14  46  18]\n",
            " [  6 921   4   3   1   3   2   1  16  43]\n",
            " [ 41   1 725  58  43  40  45  30  10   7]\n",
            " [ 13   2  29 713  37  95  47  43  11  10]\n",
            " [ 11   1  26  63 761  25  37  67   6   3]\n",
            " [  6   4  20 153  20 740  10  40   3   4]\n",
            " [  5   1  21  58  22   8 871   5   9   0]\n",
            " [  4   1   9  35  15  25   0 898   2  11]\n",
            " [ 37  10   5  15   1   1   3   2 908  18]\n",
            " [ 12  37   4   6   1   1   5   9  22 903]]\n",
            "Epoch 115/200 - Train Loss: 0.3902, Val Loss: 0.5483, Val Accuracy: 82.90%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5541\n",
            "Accuracy: 82.97%\n",
            "F1 Score: 0.8299\n",
            "Confusion Matrix:\n",
            "[[824   7  24  22   9   7   5  11  55  36]\n",
            " [ 11 902   1   8   1   1   3   0  19  54]\n",
            " [ 49   0 692  55  66  59  41  22   8   8]\n",
            " [  8   2  22 704  50 133  37  19  13  12]\n",
            " [  6   3  14  52 827  39  24  33   2   0]\n",
            " [  6   1  15 123  21 799   7  23   2   3]\n",
            " [ 11   1  24  45  26  17 867   5   3   1]\n",
            " [ 10   1   9  28  31  53   6 852   2   8]\n",
            " [ 31   8   4   8   2   3   4   3 910  27]\n",
            " [  4  32   1   8   3   5   4   4  19 920]]\n",
            "Epoch 116/200 - Train Loss: 0.3898, Val Loss: 0.5541, Val Accuracy: 82.97%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5568\n",
            "Accuracy: 82.86%\n",
            "F1 Score: 0.8278\n",
            "Confusion Matrix:\n",
            "[[841  12  39  15   6   6  12   5  38  26]\n",
            " [ 11 921   2   2   0   2   7   0  10  45]\n",
            " [ 34   4 787  26  48  40  40  12   5   4]\n",
            " [ 15   2  57 612  47 171  65  12  15   4]\n",
            " [  9   0  41  38 809  25  53  20   5   0]\n",
            " [  6   0  33  85  31 806  19  14   4   2]\n",
            " [  4   1  22  20  12  13 922   0   3   3]\n",
            " [ 13   4  32  26  41  73   9 793   0   9]\n",
            " [ 39  15   8   7   3   1   7   1 903  16]\n",
            " [ 20  45   4   6   1   2   8   7  15 892]]\n",
            "Epoch 117/200 - Train Loss: 0.3883, Val Loss: 0.5568, Val Accuracy: 82.86%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5591\n",
            "Accuracy: 82.81%\n",
            "F1 Score: 0.8276\n",
            "Confusion Matrix:\n",
            "[[852   5  29   6  17   4  10   7  45  25]\n",
            " [ 11 903   3   0   0   2   4   0  20  57]\n",
            " [ 39   0 785  29  53  33  38  11   4   8]\n",
            " [ 18   2  62 656  56 102  61  18  12  13]\n",
            " [ 14   0  24  34 858  15  33  19   3   0]\n",
            " [  9   1  40 119  47 733  19  25   1   6]\n",
            " [  7   0  41  28  24  10 884   2   3   1]\n",
            " [ 16   0  26  39  54  34   8 815   3   5]\n",
            " [ 47   8   5   8   1   2   7   2 905  15]\n",
            " [ 22  33   4   8   3   2   7   5  26 890]]\n",
            "Epoch 118/200 - Train Loss: 0.3850, Val Loss: 0.5591, Val Accuracy: 82.81%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5741\n",
            "Accuracy: 82.60%\n",
            "F1 Score: 0.8250\n",
            "Confusion Matrix:\n",
            "[[856  10  26  13   4   2   8   8  59  14]\n",
            " [  7 879   6   5   0   2   8   2  21  70]\n",
            " [ 55   1 757  48  32  31  40  20  10   6]\n",
            " [ 29   3  51 665  48  93  63  23  17   8]\n",
            " [ 18   1  34  28 796  17  49  47   8   2]\n",
            " [ 11   1  39 147  25 705  16  47   4   5]\n",
            " [  8   0  31  27  14  10 905   3   1   1]\n",
            " [ 20   0  20  34  24  16   3 869   5   9]\n",
            " [ 39   9   7   4   1   0   4   2 917  17]\n",
            " [ 16  26   7   6   2   3   6   6  17 911]]\n",
            "Epoch 119/200 - Train Loss: 0.3906, Val Loss: 0.5741, Val Accuracy: 82.60%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5362\n",
            "Accuracy: 82.82%\n",
            "F1 Score: 0.8284\n",
            "Confusion Matrix:\n",
            "[[886  12  25   9   9   2   4  10  26  17]\n",
            " [ 15 893   2   3   1   1   3   3  17  62]\n",
            " [ 55   3 772  33  41  47  22  13   7   7]\n",
            " [ 22   2  59 675  50 121  27  28  11   5]\n",
            " [ 15   0  37  39 836  23  13  36   0   1]\n",
            " [  7   2  31 120  30 765  10  31   1   3]\n",
            " [ 10   1  35  57  35  16 834   5   2   5]\n",
            " [ 19   1  19  23  36  34   1 860   0   7]\n",
            " [ 68  17  10  12   3   0   3   6 866  15]\n",
            " [ 25  49   3   5   2   1   1   4  15 895]]\n",
            "Epoch 120/200 - Train Loss: 0.3813, Val Loss: 0.5362, Val Accuracy: 82.82%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5448\n",
            "Accuracy: 82.95%\n",
            "F1 Score: 0.8316\n",
            "Confusion Matrix:\n",
            "[[820   9  33  41  11   1   3   9  46  27]\n",
            " [  7 906   1   6   1   1   2   1  11  64]\n",
            " [ 24   0 782  73  52  14  27  16   7   5]\n",
            " [  7   2  42 777  37  67  28  25   6   9]\n",
            " [  6   1  24  69 831  14  23  31   1   0]\n",
            " [  7   2  27 218  27 672   8  33   1   5]\n",
            " [  3   1  42  76  26   6 834   5   4   3]\n",
            " [ 11   1  17  44  26  18   5 871   0   7]\n",
            " [ 35  14  10  11   3   0   4   3 898  22]\n",
            " [  8  40   4  19   4   2   3   5  11 904]]\n",
            "Epoch 121/200 - Train Loss: 0.3829, Val Loss: 0.5448, Val Accuracy: 82.95%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5720\n",
            "Accuracy: 82.79%\n",
            "F1 Score: 0.8287\n",
            "Confusion Matrix:\n",
            "[[838   4  34  26   8   4   3  16  47  20]\n",
            " [ 20 890   0   4   1   3   4   4  21  53]\n",
            " [ 34   0 767  50  50  32  24  29   8   6]\n",
            " [ 10   1  48 710  48 112  24  34   7   6]\n",
            " [ 15   1  36  50 814  18  19  44   2   1]\n",
            " [  7   1  35 130  32 745   8  39   1   2]\n",
            " [ 12   1  41  71  27  11 827   7   2   1]\n",
            " [  7   1  17  24  23  27   2 890   3   6]\n",
            " [ 40  10   5  14   2   0   3   7 904  15]\n",
            " [ 27  20   2  13   1   1   4  15  23 894]]\n",
            "Epoch 122/200 - Train Loss: 0.3834, Val Loss: 0.5720, Val Accuracy: 82.79%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5562\n",
            "Accuracy: 82.31%\n",
            "F1 Score: 0.8244\n",
            "Confusion Matrix:\n",
            "[[846  16  28  20  10   0   8  12  43  17]\n",
            " [  8 926   3   4   0   1   6   0  17  35]\n",
            " [ 43   1 794  57  28  30  31  11   4   1]\n",
            " [ 17   3  55 733  42  73  22  26  21   8]\n",
            " [ 14   2  54  57 784  10  42  30   3   4]\n",
            " [  6   1  38 166  27 720  11  26   1   4]\n",
            " [  8   0  43  77   9  10 847   3   2   1]\n",
            " [ 19   0  25  60  31  36   7 814   2   6]\n",
            " [ 45  14   5  10   1   2   6   4 902  11]\n",
            " [ 27  64   4  10   4   1   5   6  14 865]]\n",
            "Epoch 123/200 - Train Loss: 0.3853, Val Loss: 0.5562, Val Accuracy: 82.31%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5588\n",
            "Accuracy: 82.67%\n",
            "F1 Score: 0.8263\n",
            "Confusion Matrix:\n",
            "[[863   7  16  19   9   5   3   7  31  40]\n",
            " [ 10 892   1   4   1   1   2   2   8  79]\n",
            " [ 56   1 696  50  62  45  59  18   5   8]\n",
            " [ 14   5  11 709  70  85  53  25  13  15]\n",
            " [ 18   0  20  29 838  17  36  36   4   2]\n",
            " [  8   2  14 178  45 702  18  27   2   4]\n",
            " [  6   2   8  37  28   9 899   5   2   4]\n",
            " [ 14   0  10  36  31  35   2 858   5   9]\n",
            " [ 60  11   1   9   1   0   6   3 876  33]\n",
            " [  7  25   3   7   3   0   4   3  14 934]]\n",
            "Epoch 124/200 - Train Loss: 0.3821, Val Loss: 0.5588, Val Accuracy: 82.67%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5573\n",
            "Accuracy: 82.60%\n",
            "F1 Score: 0.8261\n",
            "Confusion Matrix:\n",
            "[[770  12  48  21  19   1   1   9  70  49]\n",
            " [  7 900   3   2   2   2   2   1  12  69]\n",
            " [ 35   1 745  58  49  47  29  14  12  10]\n",
            " [ 10   2  33 681  51 141  33  23  12  14]\n",
            " [  9   2  25  39 847  25  18  32   3   0]\n",
            " [  6   5  25 114  47 771   7  17   2   6]\n",
            " [  5   5  26  66  43  13 838   1   1   2]\n",
            " [  9   1  13  26  35  50   4 852   1   9]\n",
            " [ 27   9   4   7   1   1   1   7 924  19]\n",
            " [  6  23   3  10   1   1   2   3  19 932]]\n",
            "Epoch 125/200 - Train Loss: 0.3781, Val Loss: 0.5573, Val Accuracy: 82.60%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5371\n",
            "Accuracy: 83.05%\n",
            "F1 Score: 0.8303\n",
            "Confusion Matrix:\n",
            "[[867  12  33  12   6   2   9   4  35  20]\n",
            " [ 10 919   3   2   1   2   6   2  10  45]\n",
            " [ 45   1 783  47  33  29  37  16   4   5]\n",
            " [ 13   2  58 704  51  82  55  19   9   7]\n",
            " [ 18   1  52  35 823  12  40  16   3   0]\n",
            " [  6   2  39 150  35 706  26  31   2   3]\n",
            " [  8   0  22  26  18   9 910   3   3   1]\n",
            " [ 17   2  25  33  41  43   4 828   1   6]\n",
            " [ 46  15   5  11   1   1   7   3 894  17]\n",
            " [ 25  50   8   9   2   1   6  10  18 871]]\n",
            "Epoch 126/200 - Train Loss: 0.3828, Val Loss: 0.5371, Val Accuracy: 83.05%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5591\n",
            "Accuracy: 82.71%\n",
            "F1 Score: 0.8281\n",
            "Confusion Matrix:\n",
            "[[810  14  27  33  11   1   6  14  52  32]\n",
            " [  9 929   2   2   3   1   0   3  12  39]\n",
            " [ 35   2 741  68  70  28  25  21   5   5]\n",
            " [  5   3  38 752  52  82  27  23  10   8]\n",
            " [  9   1  30  50 839  19  17  30   4   1]\n",
            " [  5   2  27 173  38 718   6  24   2   5]\n",
            " [  5   1  31  62  43  16 829   5   7   1]\n",
            " [  7   2  10  35  34  35   0 872   1   4]\n",
            " [ 31  22   4  14   0   0   2   5 898  24]\n",
            " [ 14  59   4  11   4   0   5   5  15 883]]\n",
            "Epoch 127/200 - Train Loss: 0.3805, Val Loss: 0.5591, Val Accuracy: 82.71%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5499\n",
            "Accuracy: 82.91%\n",
            "F1 Score: 0.8277\n",
            "Confusion Matrix:\n",
            "[[854  20  22  14   7   0   3   6  49  25]\n",
            " [  6 928   2   4   2   2   1   1  14  40]\n",
            " [ 46   5 719  42  63  46  51   8   8  12]\n",
            " [ 19   8  30 656  43 105  81  27  18  13]\n",
            " [ 13   2  30  38 826  13  42  29   4   3]\n",
            " [  9   3  16 132  36 739  23  34   3   5]\n",
            " [  6   3  15  25  16  10 914   2   5   4]\n",
            " [ 17   3   9  33  42  30   7 846   4   9]\n",
            " [ 45  14   3   5   1   0   4   2 905  21]\n",
            " [ 18  46   1   5   0   0   4   8  14 904]]\n",
            "Epoch 128/200 - Train Loss: 0.3796, Val Loss: 0.5499, Val Accuracy: 82.91%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5866\n",
            "Accuracy: 82.65%\n",
            "F1 Score: 0.8266\n",
            "Confusion Matrix:\n",
            "[[827   3  35  20   9   3   7   9  39  48]\n",
            " [  8 828   1   8   2   4   1   0  23 125]\n",
            " [ 31   1 784  34  52  25  36  14  12  11]\n",
            " [  9   0  64 690  58  78  50  20  14  17]\n",
            " [ 10   0  22  38 858  14  30  24   4   0]\n",
            " [  6   1  39 157  39 708  13  27   2   8]\n",
            " [  5   0  32  37  25   7 887   0   2   5]\n",
            " [ 11   0  26  36  31  31   6 844   1  14]\n",
            " [ 36   5   2   9   3   1   3   6 897  38]\n",
            " [  8  16   1  10   1   2   3   3  14 942]]\n",
            "Epoch 129/200 - Train Loss: 0.3807, Val Loss: 0.5866, Val Accuracy: 82.65%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5505\n",
            "Accuracy: 83.36%\n",
            "F1 Score: 0.8344\n",
            "Confusion Matrix:\n",
            "[[826  12  23  26  12   3   7  17  36  38]\n",
            " [  5 932   0   3   1   2   0   2   7  48]\n",
            " [ 34   5 737  71  42  38  37  25   6   5]\n",
            " [  5   5  25 745  41 105  36  26   4   8]\n",
            " [  7   2  20  68 812  15  30  40   4   2]\n",
            " [  4   3  19 138  27 767  13  22   3   4]\n",
            " [  4   4  21  66  18  12 866   4   4   1]\n",
            " [  9   1  11  34  28  28   3 876   2   8]\n",
            " [ 50  21   5  12   0   4   3   6 866  33]\n",
            " [ 14  40   0  12   2   2   3   6  12 909]]\n",
            "Epoch 130/200 - Train Loss: 0.3834, Val Loss: 0.5505, Val Accuracy: 83.36%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5629\n",
            "Accuracy: 83.33%\n",
            "F1 Score: 0.8334\n",
            "Confusion Matrix:\n",
            "[[870  11  20  12   8   1   3   8  38  29]\n",
            " [ 10 918   3   5   0   0   2   0  13  49]\n",
            " [ 54   1 729  59  56  28  32  27   7   7]\n",
            " [ 13   5  37 736  47  76  26  36  14  10]\n",
            " [ 21   1  26  52 837  11  18  28   5   1]\n",
            " [ 11   2  16 157  30 721   9  42   4   8]\n",
            " [  6   5  26  55  39   4 855   5   3   2]\n",
            " [ 10   0  16  37  30  25   2 870   5   5]\n",
            " [ 44   6   3  11   3   0   0   2 907  24]\n",
            " [ 13  59   5   7   2   0   6   5  13 890]]\n",
            "Epoch 131/200 - Train Loss: 0.3759, Val Loss: 0.5629, Val Accuracy: 83.33%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5614\n",
            "Accuracy: 82.98%\n",
            "F1 Score: 0.8292\n",
            "Confusion Matrix:\n",
            "[[864  16  32  14   8   3   4  13  36  10]\n",
            " [  6 940   3   1   0   3   1   2   9  35]\n",
            " [ 50   4 748  52  54  30  33  14   7   8]\n",
            " [ 14   6  50 697  58  79  48  35   6   7]\n",
            " [ 16   1  27  30 853  14  31  24   4   0]\n",
            " [ 10   3  39 134  41 711  14  38   4   6]\n",
            " [  8   3  27  47  34  10 858   6   6   1]\n",
            " [ 15   1  24  25  43  20   1 863   2   6]\n",
            " [ 44  18   2   7   4   0   3   5 906  11]\n",
            " [ 26  77   2   5   3   0   4   2  23 858]]\n",
            "Epoch 132/200 - Train Loss: 0.3799, Val Loss: 0.5614, Val Accuracy: 82.98%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5671\n",
            "Accuracy: 82.68%\n",
            "F1 Score: 0.8271\n",
            "Confusion Matrix:\n",
            "[[824  10  34  30  13   3   8  11  49  18]\n",
            " [  9 927   6   7   3   2   4   4  10  28]\n",
            " [ 35   2 755  56  45  30  38  28   8   3]\n",
            " [ 11   2  46 736  46  81  41  28   4   5]\n",
            " [ 10   2  27  43 838  16  23  35   4   2]\n",
            " [  7   2  35 162  36 700  12  43   2   1]\n",
            " [  3   4  30  35  28   7 886   5   2   0]\n",
            " [  2   0  16  41  23  22   4 888   0   4]\n",
            " [ 46  21  13  18   5   1   8   6 871  11]\n",
            " [ 15  83   4  11   3   4   7  13  17 843]]\n",
            "Epoch 133/200 - Train Loss: 0.3822, Val Loss: 0.5671, Val Accuracy: 82.68%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5811\n",
            "Accuracy: 82.48%\n",
            "F1 Score: 0.8254\n",
            "Confusion Matrix:\n",
            "[[854  15  22  14  10   4   4  16  35  26]\n",
            " [ 13 947   1   5   0   2   1   0   9  22]\n",
            " [ 64   3 709  63  42  51  34  24   7   3]\n",
            " [  9   7  21 723  32 143  28  20  12   5]\n",
            " [ 10   2  31  62 769  34  34  51   5   2]\n",
            " [  6   3  23 122  19 792   5  25   3   2]\n",
            " [  9   3  17  78  14  15 851   6   7   0]\n",
            " [  5   2   9  31  28  57   4 857   4   3]\n",
            " [ 47  21   2  10   2   2   5   4 898   9]\n",
            " [ 25  72   1  10   1   7   3   7  26 848]]\n",
            "Epoch 134/200 - Train Loss: 0.3752, Val Loss: 0.5811, Val Accuracy: 82.48%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5941\n",
            "Accuracy: 82.38%\n",
            "F1 Score: 0.8238\n",
            "Confusion Matrix:\n",
            "[[836   8  50  10  19   2  10   4  52   9]\n",
            " [ 15 884   8   4   0   2   6   2  21  58]\n",
            " [ 32   1 786  40  48  31  27  23   9   3]\n",
            " [ 17   2  68 651  65 102  49  35   8   3]\n",
            " [ 11   0  41  30 827  16  25  44   5   1]\n",
            " [  6   0  35 122  37 739  23  31   2   5]\n",
            " [  9   0  47  40  20  12 867   5   0   0]\n",
            " [ 14   0  20  31  32  32   7 860   1   3]\n",
            " [ 52   5  13  10   1   0   3   3 905   8]\n",
            " [ 27  31   9   9   5   5   4   6  21 883]]\n",
            "Epoch 135/200 - Train Loss: 0.3787, Val Loss: 0.5941, Val Accuracy: 82.38%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5415\n",
            "Accuracy: 83.11%\n",
            "F1 Score: 0.8302\n",
            "Confusion Matrix:\n",
            "[[861   7  26  12  14   0   9   6  45  20]\n",
            " [ 10 916   2   2   1   0   4   2  15  48]\n",
            " [ 57   0 752  46  44  19  51  18   8   5]\n",
            " [ 28   2  55 702  40  56  74  21  12  10]\n",
            " [ 19   0  25  42 836  16  34  23   4   1]\n",
            " [  8   1  40 181  37 661  29  38   4   1]\n",
            " [  5   2  26  28  18   1 912   2   4   2]\n",
            " [ 13   1  16  36  33  21   7 863   3   7]\n",
            " [ 37  13   5   8   2   0   4   3 914  14]\n",
            " [ 16  42   2   5   1   3   3   2  32 894]]\n",
            "Epoch 136/200 - Train Loss: 0.3776, Val Loss: 0.5415, Val Accuracy: 83.11%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5767\n",
            "Accuracy: 83.10%\n",
            "F1 Score: 0.8315\n",
            "Confusion Matrix:\n",
            "[[862   9  36  19  12   6   9   8  22  17]\n",
            " [ 18 906   3   5   1   3   8   3  10  43]\n",
            " [ 49   0 765  40  53  44  28  16   1   4]\n",
            " [ 10   1  37 698  48 127  32  41   3   3]\n",
            " [ 10   0  37  38 813  26  34  41   0   1]\n",
            " [  4   2  32 108  31 775   9  37   1   1]\n",
            " [  5   1  37  43  21  19 868   5   1   0]\n",
            " [  3   0  15  31  29  27   4 887   2   2]\n",
            " [ 65  11   3  13   4   6   7  13 858  20]\n",
            " [ 22  42   7  13   4   1   2  19  12 878]]\n",
            "Epoch 137/200 - Train Loss: 0.3721, Val Loss: 0.5767, Val Accuracy: 83.10%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5726\n",
            "Accuracy: 82.90%\n",
            "F1 Score: 0.8290\n",
            "Confusion Matrix:\n",
            "[[813  12  34  13  11   1   7   6  78  25]\n",
            " [  7 893   3   6   1   2   1   1  24  62]\n",
            " [ 33   5 766  45  41  37  42  13   8  10]\n",
            " [ 10   4  47 683  32 126  42  22  24  10]\n",
            " [ 17   1  35  44 811  31  31  20   6   4]\n",
            " [  8   0  28 124  24 783   7  17   4   5]\n",
            " [  5   2  20  45  22  16 875   3   7   5]\n",
            " [  8   1  13  30  40  55   7 832   1  13]\n",
            " [ 27   7   7   5   0   0   4   1 933  16]\n",
            " [ 13  25   6  10   1   2   3   2  37 901]]\n",
            "Epoch 138/200 - Train Loss: 0.3787, Val Loss: 0.5726, Val Accuracy: 82.90%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5491\n",
            "Accuracy: 83.09%\n",
            "F1 Score: 0.8310\n",
            "Confusion Matrix:\n",
            "[[849   8  27  21  11   4   8   5  44  23]\n",
            " [  7 909   1   5   0   3   2   0  15  58]\n",
            " [ 45   3 727  68  41  47  39  14   7   9]\n",
            " [ 12   5  36 705  33 120  46  20  10  13]\n",
            " [ 11   0  33  53 779  28  37  53   5   1]\n",
            " [  7   4  27 133  25 756  15  28   2   3]\n",
            " [  7   3  20  50  18  10 884   1   2   5]\n",
            " [  5   1  10  34  19  33   8 879   0  11]\n",
            " [ 37  13   5  12   1   2   3   3 902  22]\n",
            " [ 14  28   2   8   0   3   3   5  18 919]]\n",
            "Epoch 139/200 - Train Loss: 0.3790, Val Loss: 0.5491, Val Accuracy: 83.09%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5873\n",
            "Accuracy: 82.17%\n",
            "F1 Score: 0.8214\n",
            "Confusion Matrix:\n",
            "[[844  10  42  18  12   5   8   6  38  17]\n",
            " [ 17 924   5   7   0   0   5   0  10  32]\n",
            " [ 38   0 800  37  36  33  39  10   4   3]\n",
            " [ 14   5  55 633  56 137  62  20  13   5]\n",
            " [ 13   2  56  30 833  15  35  13   2   1]\n",
            " [  5   2  35 109  34 775  15  20   3   2]\n",
            " [  4   3  36  24  37  12 880   1   1   2]\n",
            " [ 21   4  28  43  66  40   8 782   1   7]\n",
            " [ 48  22   4  10   2   3   8   4 884  15]\n",
            " [ 24  67   8   7   2   0   4   3  23 862]]\n",
            "Epoch 140/200 - Train Loss: 0.3745, Val Loss: 0.5873, Val Accuracy: 82.17%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5365\n",
            "Accuracy: 83.07%\n",
            "F1 Score: 0.8302\n",
            "Confusion Matrix:\n",
            "[[850  15  30  14   7   1   5   8  42  28]\n",
            " [ 10 932   4   1   2   0   4   0  11  36]\n",
            " [ 40   2 790  31  42  24  38  21   5   7]\n",
            " [ 13   2  54 698  63  73  44  32  10  11]\n",
            " [ 12   0  41  31 833  15  26  35   4   3]\n",
            " [  8   2  40 159  33 700  17  34   1   6]\n",
            " [  8   2  41  39  22   6 875   2   2   3]\n",
            " [ 14   2  23  37  23  27   7 858   2   7]\n",
            " [ 51  14   4   5   3   1   8   2 895  17]\n",
            " [ 13  67   7   7   1   3   2   7  17 876]]\n",
            "Epoch 141/200 - Train Loss: 0.3816, Val Loss: 0.5365, Val Accuracy: 83.07%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5559\n",
            "Accuracy: 83.37%\n",
            "F1 Score: 0.8331\n",
            "Confusion Matrix:\n",
            "[[870  14  23  15  13   2   1   8  40  14]\n",
            " [ 11 929   1   2   1   0   4   4  17  31]\n",
            " [ 42   1 798  37  38  24  27  23   5   5]\n",
            " [ 21   5  59 681  42  89  37  44  16   6]\n",
            " [ 14   2  45  18 838  15  24  41   2   1]\n",
            " [ 11   3  28 158  39 698  10  45   6   2]\n",
            " [  9   1  36  40  33   5 865   5   3   3]\n",
            " [ 16   0  12  25  35  22   2 879   2   7]\n",
            " [ 47  19   5   5   1   1   1   5 910   6]\n",
            " [ 26  53   7  10   2   3   1   5  24 869]]\n",
            "Epoch 142/200 - Train Loss: 0.3785, Val Loss: 0.5559, Val Accuracy: 83.37%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5506\n",
            "Accuracy: 83.16%\n",
            "F1 Score: 0.8316\n",
            "Confusion Matrix:\n",
            "[[846  13  41  14   7   2   9   5  40  23]\n",
            " [  3 937   2   4   0   0   1   0  18  35]\n",
            " [ 44   1 807  39  27  23  32  15   8   4]\n",
            " [ 21   3  58 675  31 145  30  16  13   8]\n",
            " [ 15   2  67  51 758  27  28  45   6   1]\n",
            " [  9   1  36 109  22 775  10  30   5   3]\n",
            " [  9   8  30  49  14  15 866   3   4   2]\n",
            " [ 13   0  19  40  11  44   4 859   2   8]\n",
            " [ 45  14   6   5   0   3   1   1 908  17]\n",
            " [ 18  52   5   5   0   4   4   5  22 885]]\n",
            "Epoch 143/200 - Train Loss: 0.3737, Val Loss: 0.5506, Val Accuracy: 83.16%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5598\n",
            "Accuracy: 82.76%\n",
            "F1 Score: 0.8275\n",
            "Confusion Matrix:\n",
            "[[837   9  36  12   7   1  11  11  57  19]\n",
            " [ 14 899   3   7   0   0   7   2  23  45]\n",
            " [ 43   1 782  37  36  38  34  16   9   4]\n",
            " [ 20   3  56 671  58 101  49  23  14   5]\n",
            " [ 14   0  30  34 830  24  36  28   4   0]\n",
            " [ 12   2  34 124  28 752  19  27   0   2]\n",
            " [ 10   0  41  39  20  14 873   2   1   0]\n",
            " [ 10   1  22  24  44  40   3 852   3   1]\n",
            " [ 41   9  10  14   2   0   4   4 909   7]\n",
            " [ 24  44   7  11   5   1   6   7  24 871]]\n",
            "Epoch 144/200 - Train Loss: 0.3751, Val Loss: 0.5598, Val Accuracy: 82.76%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5618\n",
            "Accuracy: 82.59%\n",
            "F1 Score: 0.8263\n",
            "Confusion Matrix:\n",
            "[[868  10  25  14  10   8   2  17  30  16]\n",
            " [ 13 925   5   7   0   4   0   6   8  32]\n",
            " [ 37   0 775  48  50  32  27  23   6   2]\n",
            " [ 18   3  54 712  38  94  35  34   6   6]\n",
            " [ 10   0  52  50 784  15  25  58   6   0]\n",
            " [  8   3  34 141  21 745  13  30   1   4]\n",
            " [  7   0  40  48  17  11 869   5   2   1]\n",
            " [ 13   1  18  28  15  28   5 890   1   1]\n",
            " [ 70  18   7  11   1   3   6   5 864  15]\n",
            " [ 28  88  10  10   2   4   4  11  16 827]]\n",
            "Epoch 145/200 - Train Loss: 0.3694, Val Loss: 0.5618, Val Accuracy: 82.59%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5572\n",
            "Accuracy: 82.93%\n",
            "F1 Score: 0.8291\n",
            "Confusion Matrix:\n",
            "[[884  10  26  14  12   2  12   7  22  11]\n",
            " [ 13 936   3   4   1   0   3   2  15  23]\n",
            " [ 41   0 788  35  33  38  44   9   7   5]\n",
            " [ 18   3  49 654  49 125  70  23   6   3]\n",
            " [ 14   1  45  34 815  26  37  25   3   0]\n",
            " [  7   1  21 125  35 764  21  22   2   2]\n",
            " [  5   1  23  27  20  11 912   0   1   0]\n",
            " [ 15   1  22  37  36  43   4 836   1   5]\n",
            " [ 83  22   4   9   1   2   6   5 856  12]\n",
            " [ 22  75   7  10   2   3  10   9  14 848]]\n",
            "Epoch 146/200 - Train Loss: 0.3771, Val Loss: 0.5572, Val Accuracy: 82.93%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5641\n",
            "Accuracy: 82.71%\n",
            "F1 Score: 0.8267\n",
            "Confusion Matrix:\n",
            "[[871   6  26  15  12   1   3  10  30  26]\n",
            " [ 13 909   0   3   1   0   4   0  12  58]\n",
            " [ 41   2 755  46  48  28  40  29   3   8]\n",
            " [ 18   3  46 708  56  72  35  45  12   5]\n",
            " [ 14   2  36  34 827  18  25  39   4   1]\n",
            " [  6   3  41 176  43 672  12  39   4   4]\n",
            " [  8   1  33  50  34   6 856   6   4   2]\n",
            " [ 16   0   9  33  27  19   3 886   0   7]\n",
            " [ 60  19   4   4   3   1   6   3 876  24]\n",
            " [ 22  33   3   5   1   1   5   7  12 911]]\n",
            "Epoch 147/200 - Train Loss: 0.3700, Val Loss: 0.5641, Val Accuracy: 82.71%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5234\n",
            "Accuracy: 83.50%\n",
            "F1 Score: 0.8350\n",
            "Confusion Matrix:\n",
            "[[863   8  16  21  14   1   5  10  40  22]\n",
            " [ 13 922   1   5   0   1   4   2  16  36]\n",
            " [ 59   2 732  56  48  33  36  23   9   2]\n",
            " [ 21   3  32 716  40  98  40  32  11   7]\n",
            " [ 21   0  33  43 812  20  26  43   1   1]\n",
            " [  8   1  19 148  21 759  11  32   0   1]\n",
            " [  8   0  30  40  20  10 885   4   2   1]\n",
            " [  9   1  16  29  25  25   4 883   1   7]\n",
            " [ 42  15   5  14   0   2   4   4 900  14]\n",
            " [ 14  59   5   9   1   2   4   7  21 878]]\n",
            "Epoch 148/200 - Train Loss: 0.3726, Val Loss: 0.5234, Val Accuracy: 83.50%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5681\n",
            "Accuracy: 82.12%\n",
            "F1 Score: 0.8208\n",
            "Confusion Matrix:\n",
            "[[894  16  11  13   8   1   7   5  29  16]\n",
            " [  8 948   1   5   0   1   2   0   7  28]\n",
            " [ 71   5 731  46  39  45  41  12   7   3]\n",
            " [ 18   8  42 679  54 102  46  29   8  14]\n",
            " [ 23   4  37  33 816  18  31  32   4   2]\n",
            " [ 18   2  33 140  29 737  12  22   0   7]\n",
            " [  7   3  22  39  25  10 886   4   3   1]\n",
            " [ 32   7  11  43  44  30   7 816   1   9]\n",
            " [ 67  25   5  10   2   0   1   1 866  23]\n",
            " [ 26  85   4  10   3   2   6   5  20 839]]\n",
            "Epoch 149/200 - Train Loss: 0.3695, Val Loss: 0.5681, Val Accuracy: 82.12%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5465\n",
            "Accuracy: 83.04%\n",
            "F1 Score: 0.8294\n",
            "Confusion Matrix:\n",
            "[[830  12  46  16  14   1   4   5  58  14]\n",
            " [ 16 922   1   3   0   2   4   2  16  34]\n",
            " [ 38   3 793  30  43  32  33  20   6   2]\n",
            " [ 11   4  54 614  54 171  48  26  13   5]\n",
            " [ 11   1  47  27 832  18  33  28   3   0]\n",
            " [  6   1  43  88  35 785  12  23   2   5]\n",
            " [  6   4  25  35  22  16 879   3   7   3]\n",
            " [ 13   4  16  22  37  36   5 857   2   8]\n",
            " [ 29  12  10   6   4   2   6   5 916  10]\n",
            " [ 18  55   5   3   1   1   2   7  32 876]]\n",
            "Epoch 150/200 - Train Loss: 0.3678, Val Loss: 0.5465, Val Accuracy: 83.04%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5691\n",
            "Accuracy: 82.82%\n",
            "F1 Score: 0.8298\n",
            "Confusion Matrix:\n",
            "[[826  12  28  24   9   7   8   5  58  23]\n",
            " [ 16 900   4  11   1   2   3   2  18  43]\n",
            " [ 30   0 752  63  46  50  35  13   7   4]\n",
            " [ 12   4  31 709  28 162  31  13   5   5]\n",
            " [ 13   0  24  49 822  38  22  27   4   1]\n",
            " [  8   1  21 120  22 802   9  16   0   1]\n",
            " [  6   0  25  67  27  16 848   4   7   0]\n",
            " [  8   0  17  43  28  57   6 836   0   5]\n",
            " [ 35  13   4  14   4   1   4   4 903  18]\n",
            " [ 19  40   6  15   4   3   3   4  22 884]]\n",
            "Epoch 151/200 - Train Loss: 0.3665, Val Loss: 0.5691, Val Accuracy: 82.82%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5457\n",
            "Accuracy: 83.84%\n",
            "F1 Score: 0.8375\n",
            "Confusion Matrix:\n",
            "[[834  20  26  12  18   3   6  12  49  20]\n",
            " [  6 947   5   2   1   2   1   0   7  29]\n",
            " [ 30   0 767  37  57  50  35  15   5   4]\n",
            " [ 16   3  36 646  61 139  53  27  12   7]\n",
            " [  6   1  30  28 846  19  32  32   3   3]\n",
            " [  5   3  29  91  33 797  12  26   2   2]\n",
            " [  5   3  24  30  15  17 900   4   1   1]\n",
            " [  5   0  13  24  28  42   3 876   1   8]\n",
            " [ 42  25   5   8   1   1   6   3 892  17]\n",
            " [ 13  64   2  10   1   2   5  11  13 879]]\n",
            "Epoch 152/200 - Train Loss: 0.3730, Val Loss: 0.5457, Val Accuracy: 83.84%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6001\n",
            "Accuracy: 82.38%\n",
            "F1 Score: 0.8246\n",
            "Confusion Matrix:\n",
            "[[845   3  17  19   8   2   1   5  73  27]\n",
            " [ 17 902   1   6   1   1   1   0  38  33]\n",
            " [ 65   1 765  40  52  30  21   8  15   3]\n",
            " [ 12   3  41 733  50  93  30  10  20   8]\n",
            " [ 13   2  29  32 841  25  23  24   9   2]\n",
            " [ 11   0  43 156  30 731   9  12   6   2]\n",
            " [  8   4  36  60  35   7 840   3   6   1]\n",
            " [ 12   0  21  51  59  43   1 793   7  13]\n",
            " [ 30   6   5  10   1   1   0   1 931  15]\n",
            " [ 17  56   7  12   2   3   2   2  42 857]]\n",
            "Epoch 153/200 - Train Loss: 0.3656, Val Loss: 0.6001, Val Accuracy: 82.38%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5619\n",
            "Accuracy: 83.21%\n",
            "F1 Score: 0.8316\n",
            "Confusion Matrix:\n",
            "[[846  11  39  22   9   1   4   5  32  31]\n",
            " [  5 949   3   1   0   0   2   1   4  35]\n",
            " [ 45   2 799  30  40  14  45  15   5   5]\n",
            " [ 23   5  70 695  49  75  45  20   8  10]\n",
            " [ 20   2  43  32 821   7  38  31   5   1]\n",
            " [  9   3  54 140  38 697  16  35   2   6]\n",
            " [  9   4  35  29  19   3 897   3   1   0]\n",
            " [ 10   2  34  32  31  18   8 855   2   8]\n",
            " [ 49  24   5  14   8   1   5   2 874  18]\n",
            " [ 16  65   5   5   2   0   3   3  13 888]]\n",
            "Epoch 154/200 - Train Loss: 0.3697, Val Loss: 0.5619, Val Accuracy: 83.21%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5647\n",
            "Accuracy: 83.24%\n",
            "F1 Score: 0.8323\n",
            "Confusion Matrix:\n",
            "[[829   9  29  17  11   3   7  11  61  23]\n",
            " [  5 915   3   3   0   2   6   1  28  37]\n",
            " [ 54   0 754  49  53  26  37  14   8   5]\n",
            " [  9   3  47 698  49 100  50  28  10   6]\n",
            " [ 12   0  25  39 846  16  30  27   5   0]\n",
            " [ 10   3  27 163  34 718   9  30   3   3]\n",
            " [  4   0  20  51  17   5 894   3   2   4]\n",
            " [  9   2  14  30  33  27   8 866   4   7]\n",
            " [ 31   9   3  14   3   0   6   3 915  16]\n",
            " [ 15  42   3  13   2   2   8   6  20 889]]\n",
            "Epoch 155/200 - Train Loss: 0.3754, Val Loss: 0.5647, Val Accuracy: 83.24%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5350\n",
            "Accuracy: 83.49%\n",
            "F1 Score: 0.8356\n",
            "Confusion Matrix:\n",
            "[[900   7  25  12   4   2   3   9  22  16]\n",
            " [ 19 896   2   5   1   0   1   2  17  57]\n",
            " [ 60   2 739  49  50  37  30  21   6   6]\n",
            " [ 19   2  40 737  41  86  42  15   8  10]\n",
            " [ 16   1  23  54 826  24  30  20   4   2]\n",
            " [  8   3  25 169  25 733   9  26   0   2]\n",
            " [ 10   0  22  55  20  10 872   3   4   4]\n",
            " [ 16   1  14  49  34  28   2 842   2  12]\n",
            " [ 66  10   4  11   1   0   2   1 893  12]\n",
            " [ 20  33   2   5   1   0   5   3  20 911]]\n",
            "Epoch 156/200 - Train Loss: 0.3761, Val Loss: 0.5350, Val Accuracy: 83.49%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5384\n",
            "Accuracy: 83.66%\n",
            "F1 Score: 0.8368\n",
            "Confusion Matrix:\n",
            "[[894   3  34  15   7   2   6   8  22   9]\n",
            " [ 22 910   3   2   2   2   6   3  11  39]\n",
            " [ 38   1 753  42  51  28  62  18   4   3]\n",
            " [ 10   3  30 719  45  95  65  21   6   6]\n",
            " [ 19   1  31  37 805  26  49  29   3   0]\n",
            " [  8   1  22 130  26 754  21  35   0   3]\n",
            " [  8   0  23  36  12   7 909   1   2   2]\n",
            " [ 20   0  14  40  22  28   5 865   1   5]\n",
            " [ 71   7   6  10   1   1   8   3 871  22]\n",
            " [ 29  42   3  11   0   1   8   9  11 886]]\n",
            "Epoch 157/200 - Train Loss: 0.3623, Val Loss: 0.5384, Val Accuracy: 83.66%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5845\n",
            "Accuracy: 82.76%\n",
            "F1 Score: 0.8266\n",
            "Confusion Matrix:\n",
            "[[822  11  40  12   8   1  10   6  70  20]\n",
            " [  8 918   6   3   0   2   2   0  28  33]\n",
            " [ 27   0 824  29  40  26  30  10  10   4]\n",
            " [ 22   5  68 639  65  91  56  26  20   8]\n",
            " [ 18   1  42  19 826  19  42  27   4   2]\n",
            " [ 13   3  52 115  43 732  10  22   5   5]\n",
            " [  8   4  36  34  16   7 884   3   6   2]\n",
            " [ 18   0  34  25  31  28   4 849   6   5]\n",
            " [ 26   7   7   6   3   1   6   4 932   8]\n",
            " [ 11  77   5   6   2   3   6   3  37 850]]\n",
            "Epoch 158/200 - Train Loss: 0.3651, Val Loss: 0.5845, Val Accuracy: 82.76%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5848\n",
            "Accuracy: 82.38%\n",
            "F1 Score: 0.8244\n",
            "Confusion Matrix:\n",
            "[[854   9  32  19  10   3   5   8  39  21]\n",
            " [ 13 887   1   2   1   3   2   1  23  67]\n",
            " [ 54   1 772  44  36  43  21  18   7   4]\n",
            " [ 16   1  61 709  44  98  29  22  14   6]\n",
            " [ 20   1  49  46 787  22  32  42   1   0]\n",
            " [  6   0  33 155  30 728  10  31   2   5]\n",
            " [  6   1  61  52  23  10 838   5   2   2]\n",
            " [  9   2  12  34  26  43   2 861   1  10]\n",
            " [ 58   7   6   6   1   0   4   3 896  19]\n",
            " [ 21  29   4   8   1   3   4   4  20 906]]\n",
            "Epoch 159/200 - Train Loss: 0.3733, Val Loss: 0.5848, Val Accuracy: 82.38%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5605\n",
            "Accuracy: 83.65%\n",
            "F1 Score: 0.8361\n",
            "Confusion Matrix:\n",
            "[[855  11  16  16  10   2   6   7  58  19]\n",
            " [  6 944   2   6   0   0   1   2  12  27]\n",
            " [ 54   2 717  49  50  46  51  12  12   7]\n",
            " [ 17   2  28 722  42 110  36  25  13   5]\n",
            " [ 16   1  25  48 805  19  42  35   7   2]\n",
            " [ 11   0  26 130  29 766   9  25   0   4]\n",
            " [  5   1  21  54  14  16 882   4   1   2]\n",
            " [ 12   1  12  25  23  35   5 875   4   8]\n",
            " [ 37  13   2   5   1   0   2   4 924  12]\n",
            " [ 10  70   4   8   2   1   2   8  20 875]]\n",
            "Epoch 160/200 - Train Loss: 0.3665, Val Loss: 0.5605, Val Accuracy: 83.65%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5691\n",
            "Accuracy: 82.26%\n",
            "F1 Score: 0.8230\n",
            "Confusion Matrix:\n",
            "[[808  25  41  16  10   0   6  13  28  53]\n",
            " [  3 938   3   6   1   1   1   0   5  42]\n",
            " [ 37   4 770  51  46  27  38  15   5   7]\n",
            " [ 16   3  46 731  26  70  51  33  11  13]\n",
            " [ 17   2  29  69 796  15  33  36   3   0]\n",
            " [  6   6  30 203  26 680  17  25   1   6]\n",
            " [  7   5  28  50  21  10 871   2   4   2]\n",
            " [ 13   1  20  41  23  21   4 860   2  15]\n",
            " [ 40  19   4  11   2   0   9   2 856  57]\n",
            " [  8  47   6   8   0   1   3   4   7 916]]\n",
            "Epoch 161/200 - Train Loss: 0.3692, Val Loss: 0.5691, Val Accuracy: 82.26%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5737\n",
            "Accuracy: 83.14%\n",
            "F1 Score: 0.8305\n",
            "Confusion Matrix:\n",
            "[[846   8  24   7  11   3   5  10  68  18]\n",
            " [ 11 871   4   2   1   0   2   3  23  83]\n",
            " [ 38   2 737  42  62  37  33  27  11  11]\n",
            " [ 13   2  36 695  58  84  36  48  18  10]\n",
            " [ 13   0  19  24 859   7  22  47   5   4]\n",
            " [  4   2  29 146  35 720   8  41   8   7]\n",
            " [  9   1  34  39  34  11 861   5   4   2]\n",
            " [ 10   0  13  26  29  21   5 888   3   5]\n",
            " [ 29   6   2   3   3   1   3   4 935  14]\n",
            " [ 14  31   4   4   1   1   3   8  32 902]]\n",
            "Epoch 162/200 - Train Loss: 0.3771, Val Loss: 0.5737, Val Accuracy: 83.14%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5554\n",
            "Accuracy: 83.59%\n",
            "F1 Score: 0.8365\n",
            "Confusion Matrix:\n",
            "[[878  12  28  15   4   1   5   6  35  16]\n",
            " [ 14 924   1   6   1   0   0   3  13  38]\n",
            " [ 53   2 777  45  46  33  16  18   4   6]\n",
            " [ 25   3  52 697  36 124  22  27   7   7]\n",
            " [ 19   0  30  49 810  28  10  51   3   0]\n",
            " [ 16   1  24 128  22 772   4  27   3   3]\n",
            " [  8   1  28  53  29  21 844   4   8   4]\n",
            " [  7   2  22  31  18  27   3 886   0   4]\n",
            " [ 62  14   7  13   2   1   1   5 883  12]\n",
            " [ 21  48   6   8   0   3   3   4  19 888]]\n",
            "Epoch 163/200 - Train Loss: 0.3703, Val Loss: 0.5554, Val Accuracy: 83.59%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5592\n",
            "Accuracy: 83.44%\n",
            "F1 Score: 0.8337\n",
            "Confusion Matrix:\n",
            "[[862   9  30  12  11   2   7  10  34  23]\n",
            " [ 17 886   3   3   0   1   3   1  13  73]\n",
            " [ 40   1 783  40  46  39  33  10   3   5]\n",
            " [ 19   5  41 615  54 178  52  17  10   9]\n",
            " [ 10   0  32  24 853  19  39  17   5   1]\n",
            " [  9   0  27  85  36 803  13  21   1   5]\n",
            " [  2   2  31  31  23  13 889   4   4   1]\n",
            " [  6   1  10  21  42  46   8 855   3   8]\n",
            " [ 60  10   9   5   1   1   2   0 890  22]\n",
            " [ 18  22   7   9   3   1   5   8  19 908]]\n",
            "Epoch 164/200 - Train Loss: 0.3638, Val Loss: 0.5592, Val Accuracy: 83.44%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5832\n",
            "Accuracy: 82.92%\n",
            "F1 Score: 0.8291\n",
            "Confusion Matrix:\n",
            "[[870   7  27   9   8   4   3  11  41  20]\n",
            " [ 15 908   2   6   0   1   3   3  16  46]\n",
            " [ 46   0 802  33  29  40  27  13   3   7]\n",
            " [ 26   3  60 659  28 132  43  29  11   9]\n",
            " [ 23   1  64  46 740  51  40  29   5   1]\n",
            " [  7   2  47 108  15 777  12  29   2   1]\n",
            " [  7   2  29  33  14  21 885   4   3   2]\n",
            " [ 12   1  23  24  15  46   2 873   1   3]\n",
            " [ 41  15   9   7   2   3   3   4 902  14]\n",
            " [ 32  38   6  10   2   3   5   8  20 876]]\n",
            "Epoch 165/200 - Train Loss: 0.3674, Val Loss: 0.5832, Val Accuracy: 82.92%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5579\n",
            "Accuracy: 83.07%\n",
            "F1 Score: 0.8306\n",
            "Confusion Matrix:\n",
            "[[848  13  27  10  17   3   4  13  42  23]\n",
            " [ 10 912   6   6   0   1   2   4  17  42]\n",
            " [ 40   2 767  34  50  48  25  26   5   3]\n",
            " [ 20   4  37 661  47 140  35  42   9   5]\n",
            " [ 14   0  41  31 836  24  14  37   3   0]\n",
            " [  8   0  22 107  25 790   2  42   1   3]\n",
            " [  4   1  46  39  41  22 838   4   3   2]\n",
            " [ 12   4  11  24  24  46   3 872   2   2]\n",
            " [ 48  12   8   7   2   3   1  10 895  14]\n",
            " [ 17  43   4   7   1   4   2  13  21 888]]\n",
            "Epoch 166/200 - Train Loss: 0.3671, Val Loss: 0.5579, Val Accuracy: 83.07%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5615\n",
            "Accuracy: 83.37%\n",
            "F1 Score: 0.8341\n",
            "Confusion Matrix:\n",
            "[[849   6  46  12   7   3   6   9  47  15]\n",
            " [  8 924   6   3   2   1   1   1  13  41]\n",
            " [ 31   0 831  30  33  33  18   9   5  10]\n",
            " [ 20   2  68 686  43  87  44  27  12  11]\n",
            " [ 18   0  54  37 826  12  24  25   4   0]\n",
            " [  7   1  42 146  28 739   9  25   1   2]\n",
            " [  6   3  58  37  23  12 849   4   6   2]\n",
            " [ 18   0  30  33  33  33   1 848   1   3]\n",
            " [ 41  11   7  10   1   4   2   4 908  12]\n",
            " [ 23  52   8   6   1   3   4   8  18 877]]\n",
            "Epoch 167/200 - Train Loss: 0.3590, Val Loss: 0.5615, Val Accuracy: 83.37%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5397\n",
            "Accuracy: 83.57%\n",
            "F1 Score: 0.8356\n",
            "Confusion Matrix:\n",
            "[[824   3  49  16  10   3   6  10  53  26]\n",
            " [  8 887   5   2   1   1   8   1  18  69]\n",
            " [ 24   1 781  36  43  47  37  13   7  11]\n",
            " [ 11   4  31 684  54 134  44  17   8  13]\n",
            " [ 12   1  22  30 863  21  18  27   5   1]\n",
            " [  3   1  28 123  37 770  10  22   2   4]\n",
            " [  9   3  38  34  34  11 862   6   1   2]\n",
            " [ 11   0   9  29  33  45   2 860   2   9]\n",
            " [ 43   9  10   8   1   2   3   1 909  14]\n",
            " [ 10  34   3   5   1   1   5   3  21 917]]\n",
            "Epoch 168/200 - Train Loss: 0.3651, Val Loss: 0.5397, Val Accuracy: 83.57%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5740\n",
            "Accuracy: 82.23%\n",
            "F1 Score: 0.8222\n",
            "Confusion Matrix:\n",
            "[[788   7  43  24  19   1   7  13  73  25]\n",
            " [ 11 906   4   3   1   2   5   3  21  44]\n",
            " [ 33   0 760  47  50  29  38  27  14   2]\n",
            " [ 15   5  41 710  53  82  48  35   8   3]\n",
            " [  9   0  30  42 831  17  36  30   4   1]\n",
            " [  5   1  38 184  39 682  12  34   0   5]\n",
            " [  5   2  29  39  24  10 879   7   3   2]\n",
            " [  9   0  13  33  36  23   5 874   0   7]\n",
            " [ 33   9   8  13   6   0   7   4 910  10]\n",
            " [ 14  50   6   6   2   0   4  11  24 883]]\n",
            "Epoch 169/200 - Train Loss: 0.3605, Val Loss: 0.5740, Val Accuracy: 82.23%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5748\n",
            "Accuracy: 83.20%\n",
            "F1 Score: 0.8324\n",
            "Confusion Matrix:\n",
            "[[847  15  30  18   7   1   4   5  44  29]\n",
            " [  9 922   2   3   2   1   4   1  15  41]\n",
            " [ 45   1 777  44  53  30  29  10   9   2]\n",
            " [ 17   4  65 704  44 101  29  21  11   4]\n",
            " [ 12   2  34  47 848  15  21  18   3   0]\n",
            " [ 12   1  29 128  45 753   8  20   3   1]\n",
            " [ 12   0  31  50  31   7 861   4   4   0]\n",
            " [ 16   3  26  35  49  42   2 817   3   7]\n",
            " [ 46  14   6   3   2   1   3   0 913  12]\n",
            " [ 12  55   9   6   3   4   4   2  27 878]]\n",
            "Epoch 170/200 - Train Loss: 0.3646, Val Loss: 0.5748, Val Accuracy: 83.20%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5707\n",
            "Accuracy: 82.59%\n",
            "F1 Score: 0.8265\n",
            "Confusion Matrix:\n",
            "[[891   5  16  12   9   1   6  10  25  25]\n",
            " [ 17 920   1   3   0   1   3   1  13  41]\n",
            " [ 63   4 733  65  37  25  43  19   5   6]\n",
            " [ 21   1  26 758  41  70  39  30   6   8]\n",
            " [ 26   3  37  51 780  20  37  36   7   3]\n",
            " [ 10   3  27 210  25 683   9  29   3   1]\n",
            " [ 10   0  27  65  16   7 871   0   3   1]\n",
            " [ 16   1  17  39  28  29   8 854   1   7]\n",
            " [ 61  10   5   8   1   0   4   1 890  20]\n",
            " [ 18  60   4  13   1   0   3   3  19 879]]\n",
            "Epoch 171/200 - Train Loss: 0.3659, Val Loss: 0.5707, Val Accuracy: 82.59%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5675\n",
            "Accuracy: 82.92%\n",
            "F1 Score: 0.8295\n",
            "Confusion Matrix:\n",
            "[[842  12  39  15  11   2   6  16  32  25]\n",
            " [ 10 916   9   8   1   0   3   2  10  41]\n",
            " [ 35   3 764  39  63  42  33  13   4   4]\n",
            " [ 18   4  47 675  70 123  33  18   7   5]\n",
            " [ 11   0  36  24 849  31  20  24   4   1]\n",
            " [  7   1  28 104  43 776  10  29   2   0]\n",
            " [  8   0  43  34  26  15 867   1   3   3]\n",
            " [  9   2  26  29  46  46   2 837   1   2]\n",
            " [ 53  17  10   8   6   1   0   6 885  14]\n",
            " [ 16  48   7  18   1   1   1   7  20 881]]\n",
            "Epoch 172/200 - Train Loss: 0.3645, Val Loss: 0.5675, Val Accuracy: 82.92%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5821\n",
            "Accuracy: 83.03%\n",
            "F1 Score: 0.8293\n",
            "Confusion Matrix:\n",
            "[[852   8  26  11   7   4   2  10  59  21]\n",
            " [ 16 891   4   3   1   2   5   1  26  51]\n",
            " [ 44   3 784  34  40  24  39  14  10   8]\n",
            " [ 19   4  53 652  49 105  56  32  16  14]\n",
            " [ 18   1  39  35 805  17  39  36   9   1]\n",
            " [ 10   0  32 122  34 737  19  41   4   1]\n",
            " [ 10   2  34  35  11   8 891   5   1   3]\n",
            " [ 10   1  15  24  29  34   4 870   3  10]\n",
            " [ 32   7   3   9   1   0   4   4 920  20]\n",
            " [ 20  37   5   6   1   3   1   1  25 901]]\n",
            "Epoch 173/200 - Train Loss: 0.3671, Val Loss: 0.5821, Val Accuracy: 83.03%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5923\n",
            "Accuracy: 82.85%\n",
            "F1 Score: 0.8297\n",
            "Confusion Matrix:\n",
            "[[852  16  26  17   5   5   7   6  40  26]\n",
            " [  7 936   2   5   0   0   4   1   2  43]\n",
            " [ 46   4 753  65  38  34  38  11   3   8]\n",
            " [ 15   8  32 762  31  84  41  15   7   5]\n",
            " [ 14   1  38  70 788  24  34  28   3   0]\n",
            " [  9   2  22 181  27 724   9  19   2   5]\n",
            " [  7   3  18  53  19  13 878   4   2   3]\n",
            " [ 13   4  16  47  27  37   7 841   0   8]\n",
            " [ 44  29   5  16   0   0   5   2 872  27]\n",
            " [ 15  60   5  14   0   2   6   4  15 879]]\n",
            "Epoch 174/200 - Train Loss: 0.3565, Val Loss: 0.5923, Val Accuracy: 82.85%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5802\n",
            "Accuracy: 83.19%\n",
            "F1 Score: 0.8309\n",
            "Confusion Matrix:\n",
            "[[846   9  20  16  15   1   7   7  48  31]\n",
            " [  8 897   6   4   1   0   4   2  11  67]\n",
            " [ 48   1 758  43  47  25  44  19   7   8]\n",
            " [ 16   1  50 671  55  80  55  37  16  19]\n",
            " [ 11   1  30  30 825  14  48  37   2   2]\n",
            " [ 12   2  26 138  29 722  22  43   2   4]\n",
            " [  7   2  18  30  17   6 914   3   1   2]\n",
            " [ 12   2  22  23  31  27   4 867   4   8]\n",
            " [ 42  11   3   8   1   0   3   3 901  28]\n",
            " [ 16  28   3   9   1   0   3   4  18 918]]\n",
            "Epoch 175/200 - Train Loss: 0.3595, Val Loss: 0.5802, Val Accuracy: 83.19%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5984\n",
            "Accuracy: 82.06%\n",
            "F1 Score: 0.8198\n",
            "Confusion Matrix:\n",
            "[[811  10  30  20  12   2  13   7  66  29]\n",
            " [ 13 891   1   3   2   0   2   0  27  61]\n",
            " [ 37   2 745  47  39  34  59  14  15   8]\n",
            " [ 13   5  44 655  37 112  66  30  23  15]\n",
            " [ 12   1  34  47 766  26  52  50   8   4]\n",
            " [  4   1  29 129  16 749  26  39   3   4]\n",
            " [  9   3  18  37  14  14 896   1   6   2]\n",
            " [  6   0  16  24  20  44   8 868   3  11]\n",
            " [ 32   6   3   9   1   0   5   3 920  21]\n",
            " [ 14  27   2   8   1   1   6   2  34 905]]\n",
            "Epoch 176/200 - Train Loss: 0.3566, Val Loss: 0.5984, Val Accuracy: 82.06%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5354\n",
            "Accuracy: 82.89%\n",
            "F1 Score: 0.8285\n",
            "Confusion Matrix:\n",
            "[[879  10  21  13   9   1   4  10  30  23]\n",
            " [  9 935   1   2   1   4   1   1   5  41]\n",
            " [ 61   5 711  54  39  45  44  25   8   8]\n",
            " [ 27   7  36 722  41  72  40  36   7  12]\n",
            " [ 14   1  32  49 802  19  15  58   7   3]\n",
            " [ 10   0  29 159  29 713  18  39   0   3]\n",
            " [ 12   6  21  44  29  13 858  11   4   2]\n",
            " [ 10   2  12  34  24  20   2 883   0  13]\n",
            " [ 51  18   1   5   2   0   4   5 901  13]\n",
            " [ 18  50   1  12   1   3   0   7  23 885]]\n",
            "Epoch 177/200 - Train Loss: 0.3662, Val Loss: 0.5354, Val Accuracy: 82.89%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5671\n",
            "Accuracy: 82.86%\n",
            "F1 Score: 0.8283\n",
            "Confusion Matrix:\n",
            "[[843   8  42  13   6   2   6  12  45  23]\n",
            " [  9 927   2   1   0   2   4   2  15  38]\n",
            " [ 32   3 811  40  24  32  29  12  13   4]\n",
            " [ 12   1  57 668  30 136  54  20  16   6]\n",
            " [ 17   0  68  57 730  29  60  35   4   0]\n",
            " [  6   3  34 108  19 786  13  29   1   1]\n",
            " [  7   0  43  34   6  10 894   2   4   0]\n",
            " [ 11   1  27  27  22  50   3 851   3   5]\n",
            " [ 37  11   7   8   1   2   4   4 911  15]\n",
            " [ 16  65   7   9   2   3   5   2  26 865]]\n",
            "Epoch 178/200 - Train Loss: 0.3590, Val Loss: 0.5671, Val Accuracy: 82.86%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5780\n",
            "Accuracy: 82.90%\n",
            "F1 Score: 0.8295\n",
            "Confusion Matrix:\n",
            "[[801  13  32  29  13   3   6   9  62  32]\n",
            " [ 10 912   4   3   0   3   4   1  16  47]\n",
            " [ 35   4 757  45  56  46  25  15   8   9]\n",
            " [ 11   5  29 722  44 118  35  22   6   8]\n",
            " [  4   1  29  38 846  26  26  26   3   1]\n",
            " [  4   4  32 129  27 768   8  21   2   5]\n",
            " [  6   1  34  50  31  27 840   6   2   3]\n",
            " [ 13   0  15  33  50  47   3 831   0   8]\n",
            " [ 37  16   1  13   4   0   6   3 902  18]\n",
            " [ 11  39   3  11   4   0   2   1  18 911]]\n",
            "Epoch 179/200 - Train Loss: 0.3649, Val Loss: 0.5780, Val Accuracy: 82.90%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5796\n",
            "Accuracy: 82.69%\n",
            "F1 Score: 0.8258\n",
            "Confusion Matrix:\n",
            "[[848  11  22  15  16   2   7  10  52  17]\n",
            " [ 11 909   1   9   0   0   2   4  28  36]\n",
            " [ 46   3 763  39  44  37  28  25   8   7]\n",
            " [ 14   4  49 654  52 109  51  44  15   8]\n",
            " [ 11   3  36  36 809  11  38  52   4   0]\n",
            " [  6   2  35 127  41 716  19  47   3   4]\n",
            " [  6   5  22  27  25   7 892   8   7   1]\n",
            " [  9   1  14  27  26  31   7 877   4   4]\n",
            " [ 29   7   4   8   1   1   1   5 929  15]\n",
            " [ 22  56   1   9   1   0   2   8  29 872]]\n",
            "Epoch 180/200 - Train Loss: 0.3656, Val Loss: 0.5796, Val Accuracy: 82.69%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5851\n",
            "Accuracy: 82.96%\n",
            "F1 Score: 0.8287\n",
            "Confusion Matrix:\n",
            "[[846  11  21  18   7   1   6   8  68  14]\n",
            " [ 12 911   2   4   1   0   8   2  25  35]\n",
            " [ 36   1 763  43  46  39  45  10  13   4]\n",
            " [ 12   4  31 669  34 117  71  30  22  10]\n",
            " [  6   2  39  40 772  29  56  52   4   0]\n",
            " [  7   3  18 129  22 752  20  37   5   7]\n",
            " [  7   1  25  25   7  10 918   3   4   0]\n",
            " [ 16   2  12  33  19  28   5 878   5   2]\n",
            " [ 31  16   1   6   0   1   3   4 930   8]\n",
            " [ 23  55   2   3   2   2   9   6  41 857]]\n",
            "Epoch 181/200 - Train Loss: 0.3553, Val Loss: 0.5851, Val Accuracy: 82.96%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5856\n",
            "Accuracy: 82.93%\n",
            "F1 Score: 0.8295\n",
            "Confusion Matrix:\n",
            "[[848  11  31  17   7   2   6  11  34  33]\n",
            " [  9 912   2   5   0   1   3   2   5  61]\n",
            " [ 42   0 788  45  61  17  23  12   3   9]\n",
            " [ 18   3  55 673  57 122  34  18   6  14]\n",
            " [ 10   0  36  38 849  12  19  31   3   2]\n",
            " [  8   0  40 119  43 742  10  31   0   7]\n",
            " [  6   3  33  40  38  13 857   1   1   8]\n",
            " [ 13   0  27  37  49  28   4 829   2  11]\n",
            " [ 64  17  12  12   1   1   2   0 861  30]\n",
            " [  9  27   3   6   2   1   0   4  14 934]]\n",
            "Epoch 182/200 - Train Loss: 0.3650, Val Loss: 0.5856, Val Accuracy: 82.93%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5628\n",
            "Accuracy: 82.79%\n",
            "F1 Score: 0.8280\n",
            "Confusion Matrix:\n",
            "[[826  10  35  13  13   0   5   5  55  38]\n",
            " [  9 924   3   4   0   0   2   0  16  42]\n",
            " [ 43   2 789  52  44  20  29   7   6   8]\n",
            " [ 12   3  45 719  47  87  45  18  13  11]\n",
            " [ 14   2  36  39 825  16  35  27   6   0]\n",
            " [  5   1  27 186  36 699  13  21   2  10]\n",
            " [  4   6  31  43  23   9 870   5   4   5]\n",
            " [ 14   0  30  35  42  42   6 817   3  11]\n",
            " [ 35  19   4   5   4   0   4   1 910  18]\n",
            " [ 15  52   4   5   3   1   5   2  13 900]]\n",
            "Epoch 183/200 - Train Loss: 0.3606, Val Loss: 0.5628, Val Accuracy: 82.79%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5526\n",
            "Accuracy: 83.75%\n",
            "F1 Score: 0.8374\n",
            "Confusion Matrix:\n",
            "[[852  11  21  23   6   2   7  11  38  29]\n",
            " [  7 913   0   5   0   2   2   0  16  55]\n",
            " [ 37   2 753  58  45  27  48  20   2   8]\n",
            " [ 14   4  32 721  29  86  62  30  12  10]\n",
            " [ 16   4  29  48 794  23  38  43   4   1]\n",
            " [  7   5  24 161  18 731  11  37   3   3]\n",
            " [  6   5  16  49  18  11 888   2   1   4]\n",
            " [ 10   1   9  23  24  21   4 900   0   8]\n",
            " [ 42   7   7  12   2   1   2   2 910  15]\n",
            " [ 12  40   1   5   1   2   3   6  17 913]]\n",
            "Epoch 184/200 - Train Loss: 0.3660, Val Loss: 0.5526, Val Accuracy: 83.75%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5407\n",
            "Accuracy: 83.44%\n",
            "F1 Score: 0.8346\n",
            "Confusion Matrix:\n",
            "[[852  15  32  24   7   1   3   8  36  22]\n",
            " [  8 939   2   6   2   1   2   1   9  30]\n",
            " [ 42   4 780  49  39  36  25  18   3   4]\n",
            " [ 17   3  43 714  45  93  40  30   8   7]\n",
            " [ 14   0  46  32 822  18  25  39   4   0]\n",
            " [  5   2  34 162  35 718   9  31   2   2]\n",
            " [  7   1  32  40  25  12 876   4   2   1]\n",
            " [  5   1  16  36  20  32   7 876   0   7]\n",
            " [ 47  25   5  10   1   1   6   4 887  14]\n",
            " [ 11  62   3  12   3   3   3   7  16 880]]\n",
            "Epoch 185/200 - Train Loss: 0.3605, Val Loss: 0.5407, Val Accuracy: 83.44%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5866\n",
            "Accuracy: 82.62%\n",
            "F1 Score: 0.8252\n",
            "Confusion Matrix:\n",
            "[[848  14  27  13  19   4   5   8  34  28]\n",
            " [ 12 930   4   7   1   3   4   1  12  26]\n",
            " [ 47   1 738  38  62  38  47  13  10   6]\n",
            " [ 15   4  46 601  67 181  46  21   9  10]\n",
            " [ 12   0  27  31 839  32  28  29   2   0]\n",
            " [  8   2  25  81  30 803  17  28   3   3]\n",
            " [ 10   0  20  30  37  18 872  10   2   1]\n",
            " [ 11   2  18  20  35  39   5 861   1   8]\n",
            " [ 53  17   9   8   2   2   9   2 877  21]\n",
            " [ 20  43   4   8   3   2   6   4  17 893]]\n",
            "Epoch 186/200 - Train Loss: 0.3594, Val Loss: 0.5866, Val Accuracy: 82.62%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5915\n",
            "Accuracy: 82.81%\n",
            "F1 Score: 0.8277\n",
            "Confusion Matrix:\n",
            "[[849   9  16  19  10   4   6  13  53  21]\n",
            " [ 13 912   0   2   2   5   0   3  17  46]\n",
            " [ 67   2 670  63  58  52  47  21  11   9]\n",
            " [ 17   4  23 708  35 139  30  27   9   8]\n",
            " [ 16   2  22  47 795  29  36  46   5   2]\n",
            " [  8   2  13 106  32 801   6  28   1   3]\n",
            " [ 11   1  17  43  23  21 871   5   4   4]\n",
            " [  8   0  10  29  31  47   2 866   0   7]\n",
            " [ 35  10   1  12   3   0   3   4 916  16]\n",
            " [ 15  41   2   9   1   3   1  10  25 893]]\n",
            "Epoch 187/200 - Train Loss: 0.3535, Val Loss: 0.5915, Val Accuracy: 82.81%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5699\n",
            "Accuracy: 83.42%\n",
            "F1 Score: 0.8335\n",
            "Confusion Matrix:\n",
            "[[842   8  30  15  17   3   5  12  38  30]\n",
            " [  8 909   6   5   0   2   0   4  13  53]\n",
            " [ 44   0 748  34  75  31  42  15   5   6]\n",
            " [ 15   0  35 651  84 114  60  25   6  10]\n",
            " [  8   1  23  20 888   8  27  20   3   2]\n",
            " [  8   0  23 130  60 736  13  29   1   0]\n",
            " [  8   0  14  30  32   8 898   5   2   3]\n",
            " [  9   1  13  24  60  18   7 862   0   6]\n",
            " [ 46  13   5   6   4   3   4   4 899  16]\n",
            " [ 10  39   5   7   1   0   6   7  16 909]]\n",
            "Epoch 188/200 - Train Loss: 0.3551, Val Loss: 0.5699, Val Accuracy: 83.42%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5741\n",
            "Accuracy: 83.36%\n",
            "F1 Score: 0.8336\n",
            "Confusion Matrix:\n",
            "[[883   8  40  13  11   6   2  10  19   8]\n",
            " [ 17 901   7   6   2   6   2   3  13  43]\n",
            " [ 31   0 837  23  39  34  25   5   4   2]\n",
            " [ 21   1  77 614  58 148  49  23   5   4]\n",
            " [  8   0  43  22 856  28  23  18   2   0]\n",
            " [  5   1  44  82  30 809  12  14   1   2]\n",
            " [  8   2  49  24  24  19 868   1   5   0]\n",
            " [ 12   0  35  12  53  56   5 822   3   2]\n",
            " [ 63  10  10  12   2   1   3   4 885  10]\n",
            " [ 33  38   3  11   7  10   6   9  22 861]]\n",
            "Epoch 189/200 - Train Loss: 0.3611, Val Loss: 0.5741, Val Accuracy: 83.36%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5798\n",
            "Accuracy: 82.83%\n",
            "F1 Score: 0.8288\n",
            "Confusion Matrix:\n",
            "[[798   7  34  27  15   2   5  13  66  33]\n",
            " [  8 908   3   4   1   2   1   3  22  48]\n",
            " [ 41   1 742  66  47  44  27  14  10   8]\n",
            " [ 11   1  41 702  44 122  35  23  14   7]\n",
            " [  6   0  21  57 811  30  32  35   5   3]\n",
            " [  5   2  24 132  27 768  10  24   2   6]\n",
            " [  5   1  24  53  25  15 862   3   7   5]\n",
            " [  7   2  15  29  29  36   2 873   1   6]\n",
            " [ 22  12   5  11   5   2   2   4 919  18]\n",
            " [ 12  38   3   9   4   5   3   7  19 900]]\n",
            "Epoch 190/200 - Train Loss: 0.3628, Val Loss: 0.5798, Val Accuracy: 82.83%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5758\n",
            "Accuracy: 82.55%\n",
            "F1 Score: 0.8263\n",
            "Confusion Matrix:\n",
            "[[811   9  34  23  10   0   9  14  52  38]\n",
            " [  9 906   5   7   0   3   5   0  20  45]\n",
            " [ 41   1 759  59  33  32  47  17   4   7]\n",
            " [ 11   2  41 743  36  87  41  21   9   9]\n",
            " [ 10   1  22  49 818  20  41  35   3   1]\n",
            " [  6   0  37 167  30 718   8  28   1   5]\n",
            " [  5   2  24  54  13  10 887   2   2   1]\n",
            " [  9   1  25  45  20  46   5 843   0   6]\n",
            " [ 47   9   8  11   1   4   8   0 895  17]\n",
            " [ 12  58   6  15   1   2   5   4  22 875]]\n",
            "Epoch 191/200 - Train Loss: 0.3601, Val Loss: 0.5758, Val Accuracy: 82.55%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5659\n",
            "Accuracy: 83.22%\n",
            "F1 Score: 0.8325\n",
            "Confusion Matrix:\n",
            "[[830  10  27  23  11   2   5   5  61  26]\n",
            " [ 12 905   0   6   0   2   2   1  21  51]\n",
            " [ 42   2 781  48  36  25  36  11  10   9]\n",
            " [ 13   4  37 751  30  80  44  12  18  11]\n",
            " [ 15   1  45  59 788  11  43  28   8   2]\n",
            " [ 13   2  29 166  31 713  11  26   1   8]\n",
            " [  7   3  21  46  17   3 890   5   1   7]\n",
            " [ 15   1  19  47  23  32   3 836   8  16]\n",
            " [ 29   8   3   6   0   0   4   2 933  15]\n",
            " [ 18  48   1   9   1   0   2   4  22 895]]\n",
            "Epoch 192/200 - Train Loss: 0.3580, Val Loss: 0.5659, Val Accuracy: 83.22%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5637\n",
            "Accuracy: 83.24%\n",
            "F1 Score: 0.8323\n",
            "Confusion Matrix:\n",
            "[[835  16  27  18   8   4   4  12  57  19]\n",
            " [  8 927   2   5   0   1   1   1  18  37]\n",
            " [ 50   3 759  46  41  48  23  21   6   3]\n",
            " [ 13   5  28 697  41 133  41  21  10  11]\n",
            " [  7   1  35  36 830  22  21  41   6   1]\n",
            " [  4   1  29 120  29 771   9  33   2   2]\n",
            " [  6   5  25  43  28  26 854   8   4   1]\n",
            " [  4   0  19  22  29  43   2 874   0   7]\n",
            " [ 38  23   4   7   1   1   1   4 909  12]\n",
            " [ 22  60   4   5   3   2   4   6  26 868]]\n",
            "Epoch 193/200 - Train Loss: 0.3653, Val Loss: 0.5637, Val Accuracy: 83.24%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5598\n",
            "Accuracy: 83.48%\n",
            "F1 Score: 0.8334\n",
            "Confusion Matrix:\n",
            "[[897   9  19   9   7   2   6   7  18  26]\n",
            " [ 14 930   3   1   0   1   2   3  14  32]\n",
            " [ 51   1 786  36  28  25  42  19   7   5]\n",
            " [ 30   2  44 645  51  94  60  45  14  15]\n",
            " [ 21   2  44  39 803  17  41  29   4   0]\n",
            " [ 16   4  28 119  31 727  23  38   4  10]\n",
            " [  9   2  35  18  14  10 900   2   5   5]\n",
            " [ 20   0  22  19  20  19   7 884   2   7]\n",
            " [ 63  19   7   3   0   0   3   2 879  24]\n",
            " [ 20  53   4   4   0   0   5   4  13 897]]\n",
            "Epoch 194/200 - Train Loss: 0.3617, Val Loss: 0.5598, Val Accuracy: 83.48%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5793\n",
            "Accuracy: 82.99%\n",
            "F1 Score: 0.8303\n",
            "Confusion Matrix:\n",
            "[[829  14  45  13  14   4   1  10  35  35]\n",
            " [ 10 946   1   4   0   2   0   0   3  34]\n",
            " [ 36   2 803  41  49  23  17  17   3   9]\n",
            " [ 16   4  54 717  42  90  32  27  10   8]\n",
            " [ 14   1  39  48 839  16  16  24   2   1]\n",
            " [  7   2  40 171  28 701  12  34   2   3]\n",
            " [  7   2  44  51  40   6 842   4   3   1]\n",
            " [ 12   1  18  32  36  25   2 864   1   9]\n",
            " [ 54  27  10  16   3   0   0   3 861  26]\n",
            " [ 12  59   4   5   2   0   3   8  10 897]]\n",
            "Epoch 195/200 - Train Loss: 0.3543, Val Loss: 0.5793, Val Accuracy: 82.99%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.6129\n",
            "Accuracy: 82.40%\n",
            "F1 Score: 0.8238\n",
            "Confusion Matrix:\n",
            "[[824  11  24  16   4   1   5   8  73  34]\n",
            " [ 11 875   4   5   0   1   1   0  25  78]\n",
            " [ 45   2 735  61  35  27  52  22  14   7]\n",
            " [ 15   4  32 750  38  67  45  24  14  11]\n",
            " [ 12   3  35  62 771  18  58  28   6   7]\n",
            " [  7   2  21 192  27 683  28  24   6  10]\n",
            " [  8   2  18  48  13   8 892   4   6   1]\n",
            " [ 10   1  19  31  31  29  10 842   5  22]\n",
            " [ 28   2   2   6   0   0   4   3 939  16]\n",
            " [  8  28   3   8   1   0   1   5  17 929]]\n",
            "Epoch 196/200 - Train Loss: 0.3528, Val Loss: 0.6129, Val Accuracy: 82.40%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5726\n",
            "Accuracy: 83.37%\n",
            "F1 Score: 0.8337\n",
            "Confusion Matrix:\n",
            "[[892  10  16  16   5   0   4  15  32  10]\n",
            " [ 13 928   2   3   1   1   2   1  17  32]\n",
            " [ 55   5 783  43  32  29  21  24   6   2]\n",
            " [ 14   4  48 700  48 106  26  37   9   8]\n",
            " [ 18   1  36  37 810  23  27  45   2   1]\n",
            " [ 12   1  28 136  27 739   6  46   2   3]\n",
            " [ 11   4  38  54  18  10 852   6   5   2]\n",
            " [ 21   1  14  24  22  23   3 890   1   1]\n",
            " [ 59  16   3   7   2   1   2   7 892  11]\n",
            " [ 30  70   3   8   1   0   2  12  23 851]]\n",
            "Epoch 197/200 - Train Loss: 0.3567, Val Loss: 0.5726, Val Accuracy: 83.37%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5685\n",
            "Accuracy: 82.96%\n",
            "F1 Score: 0.8304\n",
            "Confusion Matrix:\n",
            "[[850  10  23  21  12   4   8   7  47  18]\n",
            " [  9 905   4   6   1   2   3   2  17  51]\n",
            " [ 45   0 718  68  55  42  40  21   7   4]\n",
            " [  9   3  16 704  51 138  33  23  17   6]\n",
            " [ 15   0  23  41 849  19  23  25   5   0]\n",
            " [  4   1  12 145  29 773   8  22   5   1]\n",
            " [  7   1  15  54  41  23 852   4   2   1]\n",
            " [  9   1  11  38  45  37   3 848   3   5]\n",
            " [ 43   8   4  12   2   2   0   3 911  15]\n",
            " [ 16  38   5  10   4   3   3  10  25 886]]\n",
            "Epoch 198/200 - Train Loss: 0.3580, Val Loss: 0.5685, Val Accuracy: 82.96%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5931\n",
            "Accuracy: 82.88%\n",
            "F1 Score: 0.8291\n",
            "Confusion Matrix:\n",
            "[[826  12  42  19   6   2   6   8  50  29]\n",
            " [  7 910   5   7   2   2   1   1  16  49]\n",
            " [ 46   0 804  38  30  22  33  16   5   6]\n",
            " [ 11   2  57 730  47  72  38  21  11  11]\n",
            " [ 10   2  47  46 825  11  29  25   4   1]\n",
            " [  8   1  50 172  35 685   9  35   2   3]\n",
            " [  9   0  45  48  23  16 847   6   4   2]\n",
            " [  6   2  20  36  31  18   3 877   1   6]\n",
            " [ 36  19  12   7   4   2   3   0 896  21]\n",
            " [ 12  59   2   8   1   1   5   6  18 888]]\n",
            "Epoch 199/200 - Train Loss: 0.3595, Val Loss: 0.5931, Val Accuracy: 82.88%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5625\n",
            "Accuracy: 83.12%\n",
            "F1 Score: 0.8319\n",
            "Confusion Matrix:\n",
            "[[822  13  31  21  10   2   2  13  60  26]\n",
            " [  7 932   1   4   0   0   2   2  18  34]\n",
            " [ 39   3 752  70  46  33  33  12   5   7]\n",
            " [ 11   1  31 710  44 115  33  25  20  10]\n",
            " [  6   1  21  61 826  25  20  33   3   4]\n",
            " [  4   1  31 146  24 755   8  23   3   5]\n",
            " [  8   7  19  64  30  12 844   6   8   2]\n",
            " [  9   1  11  42  24  40   3 863   4   3]\n",
            " [ 31  14   3   8   5   0   3   2 918  16]\n",
            " [ 14  54   3   9   1   1   6   7  15 890]]\n",
            "Epoch 200/200 - Train Loss: 0.3518, Val Loss: 0.5625, Val Accuracy: 83.12%\n",
            "Evaluation Results:\n",
            "Average Loss: 0.5659\n",
            "Accuracy: 83.07%\n",
            "F1 Score: 0.8315\n",
            "Confusion Matrix:\n",
            "[[835  18  29  22  18   0   3  11  43  21]\n",
            " [ 10 930   2   3   0   1   4   1  13  36]\n",
            " [ 42   3 751  60  51  38  29  15   6   5]\n",
            " [ 13   4  28 740  33 108  31  19  17   7]\n",
            " [  9   0  21  67 807  29  29  32   6   0]\n",
            " [  7   0  33 157  28 735   6  29   2   3]\n",
            " [  5   1  25  53  27  14 865   3   5   2]\n",
            " [  7   2  13  40  29  39   5 858   1   6]\n",
            " [ 36  19   4   9   1   0   3   5 908  15]\n",
            " [ 15  65   3   8   0   3   4   8  16 878]]\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "unsupported format string passed to tuple.__format__",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-69445863849f>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mextended_test_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Extended CNN Test Accuracy: {extended_test_accuracy:.2f}%\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nEvaluating Extended CNN...\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mextended_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: unsupported format string passed to tuple.__format__"
          ]
        }
      ]
    }
  ]
}